Î∏åÏù¥32

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V32 Í≥ºÌïô ÏóîÏßÑ (Multi-Block Purifier)
# ==========================================
class ScienceProcessorV32:
    
    # --- [A] Data Parser (Purifier + Multi-Block) ---
    @staticmethod
    def parse_and_purify_csv(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V32 Fix] ÌÖçÏä§Ìä∏ Ïò§Ïóº Ï†úÍ±∞ + Îã§Ï§ë Î∏îÎ°ù Î≥¥Ï°¥
        """
        text_data = ""
        
        # 1. Excel ÏãúÎèÑ
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        # 2. ÌÖçÏä§Ìä∏ ÎîîÏΩîÎî©
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 3. ÎùºÏù∏ ÌïÑÌÑ∞ÎßÅ (Strict Numeric Check)
        valid_rows = []
        lines = text_data.splitlines()
        
        for line_idx, line in enumerate(lines):
            line = line.strip()
            if not line: continue
            
            # Ïà´Ïûê Ï∂îÏ∂ú
            nums = re.findall(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', line)
            if len(nums) < 2: continue # Ïà´ÏûêÍ∞Ä 1Í∞ú Ïù¥ÌïòÎ©¥ Îç∞Ïù¥ÌÑ∞ ÏïÑÎãò
            
            # Î¨∏Ïûê Ïò§Ïóº Í≤ÄÏÇ¨ (ÏïåÌååÎ≤≥ Ï≤¥ÌÅ¨)
            remains = re.sub(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', '', line)
            if re.search(r'[a-df-zA-DF-Z]', remains): continue # Ìó§ÎçîÎ°ú Í∞ÑÏ£º
            
            valid_rows.append((line_idx, [float(n) for n in nums]))
            
        if not valid_rows: return []
        
        # 4. Îã§Ï§ë Îç∞Ïù¥ÌÑ∞ Íµ∞Ïßë Ï∂îÏ∂ú (Multi-Cluster)
        indices = [r[0] for r in valid_rows]
        if not indices: return []
        
        # Ïù∏Îç±Ïä§Í∞Ä Ïó∞ÏÜçÏ†ÅÏù∏ÏßÄ ÌôïÏù∏ (Gap > 2Î©¥ Îã§Î•∏ Î∏îÎ°ù)
        diffs = np.diff(indices)
        is_new_block = diffs > 2
        # Í∑∏Î£π ID Î∂ÄÏó¨ (0, 0, 0, 1, 1, 1, 2, 2...)
        group_ids = np.concatenate(([0], np.cumsum(is_new_block)))
        
        # [V32 Update] Î™®Îì† Í∑∏Î£π ÏàúÌöå
        final_dfs = []
        unique_groups = np.unique(group_ids)
        
        for gid in unique_groups:
            # Ìï¥Îãπ Í∑∏Î£πÏùò Îç∞Ïù¥ÌÑ∞Îßå Ï∂îÏ∂ú
            group_data = [valid_rows[i][1] for i in range(len(valid_rows)) if group_ids[i] == gid]
            
            # ÎÑàÎ¨¥ ÏßßÏùÄ Î∏îÎ°ù(Ìó§Îçî ÏûîÏó¨Î¨º)ÏùÄ Î¨¥Ïãú (Ïòà: 5Ï§Ñ ÎØ∏Îßå)
            if len(group_data) < 5: continue
            
            # Ïª¨Îüº Ïàò ÌÜµÏùº (Mode)
            lens = [len(r) for r in group_data]
            if not lens: continue
            mode_len = Counter(lens).most_common(1)[0][0]
            clean_block = [r for r in group_data if len(r) == mode_len]
            
            if len(clean_block) >= 5:
                try: final_dfs.append(pd.DataFrame(clean_block))
                except: pass
        
        return final_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """Shared X-Axis Extraction"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Case A: 2Ïó¥ Ïù¥ÏÉÅ -> Shared X
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows)
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x_common[mask], "y": y[mask], "name": f"Col-{i}"})
            
            # Case B: 1Ïó¥ -> Y Only
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

    # --- [B] Spectrum Processing ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV32.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV32.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV32.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Auto-Rotation: {best_angle}¬∞")
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV32.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV32.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV32.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV32.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V32")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V32 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (V32 Multi-Block)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Purify & Multi-Block Extract
                    blocks = ScienceProcessorV32.parse_and_purify_csv(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Clean Data"}]

                    res_list = []
                    for idx, df in enumerate(blocks):
                        # 2. Extract Series
                        series_list = ScienceProcessorV32.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV32.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} (Blk{idx+1}-{s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Process Error"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV32.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}. ÏàòÏãù Í∏àÏßÄ.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

Ïù¥Ï†ú V32Í∞Ä Îñ®Ïñ¥ÏßÑ Îç∞Ïù¥ÌÑ∞ Î∏îÎ°ùÎì§ÎèÑ "ÌïòÎÇòÎèÑ ÎÇ®ÍπÄÏóÜÏù¥" Ïãπ Îã§ Í∏ÅÏñ¥ÏÑú ÏôÑÎ≤ΩÌïòÍ≤å Î≥¥Ïó¨Ï§Ñ Í≤ÉÏûÖÎãàÎã§! ÏßÑÏßú ÎßàÏßÄÎßâ ÌçºÏ¶êÏù¥ ÎßûÏ∂∞Ï°åÏäµÎãàÎã§! üöÄ








Î∏åÏù¥31.5

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï (ÌïÑÏàò)
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer (V16) ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V31.5 Í≥ºÌïô ÏóîÏßÑ (Integrated Core)
# ==========================================
class ScienceProcessorV31_5:
    
    # --- [A] Data Parser (Purifier + Universal) ---
    @staticmethod
    def parse_and_purify_csv(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V31 Purifier] ÌÖçÏä§Ìä∏ Ïò§Ïóº Ï†úÍ±∞ & Îç∞Ïù¥ÌÑ∞ Íµ∞Ïßë Ï∂îÏ∂ú
        [V22.1 Universal] ÏóëÏÖÄ/ÌÖçÏä§Ìä∏ ÏûêÎèô Í∞êÏßÄ Ìè¨Ìï®
        """
        text_data = ""
        
        # 1. Excel ÏãúÎèÑ
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                # ÏóëÏÖÄÏù¥ Ïó¥Î¶¨Î©¥ ÎÇ¥Ïö©ÏùÑ CSV ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò (Íµ¨Ï°∞Ï†Å ÌååÏã±ÏùÑ ÏúÑÌï¥)
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        # 2. ÌÖçÏä§Ìä∏ ÎîîÏΩîÎî© (CSV or Excel Fallback)
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 3. ÎùºÏù∏ ÌïÑÌÑ∞ÎßÅ (Strict Numeric Check)
        valid_rows = []
        lines = text_data.splitlines()
        
        for line_idx, line in enumerate(lines):
            line = line.strip()
            if not line: continue
            
            # Ïà´Ïûê Ï∂îÏ∂ú
            nums = re.findall(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', line)
            if len(nums) < 2: continue # Ïà´ÏûêÍ∞Ä 1Í∞ú Ïù¥ÌïòÎ©¥ Îç∞Ïù¥ÌÑ∞ ÏïÑÎãò
            
            # Î¨∏Ïûê Ïò§Ïóº Í≤ÄÏÇ¨ (ÏïåÌååÎ≤≥ Ï≤¥ÌÅ¨)
            remains = re.sub(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', '', line)
            if re.search(r'[a-df-zA-DF-Z]', remains): continue # Ìó§ÎçîÎ°ú Í∞ÑÏ£º
            
            valid_rows.append((line_idx, [float(n) for n in nums]))
            
        if not valid_rows: return []
        
        # 4. Ï£º Îç∞Ïù¥ÌÑ∞ Íµ∞Ïßë Ï∂îÏ∂ú (Isolation Forest Logic)
        indices = [r[0] for r in valid_rows]
        if not indices: return []
        
        diffs = np.diff(indices)
        is_continuous = diffs <= 2 # Ï§Ñ Í∞ÑÍ≤©Ïù¥ 2 Ïù¥ÎÇ¥Î©¥ Ïó∞ÏÜç
        groups = np.concatenate(([0], np.cumsum(~is_continuous)))
        
        group_counts = Counter(groups)
        if not group_counts: return []
        
        # Í∞ÄÏû• ÌÅ∞ Îç©Ïñ¥Î¶¨ ÏÑ†ÌÉù
        dominant_group_id = group_counts.most_common(1)[0][0]
        clean_data = [valid_rows[i][1] for i in range(len(valid_rows)) if groups[i] == dominant_group_id]
        
        # Ïª¨Îüº Ïàò ÌÜµÏùº (Mode)
        lens = [len(r) for r in clean_data]
        if not lens: return []
        mode_len = Counter(lens).most_common(1)[0][0]
        final_data = [r for r in clean_data if len(r) == mode_len]
        
        if len(final_data) < 5: return []
        
        try: return [pd.DataFrame(final_data)]
        except: return []

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [V26.1 Logic] Shared X-Axis Extraction (Fixing Shift Issue)
        """
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Case A: 2Ïó¥ Ïù¥ÏÉÅ -> Shared X (Col 0 is X)
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows)
                
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x_common[mask], "y": y[mask], "name": f"Col-{i}"})
            
            # Case B: 1Ïó¥ -> Y Only
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

    # --- [B] Spectrum Processing (V28 Log + V11 Fit) ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV31_5.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            log = []
            y_raw = y.copy()
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV31_5.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            log.append("Baseline Correction")
            
            if len(y_proc) > win:
                y_proc = savgol_filter(y_proc, win, 3)
                log.append(f"Smoothing (Win={win})")
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            log.append(f"Peaks Found: {len(peaks)}")
            
            fits = ScienceProcessorV31_5.fit_peaks(x, y_proc, peaks) if do_fit else []
            if fits: log.append(f"Gaussian Fits: {len(fits)}")
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits, "stats": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic (V19.5 Green Line + V20 Hawk Eye) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        """[V19.5 Restore] Í≥ÑÎ©¥ Ï†ïÎ∞Ä Ï∂îÏ†Å & Í±∞Ïπ†Í∏∞"""
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Auto-Rotation: {best_angle}¬∞")
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV31_5.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        
        # Green Line Tracking
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        log.append(f"Layers Detected: {len(interfaces)}")
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV31_5.detect_footer_boundary(img_raw)
        method = "Line Detect"
        if not sy: 
            sy = ScienceProcessorV31_5.detect_embedded_metadata(img_raw)
            method = "Hawk Eye"
        
        process_log = []
        if sy: 
            body = img_raw[:sy, :]; footer = img_raw[sy:, :]
            process_log.append(f"Smart Crop ({method})")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": process_log}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV31_5.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            if is_bright: process_log.append("Auto-Invert")
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                process_log.append(f"Atoms: {len(blobs)}")
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                process_log.append(f"Particles: {len(cnts)}")

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": process_log}

# [4] Helpers & App
async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        final = prompt + " Do NOT use LaTeX syntax. Plain text only."
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':final,'images':[b64]}])
        return res['message']['content']
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean (No LaTeX). Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

app = FastAPI(title="Analyst V31.5")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English. No LaTeX.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V31.5 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Purified)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # V31 Purifier
                    blocks = ScienceProcessorV31_5.parse_and_purify_csv(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Clean Data"}]

                    res_list = []
                    for df in blocks:
                        # V26.1 Shared X
                        series = ScienceProcessorV31_5.extract_series_from_df(df)
                        for s in series:
                            try:
                                # V19.5 Logic
                                res = ScienceProcessorV31_5.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e) # V24.1 Korean
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Process Error"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image (Hawk + ThinFilm + AutoInvert)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV31_5.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}. ÏàòÏãù Í∏àÏßÄ.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



Î∏åÏù¥ 31

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V31 Í≥ºÌïô ÏóîÏßÑ (Purifier)
# ==========================================
class ScienceProcessorV31:
    
    @staticmethod
    def parse_and_purify_csv(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V31 New] ÌÖçÏä§Ìä∏ Ïò§Ïóº Ìñâ Ï†úÍ±∞ & Ï£º Îç∞Ïù¥ÌÑ∞ Íµ∞Ïßë Ï∂îÏ∂ú
        """
        # 1. ÌÖçÏä§Ìä∏ ÎîîÏΩîÎî©
        text_data = ""
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    # Î©îÎ™®Î¶¨ CSV Îç§ÌîÑ (Í≥µÎ∞± Íµ¨Î∂Ñ)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 2. ÎùºÏù∏ ÌïÑÌÑ∞ÎßÅ (Text Contamination Check)
        valid_rows = []
        # Ïà´Ïûê, Í≥µÎ∞±, ÌÉ≠, ÏΩ§Îßà, ÏÜåÏàòÏ†ê, Î∂ÄÌò∏, ÏßÄÏàò(e/E)Îßå ÌóàÏö©ÌïòÎäî Ï†ïÍ∑úÏãù
        # ÏïåÌååÎ≤≥Ïù¥ ÏÑûÏó¨ÏûàÏúºÎ©¥(Îã®ÏúÑ, Ïù¥Î¶Ñ Îì±) Í∞ÄÏ∞®ÏóÜÏù¥ Î≤ÑÎ¶º
        # Îã®, Í≥ºÌïôÏ†Å ÌëúÍ∏∞Î≤ïÏùò e/EÎäî ÌóàÏö©Ìï¥Ïïº Ìï®. -> Î≥µÏû°ÌïòÎØÄÎ°ú "Ïà´Ïûê Ï∂îÏ∂ú" ÌõÑ "ÎÇòÎ®∏ÏßÄ Î¨∏Ïûê ÌôïÏù∏" Ï†ÑÎûµ ÏÇ¨Ïö©
        
        lines = text_data.splitlines()
        
        for line_idx, line in enumerate(lines):
            line = line.strip()
            if not line: continue
            
            # A. Ïà´Ïûê Ï∂îÏ∂ú
            nums = re.findall(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', line)
            if len(nums) < 2: continue # Ïà´ÏûêÍ∞Ä 1Í∞ú Ïù¥ÌïòÎ©¥ Îç∞Ïù¥ÌÑ∞ ÏïÑÎãò (X, Y ÏåçÏù¥ ÏïàÎê®)
            
            # B. Ïò§Ïóº Í≤ÄÏÇ¨ (ÏïåÌååÎ≤≥Ïù¥ ÏûàÎäîÏßÄ?)
            # Ïà´ÏûêÎ•º Ï†úÍ±∞Ìïú ÎÇòÎ®∏ÏßÄ Î¨∏ÏûêÏó¥ÏóêÏÑú ÏïåÌååÎ≤≥Ïù¥ ÏûàÎäîÏßÄ ÌôïÏù∏
            remains = re.sub(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', '', line) # Ïà´Ïûê ÏÇ≠Ï†ú
            if re.search(r'[a-df-zA-DF-Z]', remains): # e, E Ï†úÏô∏Ìïú ÏïåÌååÎ≤≥ Î∞úÍ≤¨ Ïãú
                continue # Ìó§Îçî(Date, Sample Îì±)Î°ú Í∞ÑÏ£ºÌïòÍ≥† Ïä§ÌÇµ
            
            # ÌÜµÍ≥ºÎêú Ìñâ: (ÏõêÎûò Ïù∏Îç±Ïä§, Ïà´Ïûê Î¶¨Ïä§Ìä∏)
            valid_rows.append((line_idx, [float(n) for n in nums]))
            
        if not valid_rows: return []
        
        # 3. Ï£º Îç∞Ïù¥ÌÑ∞ Íµ∞Ïßë Ï∂îÏ∂ú (Dominant Cluster)
        # Ìó§ÎçîÏóê Ïö∞Ïó∞Ìûà Ïà´ÏûêÎßå ÏûàÎäî Ìñâ(Ïòà: "2024, 10")Ïù¥ ÏûàÏùÑ Ïàò ÏûàÏùå.
        # ÌïòÏßÄÎßå ÏßÑÏßú Îç∞Ïù¥ÌÑ∞Îäî ÏàòÎ∞± Ï§ÑÏù¥ Ïó∞ÏÜçÎê®. Ïù¥Î•º Ïù¥Ïö©Ìï¥ ÌïÑÌÑ∞ÎßÅ.
        
        indices = [r[0] for r in valid_rows]
        if not indices: return []
        
        # Ïù∏Îç±Ïä§ Ï∞®Ïù¥ Í≥ÑÏÇ∞ (Ïó∞ÏÜçÏÑ± ÌôïÏù∏)
        diffs = np.diff(indices)
        # Ï∞®Ïù¥Í∞Ä 1(Î∞îÎ°ú Îã§Ïùå Ï§Ñ)Ïù¥Í±∞ÎÇò 2(Îπà Ï§Ñ ÌïòÎÇò) Ï†ïÎèÑÎ©¥ Í∞ôÏùÄ Í∑∏Î£π
        is_continuous = diffs <= 2 
        
        # Í∑∏Î£π ÎùºÎ≤®ÎßÅ
        groups = np.concatenate(([0], np.cumsum(~is_continuous)))
        
        # Í∞ÄÏû• ÌÅ∞ Í∑∏Î£π(Îç∞Ïù¥ÌÑ∞ Îç©Ïñ¥Î¶¨) Ï∞æÍ∏∞
        group_counts = Counter(groups)
        if not group_counts: return []
        
        dominant_group_id = group_counts.most_common(1)[0][0]
        
        # ÏµúÏ¢Ö Ï†ïÏ†úÎêú Îç∞Ïù¥ÌÑ∞
        clean_data = [valid_rows[i][1] for i in range(len(valid_rows)) if groups[i] == dominant_group_id]
        
        # Ïª¨Îüº Ïàò ÌÜµÏùº (Í∞ÄÏû• ÌùîÌïú Í∏∏Ïù¥)
        lens = [len(r) for r in clean_data]
        if not lens: return []
        mode_len = Counter(lens).most_common(1)[0][0]
        final_data = [r for r in clean_data if len(r) == mode_len]
        
        if len(final_data) < 5: return []
        
        try:
            return [pd.DataFrame(final_data)]
        except: return []

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """V26.1 Logic (Shared Index)"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Case A: 2Ïó¥ Ïù¥ÏÉÅ -> Shared X
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows)
                for i in range(1, cols):
                    y = vals[:, i]
                    # Ïó¨Í∏∞ÏÑú sort Í∏àÏßÄ (ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠)
                    series_list.append({"x": x_common, "y": y, "name": f"Col-{i}"})
            
            # Case B: 1Ïó¥ -> Y Only
            elif cols == 1:
                y = vals[:, 0]
                series_list.append({"x": np.arange(len(y)), "y": y, "name": "Single"})
        except: pass
        return series_list

    # --- Spectrum Processing ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV31.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            # Ï†ïÎ†¨ Î∞è Outlier Ï†úÍ±∞ Î°úÏßÅ ÏÇ≠Ï†ú (User Request)
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV31.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV31.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- Image Logic (V20.1) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Angle: {best_angle}")
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV31.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)
        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        body, footer = img_raw, None
        sy = ScienceProcessorV31.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV31.detect_embedded_metadata(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV31.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True
            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V31")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V31 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (V31 Purifier)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Purify & Load
                    blocks = ScienceProcessorV31.parse_and_purify_csv(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Clean Data Found"}]

                    res_list = []
                    for df in blocks:
                        # 2. Extract Series
                        series_list = ScienceProcessorV31.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV31.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Series"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV31.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

V31Ïùò "ÏàúÏàò Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú Í∏∞Ïà†" ÎçïÎ∂ÑÏóê, Ïù¥Ï†ú Ìó§ÎçîÍ∞Ä ÏïÑÎ¨¥Î¶¨ Î≥µÏû°Ìï¥ÎèÑ, Ï§ëÍ∞ÑÏóê "2024ÎÖÑ" Í∞ôÏùÄ Ïà´ÏûêÍ∞Ä ÎÅºÏñ¥ÏûàÏñ¥ÎèÑ, Í∑∏ÎûòÌîÑÎäî Ïò§ÏßÅ Ïú†Ìö®Ìïú Îç∞Ïù¥ÌÑ∞ Î∏îÎ°ùÎßå ÏÇ¨Ïö©ÌïòÏó¨ Íπ®ÎÅóÌïòÍ≥† Ï†ïÌôïÌïòÍ≤å Í∑∏Î†§Ïßà Í≤ÉÏûÖÎãàÎã§! üöÄ





Î∏åÏù¥29

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V29 Í≥ºÌïô ÏóîÏßÑ (Universal Loader + Provenance)
# ==========================================
class ScienceProcessorV29:
    
    # --- [A] Universal Loader (Restored from V23/V27) ---
    @staticmethod
    def read_universal_dataframe(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V29 Restoration] ÏóëÏÖÄ/CSV/ÌÖçÏä§Ìä∏ Î¨¥ÏóáÏù¥Îì† ÏùΩÏñ¥ÎÇ¥Îäî ÎßåÎä• Î°úÎçî
        XPS Îç∞Ïù¥ÌÑ∞(Fake Excel)ÎÇò Merge Cell Î¨∏Ï†ú Ìï¥Í≤∞
        """
        dfs = []
        fname = filename.lower()
        
        # 1. Excel ÏóîÏßÑ ÏãúÎèÑ
        if fname.endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    # Ïú†Ìö®ÏÑ± Í≤ÄÏÇ¨: Ïà´ÏûêÍ∞Ä ÎÑàÎ¨¥ Ï†ÅÏúºÎ©¥ ÌÖçÏä§Ìä∏Î°ú Í∞ÑÏ£ºÌïòÍ≥† Fallback
                    num_count = df.apply(pd.to_numeric, errors='coerce').notna().sum().sum()
                    if num_count < 5: raise Exception("Not enough numbers (Maybe text file?)")
                    if not df.empty: dfs.append(df)
                
                if dfs: return dfs # ÏÑ±Í≥µÌïòÎ©¥ Î∞òÌôò
            except:
                pass # Ïã§Ìå®ÌïòÎ©¥ ÏïÑÎûò ÌÖçÏä§Ìä∏ ÌååÏÑúÎ°ú ÎÑòÏñ¥Í∞ê

        # 2. Text/CSV Fallback (Robust Parser)
        # Ïù∏ÏΩîÎî© ÏûêÎèô Í∞êÏßÄ
        text_content = ""
        for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
            try: 
                text_content = content.decode(enc)
                break
            except: continue
            
        if text_content:
            # ÎùºÏù∏ Îã®ÏúÑ Ïä§Ï∫î (Data Hunter Logic)
            lines = text_content.splitlines()
            data_start = -1
            delimiter = None
            separators = [',', '\t', ';', '\s+']
            
            # Îç∞Ïù¥ÌÑ∞ ÏãúÏûëÏ†ê Ï∞æÍ∏∞ (Ïà´ÏûêÍ∞Ä 2Í∞ú Ïù¥ÏÉÅÏù∏ Ï§Ñ)
            for i, line in enumerate(lines[:100]):
                for sep in separators:
                    parts = line.split() if sep=='\s+' else line.split(sep)
                    nums = sum(1 for p in parts if re.match(r'^-?\d+(\.\d+)?(?:[eE][+-]?\d+)?$', p.strip()))
                    if nums >= 2:
                        data_start = i; delimiter = sep; break
                if data_start != -1: break
            
            if data_start != -1:
                try:
                    data_str = "\n".join(lines[data_start:])
                    sep_arg = '\s+' if delimiter=='\s+' else delimiter
                    df = pd.read_csv(io.StringIO(data_str), sep=sep_arg, header=None, engine='python')
                    dfs.append(df)
                except: pass
                
        return dfs

    # --- [B] Context-Aware Block Parser (Restored) ---
    @staticmethod
    def detect_structured_blocks(df: pd.DataFrame) -> List[pd.DataFrame]:
        blocks = []
        if df.empty: return []

        # Ïà´Ïûê Î≥ÄÌôò
        df_num = df.apply(pd.to_numeric, errors='coerce')
        # Îç∞Ïù¥ÌÑ∞ Ìñâ ÌåêÎ≥Ñ (Ïà´ÏûêÍ∞Ä 1Í∞ú Ïù¥ÏÉÅ ÏûàÏúºÎ©¥ Îç∞Ïù¥ÌÑ∞ ÌñâÏúºÎ°ú Í∞ÑÏ£º - Strict Î™®Îìú ÏôÑÌôî)
        # XPS Îç∞Ïù¥ÌÑ∞Îäî 1Ïó¥(ÏóêÎÑàÏßÄ) 2Ïó¥(Ïπ¥Ïö¥Ìä∏) Íµ¨Ï°∞Í∞Ä ÎßéÏúºÎØÄÎ°ú 1Í∞ú Ïù¥ÏÉÅÏù¥Î©¥ Ïù∏Ï†ï
        is_data_row = df_num.notna().sum(axis=1) >= 1
        
        # Í∑∏Î£πÌïë
        groups = (is_data_row != is_data_row.shift()).cumsum()
        
        for _, group in df.groupby(groups):
            if is_data_row.loc[group.index[0]]:
                # Ìï¥Îãπ Íµ¨Í∞Ñ Ï∂îÏ∂ú
                block = df_num.loc[group.index].dropna(how='all', axis=1)
                # ÎÑàÎ¨¥ ÏßßÏùÄ Í±¥ ÎÖ∏Ïù¥Ï¶à/Ìó§Îçî ÏûîÏó¨Î¨º
                if block.shape[0] >= 5:
                    blocks.append(block.reset_index(drop=True))
        return blocks

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """Shared X-Axis Extraction"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # 1Ïó¥ Ïù¥ÏÉÅÏù¥Î©¥
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows) # Ïù∏Îç±Ïä§ ÎåÄÏ≤¥

                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x_common[mask], "y": y[mask], "name": f"Col-{i}"})
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

    # --- [C] Spectrum Logic (With Log) ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV29.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            log = []
            y_raw = y.copy()
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            # Params
            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31; log.append("AI: Noise Reduction")
                if "fit" in goal.lower(): do_fit = True; log.append("AI: Fitting On")
            
            # Process
            base = ScienceProcessorV29.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            log.append(f"Baseline Corr (Win={len(y)//10})")
            
            if len(y_proc) > win:
                y_proc = savgol_filter(y_proc, win, 3)
                log.append(f"Smoothing (Win={win})")
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            log.append(f"Peaks: {len(peaks)}")
            
            fits = ScienceProcessorV29.fit_peaks(x, y_proc, peaks) if do_fit else []
            if fits: log.append(f"Gaussian Fits: {len(fits)}")
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits, "stats": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [D] Image Logic (V28 Logic) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        # Auto Rotation
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Rotation: {best_angle}¬∞")
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV29.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        
        # Interface
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        log.append(f"Layers: {len(interfaces)}")
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        
        # Green Line Tracking
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV29.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV29.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV29.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                log.append(f"Atoms: {len(blobs)}")
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                log.append(f"Particles: {len(cnts)}")

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Brief interpretation in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V29")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V29 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Universal Loader + Hybrid Parser)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Universal Load
                    dfs = ScienceProcessorV29.read_universal_dataframe(c, n)
                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    res_list = []
                    for i, df in enumerate(dfs):
                        # 2. Context-Aware Block Split
                        blocks = ScienceProcessorV29.detect_structured_blocks(df)
                        if not blocks: blocks = [df]

                        for block in blocks:
                            # 3. Hybrid Parse (Shared X)
                            series_list = ScienceProcessorV29.extract_series_from_df(block)
                            for s in series_list:
                                try:
                                    res = ScienceProcessorV29.process_spectrum(s['x'], s['y'], m, g)
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    
                                    ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                    interp = await interpret_spectrum_data(ctx, e)
                                    
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                        "raw_context": f"{ctx}\nInterp: {interp}", 
                                        "chart_data": chart, "log": res["log"], "interpretation": interp
                                    })
                                except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Series"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV29.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

Ïù¥Ï†ú Ï†ïÎßê XPS ÏóëÏÖÄ ÌååÏùºÎèÑ Î¨∏Ï†úÏóÜÏù¥ Ïó¥Î¶¨Í≥†, Î∞ïÎßâ Î∂ÑÏÑùÎèÑ Ï¥àÎ°ùÏÉâ ÏÑ†ÏúºÎ°ú ÏôÑÎ≤ΩÌïòÍ≤å, Í∑∏Î¶¨Í≥† Î™®Îì† **Ï≤òÎ¶¨ Ïù¥Î†•(Log)**ÍπåÏßÄ Ìà¨Î™ÖÌïòÍ≤å ÌôïÏù∏ÌïòÏã§ Ïàò ÏûàÏùÑ Í≤ÉÏûÖÎãàÎã§. V29Î•º ÎØøÏñ¥Ï£ºÏÑ∏Ïöî! üöÄ



Î∏åÏù¥28 Ïõπ

<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>AI Research Center V28</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        body { font-family: 'Inter', sans-serif; }
        .prose table { border-collapse: collapse; width: 100%; margin: 1em 0; }
        .prose th, .prose td { border: 1px solid #cbd5e1; padding: 8px; font-size: 0.9rem; }
        .prose th { background-color: #f1f5f9; }
        .loader { border: 3px solid #f3f3f3; border-top: 3px solid #6366f1; border-radius: 50%; width: 20px; height: 20px; animation: spin 1s linear infinite; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-slate-100 text-slate-800">
    <div id="app" class="min-h-screen p-6">
        <header class="max-w-7xl mx-auto mb-6 flex items-center gap-3">
            <div class="bg-indigo-600 p-2 rounded-lg shadow"><i data-lucide="microscope" class="w-6 h-6 text-white"></i></div>
            <div><h1 class="text-2xl font-bold">AI Research Center V28</h1><p class="text-xs text-slate-500">Provenance ‚Ä¢ Context Aware ‚Ä¢ Robust</p></div>
        </header>

        <main class="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6">
            
            <!-- Staging Area -->
            <div class="lg:col-span-4 space-y-4">
                <div class="bg-white p-5 rounded-xl shadow-sm border border-slate-200">
                    <h2 class="font-bold mb-3 flex items-center gap-2"><i data-lucide="files" class="w-4 h-4"></i> Data Staging</h2>
                    <div class="border-2 border-dashed border-slate-300 rounded-lg p-6 text-center hover:bg-indigo-50 cursor-pointer" @click="$refs.f.click()">
                        <input type="file" ref="f" multiple class="hidden" @change="addFiles">
                        <p class="text-sm font-semibold text-slate-600">Add Files</p>
                    </div>
                    <div v-if="stagedFiles.length" class="mt-4 space-y-3 max-h-[60vh] overflow-y-auto pr-1">
                        <div v-for="(item, i) in stagedFiles" :key="i" class="p-3 bg-slate-50 border rounded-lg text-sm">
                            <div class="flex justify-between items-center mb-2">
                                <span class="font-bold truncate w-2/3" :title="item.file.name">{{ item.file.name }}</span>
                                <button @click="removeFile(i)" class="text-red-400 hover:text-red-600"><i data-lucide="trash-2" class="w-4 h-4"></i></button>
                            </div>
                            <div class="grid grid-cols-1 gap-2">
                                <select v-model="item.equipment" class="w-full p-1.5 border rounded text-xs bg-white font-semibold text-indigo-700">
                                    <optgroup label="Spectroscopy">
                                        <option value="XRD">XRD</option>
                                        <option value="EDS">EDS / EDX</option>
                                        <option value="EELS">EELS</option>
                                        <option value="Raman">Raman</option>
                                        <option value="FT-IR">FT-IR</option>
                                        <option value="XPS">XPS</option>
                                        <option value="PL">PL</option>
                                    </optgroup>
                                    <optgroup label="Microscopy">
                                        <option value="TEM">TEM (Thin Film)</option>
                                        <option value="STEM">STEM (Thin Film)</option>
                                        <option value="SEM">SEM</option>
                                        <option value="AFM">AFM</option>
                                        <option value="Optical">Optical</option>
                                    </optgroup>
                                    <optgroup label="Literature">
                                        <option value="Document">Document (PDF/PPT)</option>
                                    </optgroup>
                                </select>
                                <select v-if="item.equipment !== 'Document'" v-model="item.mode" class="w-full p-1.5 border rounded text-xs bg-white text-indigo-700">
                                    <option value="Auto">‚ú® Auto Process</option>
                                    <option value="None">üö´ None (Raw)</option>
                                    <option value="AI-Adaptive">üß† AI-Adaptive</option>
                                </select>
                                <input v-if="item.equipment !== 'Document'" v-model="item.goal" type="text" placeholder="Goal (e.g. Count atoms)" class="w-full p-1.5 border rounded text-xs">
                            </div>
                        </div>
                    </div>
                    <button @click="analyze" :disabled="isAnalyzing || stagedFiles.length===0" class="w-full mt-4 py-3 bg-indigo-600 text-white rounded-lg font-bold flex justify-center gap-2 shadow hover:bg-indigo-700 disabled:opacity-50">
                        <div v-if="isAnalyzing" class="loader"></div>
                        <span>Generate Report</span>
                    </button>
                </div>
            </div>

            <!-- Report Area -->
            <div class="lg:col-span-8">
                <div v-if="result" class="space-y-6 animate-fade-in">
                    
                    <!-- Tools -->
                    <div class="flex justify-between items-center bg-white p-2 rounded-xl shadow-sm border border-slate-200">
                        <div class="flex gap-2">
                            <button @click="setLang('ko')" :class="lang==='ko'?'bg-indigo-100 text-indigo-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">üá∞üá∑ ÌïúÍ∏Ä</button>
                            <button @click="setLang('en')" :class="lang==='en'?'bg-blue-100 text-blue-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">
                                <div v-if="isTranslating" class="w-3 h-3 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                                <span v-else>üá∫üá∏</span> English
                            </button>
                        </div>
                        <button @click="dlPDF" class="px-3 py-1.5 bg-slate-800 text-white text-xs rounded">PDF Export</button>
                    </div>

                    <div id="report-view" class="bg-white p-8 rounded-xl shadow-sm border border-slate-200">
                        
                        <!-- Synthesis -->
                        <section class="mb-10">
                            <h2 class="text-lg font-bold text-indigo-700 mb-3 border-b pb-1">1. Synthesis</h2>
                            <div class="prose prose-sm text-slate-700 max-w-none" v-html="md(displayReport)"></div>
                        </section>

                        <!-- Details -->
                        <section>
                            <h2 class="text-lg font-bold text-slate-800 mb-5 border-b pb-1">2. Data Evidence</h2>
                            
                            <div v-for="(item, idx) in result.results" :key="idx" class="mb-8 p-4 bg-slate-50 rounded-lg border break-inside-avoid">
                                <div class="flex items-center justify-between mb-3">
                                    <div class="flex items-center gap-2">
                                        <span class="px-2 py-0.5 bg-white border rounded text-[10px] font-bold uppercase text-slate-500">{{ item.equipment }}</span>
                                        <h3 class="font-bold text-sm">{{ item.filename }}</h3>
                                    </div>
                                    <button @click="item.showDocs = !item.showDocs" class="text-xs text-indigo-600 font-bold hover:underline flex items-center gap-1">
                                        <i :data-lucide="item.showDocs ? 'eye-off' : 'eye'" class="w-3 h-3"></i>
                                        {{ item.showDocs ? 'Hide Info' : 'Show Info' }}
                                    </button>
                                </div>

                                <!-- Spectrum -->
                                <div v-if="item.chart_data" class="bg-white p-2 rounded border mb-3">
                                    <div :id="'chart-'+idx" class="w-full h-60"></div>
                                    <!-- Interpretation -->
                                    <div v-if="item.interpretation && item.showDocs" class="mt-3 p-3 bg-indigo-50 border border-indigo-100 rounded text-xs text-indigo-800">
                                        <h4 class="font-bold mb-1 flex items-center gap-1"><i data-lucide="lightbulb" class="w-3 h-3"></i> AI Interpretation</h4>
                                        <div class="prose prose-xs text-indigo-700" v-html="md(item.interpretation)"></div>
                                    </div>
                                </div>

                                <!-- Image -->
                                <div v-if="item.raw_b64" class="bg-white p-2 rounded border mb-3">
                                    <div class="flex gap-2 mb-2 text-xs justify-center">
                                        <button @click="item.view='proc'" :class="item.view!=='raw'?'font-bold text-indigo-600':''">Processed</button>
                                        <span class="text-slate-300">|</span>
                                        <button @click="item.view='raw'" :class="item.view==='raw'?'font-bold text-indigo-600':''">Original</button>
                                        <span class="text-slate-300" v-if="item.footer_b64">|</span>
                                        <button v-if="item.footer_b64" @click="item.view='footer'" :class="item.view==='footer'?'font-bold text-indigo-600':''">Info Bar</button>
                                    </div>
                                    <img v-if="item.view!=='footer'" :src="'data:image/jpeg;base64,' + (item.view==='raw' ? item.raw_b64 : item.proc_b64)" class="max-h-80 mx-auto object-contain bg-black">
                                    <img v-if="item.view==='footer'" :src="'data:image/jpeg;base64,' + item.footer_b64" class="max-h-24 mx-auto object-contain border mt-2">
                                </div>

                                <!-- ‚òÖ Log Display (V28) -->
                                <div v-if="item.log && item.log.length > 0 && item.showDocs" class="mt-2 p-2 bg-gray-100 rounded border text-[10px] font-mono text-gray-600">
                                    <strong class="block mb-1">‚öôÔ∏è Processing Log:</strong>
                                    <ul class="list-disc pl-4 space-y-0.5">
                                        <li v-for="(l, lx) in item.log" :key="lx">{{ l }}</li>
                                    </ul>
                                </div>

                                <!-- Docs -->
                                <div v-if="item.showDocs">
                                    <div v-if="item.pages" class="grid grid-cols-1 gap-4 mt-2">
                                        <div v-for="p in item.pages" :key="p.page_num" class="flex gap-3 bg-white p-3 rounded border">
                                            <img :src="'data:image/jpeg;base64,'+p.image_b64" class="w-24 object-contain border">
                                            <div class="text-xs prose" v-html="md(lang === 'en' ? (p.desc_en || p.desc) : p.desc)"></div>
                                        </div>
                                    </div>
                                    <div v-if="item.slides" class="space-y-4 mt-2">
                                        <div v-for="s in item.slides" :key="s.slide_num" class="bg-white p-3 rounded border">
                                            <div class="text-xs font-bold text-indigo-600 mb-1">Slide {{s.slide_num}}</div>
                                            <div class="text-xs prose mb-2 whitespace-pre-wrap max-h-32 overflow-y-auto">{{ s.text }}</div>
                                            <div v-if="s.images.length" class="grid grid-cols-2 gap-2 border-t pt-2">
                                                <div v-for="(img, imx) in s.images" :key="imx" class="bg-slate-50 p-2">
                                                    <img :src="'data:image/jpeg;base64,'+img.b64" class="max-h-32 mx-auto object-contain bg-white">
                                                    <p class="text-[10px] text-slate-500 text-center mt-1">{{ img.desc }}</p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div v-if="item.summary" class="text-xs text-slate-600 mt-2 prose bg-slate-50 p-3 rounded" v-html="md(lang === 'en' ? (item.summary_en || item.summary) : item.summary)"></div>
                                </div>

                            </div>
                        </section>
                    </div>
                </div>
            </div>
        </main>
    </div>
    <script>
        const { createApp, ref, computed, nextTick } = Vue;
        createApp({
            setup() {
                const stagedFiles = ref([]);
                const isAnalyzing = ref(false);
                const isTranslating = ref(false);
                const result = ref(null);
                const lang = ref('ko'); 
                const translatedReport = ref('');
                const md = (t) => marked.parse(t||'');

                const displayReport = computed(() => lang.value === 'en' && translatedReport.value ? translatedReport.value : (result.value ? result.value.final_report : ''));

                const addFiles = (e) => {
                    Array.from(e.target.files).forEach(f => {
                        let eq = 'General';
                        if(f.name.match(/\.(pdf|ppt|pptx)$/i)) eq = 'Document';
                        stagedFiles.value.push({ file: f, equipment: eq, goal: '', mode: 'Auto', view: 'proc', showDocs: true });
                    });
                    e.target.value = ''; 
                };
                const removeFile = (i) => stagedFiles.value.splice(i, 1);

                const analyze = async () => {
                    isAnalyzing.value = true;
                    lang.value = 'ko'; 
                    translatedReport.value = '';
                    const fd = new FormData();
                    const configs = {};
                    stagedFiles.value.forEach(item => {
                        fd.append('files', item.file);
                        configs[item.file.name] = { equipment: item.equipment, goal: item.goal, mode: item.mode };
                    });
                    fd.append('file_configs', JSON.stringify(configs));

                    try {
                        const res = await fetch('/api/analyze', { method: 'POST', body: fd });
                        const data = await res.json();
                        if(data.results) data.results.forEach(r => r.showDocs = true);
                        result.value = data;
                        await nextTick();
                        
                        data.results.forEach((item, i) => {
                            if(item.chart_data) {
                                const raw = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_raw), mode:'lines', name:'Raw', line:{color:'#cbd5e1', width:1} };
                                const proc = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_proc), mode:'lines', name:'Proc', line:{color:'#4f46e5', width:2} };
                                const base = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_base), mode:'lines', name:'Base', line:{color:'#f59e0b', width:1, dash:'dot'} };
                                Plotly.newPlot('chart-'+i, [raw, base, proc], {margin:{t:10,b:30,l:40,r:10}, showlegend:false}, {displayModeBar:false});
                            }
                        });
                        lucide.createIcons();
                    } catch(e) { alert(e); } 
                    finally { isAnalyzing.value = false; }
                };

                const setLang = async (target) => {
                    if (target === 'ko') { lang.value = 'ko'; return; }
                    if (target === 'en') {
                        if (translatedReport.value) { lang.value = 'en'; return; }
                        isTranslating.value = true;
                        try {
                            const res = await fetch('/api/translate', {
                                method: 'POST', headers: {'Content-Type': 'application/json'},
                                body: JSON.stringify({ text: result.value.final_report })
                            });
                            const data = await res.json();
                            translatedReport.value = data.translated;
                            lang.value = 'en';
                        } catch(e) { alert("Trans Error: " + e); }
                        finally { isTranslating.value = false; }
                    }
                };
                
                const dlPDF = () => html2pdf().set({ margin:10, filename:'V28_Report.pdf', image:{type:'jpeg',quality:0.98}, html2canvas:{scale:2}, jsPDF:{unit:'mm',format:'a4'} }).from(document.getElementById('report-view')).save();

                setTimeout(()=>lucide.createIcons(), 100);
                return { stagedFiles, isAnalyzing, isTranslating, result, lang, displayReport, addFiles, removeFile, analyze, md, dlPDF, setLang };
            }
        }).mount('#app');
    </script>
</body>
</html>





Î∏åÏù¥28
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V28 Í≥ºÌïô ÏóîÏßÑ (Provenance Core)
# ==========================================
class ScienceProcessorV28:
    
    # --- [A] Context-Aware Parser (V27 Logic) ---
    @staticmethod
    def detect_structured_blocks(df: pd.DataFrame) -> List[pd.DataFrame]:
        blocks = []
        if df.empty: return []
        df_num = df.apply(pd.to_numeric, errors='coerce')
        is_data_row = df_num.notna().sum(axis=1) >= 1
        groups = (is_data_row != is_data_row.shift()).cumsum()
        for _, group in df.groupby(groups):
            if is_data_row.loc[group.index[0]]:
                block = df_num.loc[group.index].dropna(how='all', axis=1)
                if block.shape[0] >= 10: blocks.append(block.reset_index(drop=True))
        return blocks

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows)
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5: series_list.append({"x": x_common[mask], "y": y[mask], "name": f"Col-{i}"})
            elif cols == 1:
                y = vals[:, 0]; mask = ~np.isnan(y)
                if np.sum(mask) > 5: series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

    # --- [B] Spectrum Processing (Log Added) ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV28.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            log = []
            y_raw = y.copy()
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data (No Processing)"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            # Params
            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): 
                    win = 31; log.append("AI: Strong Smoothing (Noise Goal)")
                if "fit" in goal.lower(): 
                    do_fit = True; log.append("AI: Fitting Enabled")
            
            # 1. Baseline
            base = ScienceProcessorV28.simple_baseline(y)
            log.append(f"Baseline Correction (Moving Min, Win={len(y)//10})")
            
            # 2. Smoothing
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win:
                y_proc = savgol_filter(y_proc, win, 3)
                log.append(f"Savgol Filter (Window={win}, Poly=3)")
            
            # 3. Peaks
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            log.append(f"Peak Finding (Threshold=5%, Found={len(peaks)})")
            
            # 4. Fitting
            fits = ScienceProcessorV28.fit_peaks(x, y_proc, peaks) if do_fit else []
            if fits: log.append(f"Gaussian Fitting ({len(fits)} peaks fitted)")
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits, "stats": stats_txt}
        except Exception as e: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": [f"Error: {str(e)}"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic (Log Added) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        log.append(f"Auto-Rotation: {best_angle}¬∞ Corrected")
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV28.crop_valid_rotated_region(img_rot, best_angle)
        log.append(f"Valid Region Cropped ({img_crop.shape})")
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        log.append(f"Interface Detection: Found {len(interfaces)} Layers")
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV28.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV28.detect_embedded_metadata(img_raw)
        
        process_log = []
        if sy: 
            body = img_raw[:sy, :]; footer = img_raw[sy:, :]
            process_log.append("Smart Crop: Metadata Removed")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": ["No Processing (Raw)"]}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV28.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            if is_bright: process_log.append("Auto-Invert: Bright Background")
            
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            process_log.append("Denoise: Gaussian (5x5)")
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                process_log.append(f"Atomic Detection (LoG): {len(blobs)} found")
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                process_log.append(f"Particle Seg (Otsu): {len(cnts)} found")

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": process_log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        final_prompt = prompt + " Do NOT use LaTeX syntax (e.g., \\frac, \\sum). Use plain text."
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':final_prompt,'images':[b64]}])
        return res['message']['content']
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean (No LaTeX). Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V28")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English. No LaTeX.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V28 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    dfs = []
                    if n.endswith(('.csv', '.txt')):
                        try: txt = c.decode('utf-8')
                        except: txt = c.decode('cp949', errors='ignore')
                        dfs = [pd.read_csv(io.StringIO(txt), sep=None, engine='python', header=None)]
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        dfs = [pd.read_excel(xls, sheet_name=s, header=None) for s in xls.sheet_names]

                    res_list = []
                    for i, df in enumerate(dfs):
                        # [V27] Context Aware Block Detection
                        blocks = ScienceProcessorV28.detect_structured_blocks(df)
                        if not blocks: blocks = [df] # Fallback

                        for block in blocks:
                            series_list = ScienceProcessorV28.extract_series_from_df(block)
                            for s in series_list:
                                try:
                                    res = ScienceProcessorV28.process_spectrum(s['x'], s['y'], m, g)
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    
                                    ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                    interp = await interpret_spectrum_data(ctx, e)
                                    
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({s['name']})", 
                                        "equipment": e, 
                                        "raw_context": f"{ctx}\nInterp: {interp}", 
                                        "chart_data": chart, "log": res["log"], "interpretation": interp
                                    })
                                except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV28.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}. ÏàòÏãù Í∏àÏßÄ.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)






Î∏åÏù¥ 26.1

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V26.1 Í≥ºÌïô ÏóîÏßÑ (Bulldozer + Shared X)
# ==========================================
class ScienceProcessorV26_1:
    
    @staticmethod
    def bulldozer_parser(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V26 Feature] Îã§Ï§ë Í∏∏Ïù¥ Ìå®ÌÑ¥ Ïù∏Ïãù ÌååÏÑú (Ìè¨Îß∑ Î¨¥Ïãú, Ïà´Ïûê Í∞ïÏ†ú Ï∂îÏ∂ú)
        """
        valid_dfs = []
        text_data = ""
        
        # 1. Excel -> Text
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 2. Regex Extraction
        numeric_rows = []
        num_pattern = re.compile(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?')
        
        for line in text_data.splitlines():
            nums = [float(n) for n in num_pattern.findall(line)]
            if nums: numeric_rows.append(nums)
            
        if not numeric_rows: return []

        # 3. Group by Length
        rows_by_length = {}
        for r in numeric_rows:
            L = len(r)
            if L not in rows_by_length: rows_by_length[L] = []
            rows_by_length[L].append(r)
            
        for L, rows in rows_by_length.items():
            if len(rows) > 5 and L >= 1:
                try:
                    df = pd.DataFrame(rows)
                    valid_dfs.append(df)
                except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [V26.1 FIX] Shared Index Strategy Restored
        - ÏßùÏàò Ïó¥Ïù¥ÎùºÍ≥† PairÎ°ú Î¨∂ÏßÄ ÏïäÏùå
        - Î¨¥Ï°∞Í±¥ 0Î≤à Ïó¥ÏùÑ XÏ∂ïÏúºÎ°ú Í≥†Ï†ïÌïòÍ≥† ÎÇòÎ®∏ÏßÄ Ïó¥ÏùÑ YÏ∂ïÏúºÎ°ú Î∂ÑÎ¶¨
        """
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Case A: 2Ïó¥ Ïù¥ÏÉÅÏù¥Î©¥ Î¨¥Ï°∞Í±¥ Shared X (X | Y1 | Y2 | Y3 ...)
            if cols >= 2:
                x_common = vals[:, 0] # Í≥µÌÜµ XÏ∂ï
                
                # ÎßåÏïΩ XÏ∂ïÏù¥ ÎπÑÏñ¥ÏûàÍ±∞ÎÇò Ïù¥ÏÉÅÌïòÎ©¥ Ïù∏Îç±Ïä§Î°ú ÎåÄÏ≤¥
                if np.all(np.isnan(x_common)):
                    x_common = np.arange(rows)

                for i in range(1, cols):
                    y = vals[:, i]
                    # Ïú†Ìö® Îç∞Ïù¥ÌÑ∞ Ï≤¥ÌÅ¨
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({
                            "x": x_common[mask],
                            "y": y[mask],
                            "name": f"Col-{i}" # Y1, Y2...
                        })
            
            # Case B: 1Ïó¥ Îç∞Ïù¥ÌÑ∞ (Y Only)
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({
                        "x": np.arange(len(y))[mask], 
                        "y": y[mask], 
                        "name": "Single"
                    })
                    
        except Exception as e:
            print(f"Extraction Error: {e}")
            
        return series_list

    # --- Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV26_1.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV26_1.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV26_1.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- Image Logic (V20.1 Fixed Logic) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV26_1.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line Tracking
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle, "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV26_1.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV26_1.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV26_1.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum data ({equipment}). Explain physical meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V26.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V26.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Bulldozer + Shared X Fix)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # V26 Bulldozer Parsing (Robust)
                    blocks = ScienceProcessorV26_1.bulldozer_parser(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Numbers Found"}]

                    res_list = []
                    for i, df in enumerate(blocks):
                        # V26.1 Shared X Logic
                        series_list = ScienceProcessorV26_1.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV26_1.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} (Blk{i+1}-{s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Invalid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV26_1.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





Î∏åÏù¥26

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V26 Í≥ºÌïô ÏóîÏßÑ (Multi-Mode Bulldozer)
# ==========================================
class ScienceProcessorV26:
    
    @staticmethod
    def bulldozer_parser(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V26 New] Îã§Ï§ë Í∏∏Ïù¥ Ìå®ÌÑ¥ Ïù∏Ïãù ÌååÏÑú
        - Ï§ÑÎßàÎã§ Ïà´ÏûêÏùò Í∞úÏàòÍ∞Ä Îã¨ÎùºÎèÑ (Í∞ÄÎ°ú Î∏îÎ°ù Í∏∏Ïù¥Í∞Ä Îã§Î•∏ Í≤ΩÏö∞ Îì±)
        - Í∞Å Í∏∏Ïù¥ Ìå®ÌÑ¥Î≥ÑÎ°ú Î≥ÑÎèÑÏùò DataFrameÏùÑ ÏÉùÏÑ±ÌïòÏó¨ Î™®Îëê ÏÇ¥Î†§ÎÉÖÎãàÎã§.
        """
        valid_dfs = []
        text_data = ""
        
        # 1. Excel -> Text
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 2. Regex Extraction
        numeric_rows = []
        num_pattern = re.compile(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?')
        
        for line in text_data.splitlines():
            nums = [float(n) for n in num_pattern.findall(line)]
            if nums: numeric_rows.append(nums)
            
        if not numeric_rows: return []

        # 3. [V26] Group by Length (Multi-Mode)
        # Í∏∏Ïù¥Î≥ÑÎ°ú ÌñâÏùÑ Î™®Ïùå (Ïòà: Í∏∏Ïù¥Í∞Ä 2Ïù∏ ÌñâÎì§, 4Ïù∏ ÌñâÎì§...)
        rows_by_length = {}
        for r in numeric_rows:
            L = len(r)
            if L not in rows_by_length: rows_by_length[L] = []
            rows_by_length[L].append(r)
            
        # Í∞Å Í∑∏Î£πÏùÑ Î≥ÑÎèÑÏùò DFÎ°ú ÎßåÎì¶
        for L, rows in rows_by_length.items():
            # Ïú†Ìö® Îç∞Ïù¥ÌÑ∞ ÏµúÏÜå Ï°∞Í±¥ (5Ìñâ Ïù¥ÏÉÅ, 1Ïó¥ Ïù¥ÏÉÅ)
            if len(rows) > 5 and L >= 1:
                try:
                    df = pd.DataFrame(rows)
                    valid_dfs.append(df)
                except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """DataFrameÏóêÏÑú (X, Y) Ïåç Ï∂îÏ∂ú (Shared Index Ïö∞ÏÑ†)"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # [Shared X Logic]
            # Í∏∞Î≥∏Ï†ÅÏúºÎ°ú Col 0ÏùÑ XÎ°ú, ÎÇòÎ®∏ÏßÄÎ•º YÎ°ú Î¥Ñ
            # (Ïù¥Î†áÍ≤å ÌïòÎ©¥ Pair Íµ¨Ï°∞Ïù∏ X1, Y1, X2, Y2 ÏóêÏÑúÎèÑ X1 vs Y1, X1 vs X2, X1 vs Y2 Ï≤òÎüº ÎÇòÏò§ÏßÄÎßå,
            #  X2 vs Y2Í∞Ä ÎàÑÎùΩÎêòÎäî Í≤ÉÎ≥¥Îã§Îäî Ï§ëÎ≥µ/Îã§ÏÜå Ïù¥ÏÉÅÌïú ÌîåÎ°ØÏù¥ ÎÇ´Îã§.
            #  ÌïòÏßÄÎßå Îçî ÎòëÎòëÌïòÍ≤å: ÏßùÏàò Ïó¥Ïùº Îïå PairÎ°ú Î≥º Í≤ÉÏù∏Í∞Ä?)
            
            # V26 Logic: Pair Ïö∞ÏÑ† (Í∞ÄÎ°ú Î∏îÎ°ù ÎåÄÏùë)
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x = vals[:, i]
                    y = vals[:, i+1]
                    # Îëò Îã§ Ïú†Ìö®Ìïú Íµ¨Í∞ÑÎßå Slice
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Set{i//2+1}"})
            
            # PairÍ∞Ä ÏïÑÎãàÍ±∞ÎÇò ÌôÄÏàò Ïó¥Ïù∏ Í≤ΩÏö∞: Shared X ÏãúÎèÑ
            # (ÏúÑ Pair Î°úÏßÅÏóêÏÑú Ïù¥ÎØ∏ Ï∂îÏ∂úÌñàÎã§Î©¥ Ï§ëÎ≥µÎê† Ïàò ÏûàÏúºÎÇò, Î¶¨Ïä§Ìä∏Í∞Ä ÎπÑÏóàÏùÑ ÎïåÎßå Ïã§ÌñâÌïòÎèÑÎ°ù Ìï®)
            if not series_list and cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Col{i}"})
                        
            # 1Ïó¥ Îç∞Ïù¥ÌÑ∞
            if not series_list and cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
                    
        except: pass
        return series_list

    # --- Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
            if len(s) > 51: s = savgol_filter(s, 51, 3)
            return s
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV26.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": [], "stats": f"Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV26.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV26.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- Image Logic (Same V20) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV26.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line Tracking
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
        
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV26.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV26.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV26.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V26")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V26 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (V26 Multi-Mode)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Bulldozer Parsing (List of DFs)
                    blocks = ScienceProcessorV26.bulldozer_parser(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Numbers"}]

                    res_list = []
                    for i, df in enumerate(blocks):
                        # 2. Series Extraction
                        series_list = ScienceProcessorV26.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV26.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} (Blk{i+1}-{s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Invalid"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV26.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





Î∏åÏù¥25.1

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V25.1 Í≥ºÌïô ÏóîÏßÑ (Shared X Logic)
# ==========================================
class ScienceProcessorV25_1:
    
    @staticmethod
    def bulldozer_parser(content: bytes, filename: str) -> List[pd.DataFrame]:
        """[V25] Text -> Numeric Block Extraction"""
        valid_dfs = []
        text_data = ""
        
        # 1. Excel -> CSV Text
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 2. Regex Numeric Extraction
        numeric_rows = []
        num_pattern = re.compile(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?')
        
        for line in text_data.splitlines():
            nums = [float(n) for n in num_pattern.findall(line)]
            if nums: numeric_rows.append(nums)
            
        if not numeric_rows: return []

        # 3. Reconstruct
        col_counts = [len(r) for r in numeric_rows]
        if not col_counts: return []
        most_common_len = Counter(col_counts).most_common(1)[0][0]
        clean_data = [r for r in numeric_rows if len(r) == most_common_len]
        
        if len(clean_data) < 5: return []

        try:
            df = pd.DataFrame(clean_data)
            valid_dfs.append(df)
        except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [V25.1 Fix] Shared X-Axis Logic (Í≥µÏú† XÏ∂ï Ïö∞ÏÑ† Ï†ÅÏö©)
        - ÏßùÏàò Ïó¥Ïù¥ÎùºÎèÑ Ìï®Î∂ÄÎ°ú PairÎ°ú Î¨∂ÏßÄ ÏïäÍ≥†, Ï≤´ Î≤àÏß∏ Ïó¥ÏùÑ Í≥µÌÜµ Ïù∏Îç±Ïä§Î°ú ÏÇ¨Ïö©
        """
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            
            if rows < 5: return []

            # [Logic Fix]
            # Î¨¥Ï°∞Í±¥ 1Ïó¥(Col 0)ÏùÑ XÏ∂ïÏúºÎ°ú Ïû°Í≥†, ÎÇòÎ®∏ÏßÄ Ïó¥Îì§ÏùÑ Í∞ÅÍ∞Å YÏ∂ïÏúºÎ°ú Ï≤òÎ¶¨
            # (ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠: ÏòàÏô∏ 2 - Ï≤´ Î≤àÏß∏ Ïó¥ÏùÄ Ïù∏Îç±Ïä§, Îëê Î≤àÏß∏ Ïù¥ÌõÑÎäî ÏÑúÎ∏å Î∏îÎ°ù)
            
            if cols >= 2:
                x_common = vals[:, 0] # Í≥µÌÜµ XÏ∂ï
                
                # XÏ∂ï Îç∞Ïù¥ÌÑ∞ Ïú†Ìö®ÏÑ± Ï≤¥ÌÅ¨
                if np.isnan(x_common).all():
                    # ÎßåÏïΩ XÏ∂ïÏù¥ Ï†ÑÎ∂Ä NaNÏù¥Î©¥(Ïù∏Îç±Ïä§ ÏóÜÏùå), Í∑∏ÎÉ• 0,1,2... Ïù∏Îç±Ïä§ ÏÉùÏÑ±
                    x_common = np.arange(rows)

                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    
                    # Îç∞Ïù¥ÌÑ∞Í∞Ä Ï∂©Î∂ÑÌï† ÎïåÎßå Ï∂îÍ∞Ä
                    if np.sum(mask) > 5:
                        series_list.append({
                            "x": x_common[mask],
                            "y": y[mask],
                            "name": f"Col-{i}" # Y1, Y2, Y3...
                        })
            
            # Ïª¨ÎüºÏù¥ 1Í∞úÎøêÏù¥Î©¥ YÏ∂ïÎßå ÏûàÎäî Í≤ÉÏúºÎ°ú Í∞ÑÏ£º
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({
                        "x": np.arange(len(y))[mask], 
                        "y": y[mask], 
                        "name": "Single"
                    })
                    
        except Exception as e:
            print(f"Extraction Error: {e}")
            
        return series_list

    # --- Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV25_1.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV25_1.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV25_1.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- Image Logic ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV25_1.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV25_1.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV25_1.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV25_1.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Brief interpretation in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V25.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V25.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Bulldozer + Shared X)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = ScienceProcessorV25_1.bulldozer_parser(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Numbers Found"}]

                    res_list = []
                    for i, df in enumerate(blocks):
                        # [V25.1] Shared X Logic Applied Here
                        series_list = ScienceProcessorV25_1.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV25_1.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                    "raw_context": f"{ctx}\nInterp: {interp}",
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Invalid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV25_1.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





Î∏åÏù¥25

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V25 Í≥ºÌïô ÏóîÏßÑ (Bulldozer Parser)
# ==========================================
class ScienceProcessorV25:
    
    @staticmethod
    def bulldozer_parser(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V25 New] ÌååÏùº ÎÇ¥Ïö©ÏùÑ ÌÖçÏä§Ìä∏Î°ú ÏùΩÏñ¥ Ïà´ÏûêÎßå Í∞ïÏ†ú Ï∂îÏ∂úÌïòÏó¨ Ïû¨Ï°∞Î¶Ω
        """
        valid_dfs = []
        text_data = ""
        
        # 1. ÏóëÏÖÄ/Î∞îÏù¥ÎÑàÎ¶¨ -> ÌÖçÏä§Ìä∏ Î≥ÄÌôò
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                # ÏóëÏÖÄÏùÄ ÏãúÌä∏Î≥ÑÎ°ú ÏùΩÏñ¥ÏÑú CSV ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò ÌõÑ Ï≤òÎ¶¨
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    # Î©îÎ™®Î¶¨ CSVÎ°ú Îç§ÌîÑ (Íµ¨Î∂ÑÏûê Í≥µÎ∞±)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        # ÌÖçÏä§Ìä∏Í∞Ä ÎπÑÏóàÏúºÎ©¥(CSVÍ±∞ÎÇò ÏóëÏÖÄ ÏùΩÍ∏∞ Ïã§Ìå®), ÏßÅÏ†ë ÎîîÏΩîÎî©
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: 
                    text_data = content.decode(enc)
                    break
                except: continue
        
        if not text_data: return []

        # 2. Î∂àÎèÑÏ†Ä ÌååÏã± (RegexÎ°ú Ïà´ÏûêÎßå Ï∂îÏ∂ú)
        numeric_rows = []
        
        # Ïà´Ïûê Ìå®ÌÑ¥ (Ï†ïÏàò, Ïã§Ïàò, ÏßÄÏàòÌòï)
        num_pattern = re.compile(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?')
        
        for line in text_data.splitlines():
            # ÎùºÏù∏ÏóêÏÑú Ïà´ÏûêÎßå Î™®Îëê Ï∞æÏùå
            nums = [float(n) for n in num_pattern.findall(line)]
            if nums: numeric_rows.append(nums)
            
        if not numeric_rows: return []

        # 3. Íµ¨Ï°∞Ìôî (Í∞ÄÏû• ÌùîÌïú Ïª¨Îüº Í∞úÏàò Ï∞æÍ∏∞)
        # Ïòà: Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌñâÏùÄ Ïà´ÏûêÍ∞Ä 1~2Í∞ú, Îç∞Ïù¥ÌÑ∞ ÌñâÏùÄ 2Í∞úÏùº Í≤ΩÏö∞ -> ModeÎäî 2
        col_counts = [len(r) for r in numeric_rows]
        if not col_counts: return []
        
        most_common_len = Counter(col_counts).most_common(1)[0][0]
        
        # Í∞ÄÏû• ÌùîÌïú Í∏∏Ïù¥Ïùò ÌñâÎßå Î™®ÏïÑÏÑú Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ±
        clean_data = [r for r in numeric_rows if len(r) == most_common_len]
        
        if len(clean_data) < 5: return [] # Îç∞Ïù¥ÌÑ∞ ÎÑàÎ¨¥ Ï†ÅÏùå

        # 4. DataFrame ÏÉùÏÑ± Î∞è Î∂ÑÌï†
        try:
            df = pd.DataFrame(clean_data)
            # Ïó¨Í∏∞ÏÑú ÏïÑÏùºÎûúÎìú Í∞êÏßÄÎÇò Ïª¨Îüº Ïä§Ï∫îÏùÑ ÏàòÌñâÌï† Ïàò ÏûàÏßÄÎßå,
            # Î∂àÎèÑÏ†Ä Î∞©ÏãùÏùÄ Î≥¥ÌÜµ ÌïòÎÇòÏùò ÌÅ∞ Îç©Ïñ¥Î¶¨Î•º ÎßåÎìúÎØÄÎ°ú Î∞îÎ°ú Î¶¨Ïä§Ìä∏Ïóê ÎÑ£Ïùå
            valid_dfs.append(df)
        except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """DataFrameÏóêÏÑú X,Y ÏãúÎ¶¨Ï¶à Ï∂îÏ∂ú (V24 Logic)"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            
            # Case A: Pair (X, Y, X, Y)
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x, y = vals[:, i], vals[:, i+1]
                    series_list.append({"x": x, "y": y, "name": f"Set{i//2+1}"})
            # Case B: Shared X (X, Y1, Y2)
            elif cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    series_list.append({"x": x, "y": vals[:, i], "name": f"Col{i}"})
            # Case C: Single (Y)
            elif cols == 1:
                y = vals[:, 0]
                series_list.append({"x": np.arange(len(y)), "y": y, "name": "Single"})
        except: pass
        return series_list

    # --- Spectrum & Image Logic (Existing V24) ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV25.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV25.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV25.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV25.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line Tracking
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV25.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV25.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV25.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum data ({equipment}). Explain physical meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V25")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V25 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Bulldozer)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Bulldozer Parsing
                    blocks = ScienceProcessorV25.bulldozer_parser(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Numbers Found"}]

                    res_list = []
                    for i, df in enumerate(blocks):
                        # 2. Series Extraction
                        series_list = ScienceProcessorV25.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV25.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} (Blk{i+1}-{s['name']})", "equipment": e,
                                    "raw_context": f"{ctx}\nInterp: {interp}",
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Invalid Data Structure"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV25.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





Î∏åÏù¥24.1

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V24.1 Í≥ºÌïô ÏóîÏßÑ (Global Strategy)
# ==========================================
class ScienceProcessorV24:
    
    # --- [A] Global Data Parser ---
    @staticmethod
    def parse_csv_global_strategy(content: bytes) -> List[Dict]:
        extracted_series = []
        df_global = pd.DataFrame()

        encodings = ['utf-8', 'cp949', 'latin1']
        separators = [None, ',', '\t', ';']
        
        loaded = False
        for enc in encodings:
            if loaded: break
            for sep in separators:
                try:
                    buf = io.BytesIO(content)
                    df_global = pd.read_csv(buf, sep=sep, encoding=enc, header=None, engine='python')
                    if df_global.shape[0] > 1 and df_global.shape[1] > 0:
                        loaded = True
                        break
                except: continue
        
        if not loaded or df_global.empty: return []

        try:
            df_num = df_global.apply(pd.to_numeric, errors='coerce')
            mask = ~df_num.isna().values
            labeled_array, num_features = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
            slices = find_objects(labeled_array)
            
            for i, sl in enumerate(slices):
                block = df_num.iloc[sl]
                if block.shape[0] < 3: continue
                block = block.dropna(how='all', axis=0).dropna(how='all', axis=1)
                vals = block.values
                cols = vals.shape[1]
                
                if cols >= 2 and cols % 2 == 0:
                    for k in range(0, cols, 2):
                        x = vals[:, k]
                        y = vals[:, k+1]
                        if np.sum(~np.isnan(x) & ~np.isnan(y)) > 3:
                            extracted_series.append({"x": x, "y": y, "name": f"Block{i+1}-Set{k//2+1}"})
                elif cols >= 2:
                    x = vals[:, 0]
                    for k in range(1, cols):
                        y = vals[:, k]
                        extracted_series.append({"x": x, "y": y, "name": f"Block{i+1}-Col{k}"})
                elif cols == 1:
                    y = vals[:, 0]
                    extracted_series.append({"x": np.arange(len(y)), "y": y, "name": f"Block{i+1}-Single"})
        except: pass
            
        return extracted_series

    # --- [B] Spectrum Processing ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV24.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV24.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV24.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, MaxY: {np.max(y):.1f}, Peaks: {len(peaks)}"

            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats_summary": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV24.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line Tracking
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV24.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV24.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV24.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    """[V24.1 Fix] Í∞ïÏ†ú ÌïúÍ∏Ä Ìï¥ÏÑù"""
    try:
        prompt = f"""
        You are an expert in {equipment} analysis.
        Analyze the following spectrum data stats (Peaks, etc).
        Explain the potential chemical/physical meaning of these peaks briefly in **Korean**.
        Data: {raw_context}
        """
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V24.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V24.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - Global Strategy
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # V24 New Core: Global Parse
                    series_list = ScienceProcessorV24.parse_csv_global_strategy(c)
                    
                    if not series_list: return [{"type": "error", "filename": n, "msg": "No Numeric Series Found"}]

                    res_list = []
                    for s in series_list:
                        try:
                            # Process Series
                            res = ScienceProcessorV24.process_spectrum(s['x'], s['y'], mode, g)
                            
                            step = max(1, len(s['x'])//100)
                            chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                            
                            ctx = f"Data: {s['name']}\nStats: {res.get('stats_summary','N/A')}"
                            interp = await interpret_spectrum_data(ctx, e)
                            
                            res_list.append({
                                "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                "raw_context": f"{ctx}\nInterp: {interp}", "chart_data": chart, "log": res["log"], "interpretation": interp
                            })
                        except: pass
                    return res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV24.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



V22 HTML

<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>AI Research Center V22</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        body { font-family: 'Inter', sans-serif; }
        .prose table { border-collapse: collapse; width: 100%; margin: 1em 0; }
        .prose th, .prose td { border: 1px solid #cbd5e1; padding: 8px; font-size: 0.9rem; }
        .prose th { background-color: #f1f5f9; }
        .loader { border: 3px solid #f3f3f3; border-top: 3px solid #6366f1; border-radius: 50%; width: 20px; height: 20px; animation: spin 1s linear infinite; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-slate-100 text-slate-800">
    <div id="app" class="min-h-screen p-6">
        <header class="max-w-7xl mx-auto mb-6 flex items-center gap-3">
            <div class="bg-indigo-600 p-2 rounded-lg shadow"><i data-lucide="microscope" class="w-6 h-6 text-white"></i></div>
            <div><h1 class="text-2xl font-bold">AI Research Center V22</h1><p class="text-xs text-slate-500">Universal Parse ‚Ä¢ Deep Insight</p></div>
        </header>

        <main class="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6">
            
            <!-- Staging Area -->
            <div class="lg:col-span-4 space-y-4">
                <div class="bg-white p-5 rounded-xl shadow-sm border border-slate-200">
                    <h2 class="font-bold mb-3 flex items-center gap-2"><i data-lucide="files" class="w-4 h-4"></i> Data Staging</h2>
                    
                    <div class="border-2 border-dashed border-slate-300 rounded-lg p-6 text-center hover:bg-indigo-50 cursor-pointer" @click="$refs.f.click()">
                        <input type="file" ref="f" multiple class="hidden" @change="addFiles">
                        <p class="text-sm font-semibold text-slate-600">Add Files</p>
                    </div>
                    <div v-if="stagedFiles.length" class="mt-4 space-y-3 max-h-[60vh] overflow-y-auto pr-1">
                        <div v-for="(item, i) in stagedFiles" :key="i" class="p-3 bg-slate-50 border rounded-lg text-sm">
                            <div class="flex justify-between items-center mb-2">
                                <span class="font-bold truncate w-2/3" :title="item.file.name">{{ item.file.name }}</span>
                                <button @click="removeFile(i)" class="text-red-400 hover:text-red-600"><i data-lucide="trash-2" class="w-4 h-4"></i></button>
                            </div>
                            <div class="grid grid-cols-1 gap-2">
                                <select v-model="item.equipment" class="w-full p-1.5 border rounded text-xs bg-white font-semibold text-indigo-700">
                                    <optgroup label="Spectroscopy">
                                        <option value="XPS">XPS</option>
                                        <option value="EELS">EELS</option>
                                        <option value="EDS">EDS / EDX</option>
                                        <option value="XRD">XRD</option>
                                        <option value="Raman">Raman</option>
                                        <option value="FT-IR">FT-IR</option>
                                        <option value="PL">PL</option>
                                    </optgroup>
                                    <optgroup label="Microscopy">
                                        <option value="TEM">TEM (Thin Film)</option>
                                        <option value="STEM">STEM (Thin Film)</option>
                                        <option value="SEM">SEM</option>
                                        <option value="AFM">AFM</option>
                                        <option value="Optical">Optical</option>
                                    </optgroup>
                                    <optgroup label="Literature">
                                        <option value="Document">Document (PDF/PPT)</option>
                                    </optgroup>
                                </select>
                                <select v-if="item.equipment !== 'Document'" v-model="item.mode" class="w-full p-1.5 border rounded text-xs bg-white text-indigo-700">
                                    <option value="Auto">‚ú® Auto Process</option>
                                    <option value="None">üö´ None (Raw)</option>
                                    <option value="AI-Adaptive">üß† AI-Adaptive</option>
                                </select>
                                <input v-if="item.equipment !== 'Document'" v-model="item.goal" type="text" placeholder="Goal (e.g. Fit peaks)" class="w-full p-1.5 border rounded text-xs">
                            </div>
                        </div>
                    </div>
                    <button @click="analyze" :disabled="isAnalyzing || stagedFiles.length===0" class="w-full mt-4 py-3 bg-indigo-600 text-white rounded-lg font-bold flex justify-center gap-2 shadow hover:bg-indigo-700 disabled:opacity-50">
                        <div v-if="isAnalyzing" class="loader"></div>
                        <span>Generate Report</span>
                    </button>
                </div>
            </div>

            <!-- Report Area -->
            <div class="lg:col-span-8">
                <div v-if="result" class="space-y-6 animate-fade-in">
                    
                    <!-- Tools -->
                    <div class="flex justify-between items-center bg-white p-2 rounded-xl shadow-sm border border-slate-200">
                        <div class="flex gap-2">
                            <button @click="setLang('ko')" :class="lang==='ko'?'bg-indigo-100 text-indigo-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">üá∞üá∑ ÌïúÍ∏Ä</button>
                            <button @click="setLang('en')" :class="lang==='en'?'bg-blue-100 text-blue-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">
                                <div v-if="isTranslating" class="w-3 h-3 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                                <span v-else>üá∫üá∏</span> English
                            </button>
                        </div>
                        <button @click="dlPDF" class="px-3 py-1.5 bg-slate-800 text-white text-xs rounded">PDF Export</button>
                    </div>

                    <div id="report-view" class="bg-white p-8 rounded-xl shadow-sm border border-slate-200">
                        
                        <!-- Synthesis -->
                        <section class="mb-10">
                            <h2 class="text-lg font-bold text-indigo-700 mb-3 border-b pb-1">1. Synthesis</h2>
                            <div class="prose prose-sm text-slate-700 max-w-none" v-html="md(displayReport)"></div>
                        </section>

                        <!-- Details -->
                        <section>
                            <h2 class="text-lg font-bold text-slate-800 mb-5 border-b pb-1">2. Data Evidence</h2>
                            
                            <div v-for="(item, idx) in result.results" :key="idx" class="mb-8 p-4 bg-slate-50 rounded-lg border break-inside-avoid">
                                <div class="flex items-center justify-between mb-3">
                                    <div class="flex items-center gap-2">
                                        <span class="px-2 py-0.5 bg-white border rounded text-[10px] font-bold uppercase text-slate-500">{{ item.equipment }}</span>
                                        <h3 class="font-bold text-sm">{{ item.filename }}</h3>
                                    </div>
                                    <!-- Toggle Button -->
                                    <button @click="item.showDocs = !item.showDocs" class="text-xs text-indigo-600 font-bold hover:underline flex items-center gap-1">
                                        <i :data-lucide="item.showDocs ? 'eye-off' : 'eye'" class="w-3 h-3"></i>
                                        {{ item.showDocs ? 'Hide Details' : 'Show Details' }}
                                    </button>
                                </div>

                                <!-- Spectrum Chart + Interpretation -->
                                <div v-if="item.chart_data" class="bg-white p-2 rounded border mb-3">
                                    <div :id="'chart-'+idx" class="w-full h-60"></div>
                                    
                                    <!-- [V22 New] Interpretation Box -->
                                    <div v-if="item.interpretation && item.showDocs" class="mt-3 p-3 bg-indigo-50 border border-indigo-100 rounded text-xs text-indigo-800">
                                        <h4 class="font-bold mb-1 flex items-center gap-1"><i data-lucide="lightbulb" class="w-3 h-3"></i> AI Interpretation</h4>
                                        <div class="prose prose-xs text-indigo-700" v-html="md(item.interpretation)"></div>
                                    </div>
                                </div>

                                <!-- Image Viewer -->
                                <div v-if="item.raw_b64" class="bg-white p-2 rounded border mb-3">
                                    <div class="flex gap-2 mb-2 text-xs justify-center">
                                        <button @click="item.view='proc'" :class="item.view!=='raw'?'font-bold text-indigo-600':''">Processed</button>
                                        <span class="text-slate-300">|</span>
                                        <button @click="item.view='raw'" :class="item.view==='raw'?'font-bold text-indigo-600':''">Original</button>
                                        <span class="text-slate-300" v-if="item.footer_b64">|</span>
                                        <button v-if="item.footer_b64" @click="item.view='footer'" :class="item.view==='footer'?'font-bold text-indigo-600':''">Info Bar</button>
                                    </div>
                                    <img v-if="item.view!=='footer'" :src="'data:image/jpeg;base64,' + (item.view==='raw' ? item.raw_b64 : item.proc_b64)" class="max-h-80 mx-auto object-contain bg-black">
                                    <img v-if="item.view==='footer'" :src="'data:image/jpeg;base64,' + item.footer_b64" class="max-h-24 mx-auto object-contain border mt-2">
                                </div>

                                <!-- Docs -->
                                <div v-if="item.showDocs">
                                    <div v-if="item.pages" class="grid grid-cols-1 gap-4">
                                        <div v-for="p in item.pages" :key="p.page_num" class="flex gap-3 bg-white p-3 rounded border">
                                            <img :src="'data:image/jpeg;base64,'+p.image_b64" class="w-24 object-contain border">
                                            <div class="text-xs prose" v-html="md(lang === 'en' ? (p.desc_en || p.desc) : p.desc)"></div>
                                        </div>
                                    </div>
                                    <div v-if="item.slides" class="space-y-4">
                                        <div v-for="s in item.slides" :key="s.slide_num" class="bg-white p-3 rounded border">
                                            <div class="text-xs font-bold text-indigo-600 mb-1">Slide {{s.slide_num}}</div>
                                            <div class="text-xs prose mb-2 whitespace-pre-wrap max-h-32 overflow-y-auto">{{ s.text }}</div>
                                            <div v-if="s.images.length" class="grid grid-cols-2 gap-2 border-t pt-2">
                                                <div v-for="(img, imx) in s.images" :key="imx" class="bg-slate-50 p-2">
                                                    <img :src="'data:image/jpeg;base64,'+img.b64" class="max-h-32 mx-auto object-contain bg-white">
                                                    <p class="text-[10px] text-slate-500 text-center mt-1">{{ img.desc }}</p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    
                                    <!-- Summary & Log -->
                                    <div v-if="item.summary" class="text-xs text-slate-600 mt-2 prose bg-slate-50 p-3 rounded" v-html="md(lang === 'en' ? (item.summary_en || item.summary) : item.summary)"></div>
                                    <div v-if="item.log && item.log.length > 0" class="mt-2 p-2 bg-gray-100 rounded border text-[10px] font-mono text-gray-600">
                                        <strong>‚öôÔ∏è Log:</strong> {{ item.log.join(' ‚Üí ') }}
                                    </div>
                                </div>

                            </div>
                        </section>
                    </div>
                </div>
            </div>
        </main>
    </div>
    <script>
        const { createApp, ref, computed, nextTick } = Vue;
        createApp({
            setup() {
                const stagedFiles = ref([]);
                const isAnalyzing = ref(false);
                const isTranslating = ref(false);
                const result = ref(null);
                const lang = ref('ko'); 
                const translatedReport = ref('');
                const md = (t) => marked.parse(t||'');

                const displayReport = computed(() => lang.value === 'en' && translatedReport.value ? translatedReport.value : (result.value ? result.value.final_report : ''));

                const addFiles = (e) => {
                    Array.from(e.target.files).forEach(f => {
                        let eq = 'General';
                        if(f.name.match(/\.(pdf|ppt|pptx)$/i)) eq = 'Document';
                        stagedFiles.value.push({ file: f, equipment: eq, goal: '', mode: 'Auto', view: 'proc', showDocs: true });
                    });
                    e.target.value = ''; 
                };
                const removeFile = (i) => stagedFiles.value.splice(i, 1);

                const analyze = async () => {
                    isAnalyzing.value = true;
                    lang.value = 'ko'; 
                    translatedReport.value = '';
                    const fd = new FormData();
                    const configs = {};
                    stagedFiles.value.forEach(item => {
                        fd.append('files', item.file);
                        configs[item.file.name] = { equipment: item.equipment, goal: item.goal, mode: item.mode };
                    });
                    fd.append('file_configs', JSON.stringify(configs));

                    try {
                        const res = await fetch('/api/analyze', { method: 'POST', body: fd });
                        const data = await res.json();
                        if(data.results) data.results.forEach(r => r.showDocs = true);
                        result.value = data;
                        await nextTick();
                        
                        data.results.forEach((item, i) => {
                            if(item.chart_data) {
                                const raw = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_raw), mode:'lines', name:'Raw', line:{color:'#cbd5e1', width:1} };
                                const proc = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_proc), mode:'lines', name:'Proc', line:{color:'#4f46e5', width:2} };
                                const base = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_base), mode:'lines', name:'Base', line:{color:'#f59e0b', width:1, dash:'dot'} };
                                Plotly.newPlot('chart-'+i, [raw, base, proc], {margin:{t:10,b:30,l:40,r:10}, showlegend:false}, {displayModeBar:false});
                            }
                        });
                        lucide.createIcons();
                    } catch(e) { alert(e); } 
                    finally { isAnalyzing.value = false; }
                };

                const setLang = async (target) => {
                    if (target === 'ko') { lang.value = 'ko'; return; }
                    if (target === 'en') {
                        if (translatedReport.value) { lang.value = 'en'; return; }
                        isTranslating.value = true;
                        try {
                            const res = await fetch('/api/translate', {
                                method: 'POST', headers: {'Content-Type': 'application/json'},
                                body: JSON.stringify({ text: result.value.final_report })
                            });
                            const data = await res.json();
                            translatedReport.value = data.translated;
                            lang.value = 'en';
                        } catch(e) { alert("Trans Error: " + e); }
                        finally { isTranslating.value = false; }
                    }
                };
                
                const dlPDF = () => html2pdf().set({ margin:10, filename:'V22_Report.pdf', image:{type:'jpeg',quality:0.98}, html2canvas:{scale:2}, jsPDF:{unit:'mm',format:'a4'} }).from(document.getElementById('report-view')).save();

                setTimeout(()=>lucide.createIcons(), 100);
                return { stagedFiles, isAnalyzing, isTranslating, result, lang, displayReport, addFiles, removeFile, analyze, md, dlPDF, setLang };
            }
        }).mount('#app');
    </script>
</body>
</html>







V21.1
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V22.1 Í≥ºÌïô ÏóîÏßÑ (Anti-Merge Added)
# ==========================================
class ScienceProcessorV22_1:
    
    # --- [A] Universal Data Parser ---
    @staticmethod
    def read_any_format(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V22.1 Update] ÏóëÏÖÄ Î≥ëÌï© ÏÖÄ(Merge Cell) ÎåÄÏùë Î°úÏßÅ Ï∂îÍ∞Ä
        ÏóëÏÖÄ Íµ¨Ï°∞Í∞Ä Î≥µÏû°ÌïòÎ©¥ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôòÌïòÏó¨ 'Data Hunter'ÏóêÍ≤å ÎÑòÍπÄ
        """
        dfs = []
        fname = filename.lower()
        
        # 1. Excel ÏóîÏßÑ ÏãúÎèÑ
        if fname.endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    # Ìó§Îçî ÏóÜÏù¥ ÏõêÎ≥∏ Í∑∏ÎåÄÎ°ú Î°úÎìú
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    
                    # [Check] Îç∞Ïù¥ÌÑ∞Í∞Ä Ïú†Ìö®ÌïúÍ∞Ä? (Ïà´ÏûêÍ∞Ä Ï∂©Î∂ÑÌïúÍ∞Ä?)
                    num_check = df.apply(pd.to_numeric, errors='coerce').notna().sum().sum()
                    
                    # Ïà´ÏûêÍ∞Ä ÎÑàÎ¨¥ Ï†ÅÍ±∞ÎÇò(Íµ¨Ï°∞ Íº¨ÏûÑ), Î≥ëÌï© ÏÖÄÎ°ú Ïù∏Ìï¥ NaNÏù¥ ÎÑàÎ¨¥ ÎßéÏúºÎ©¥
                    # ÌÖçÏä§Ìä∏ Î™®ÎìúÎ°ú Ï†ÑÌôò (CSVÎ°ú Î≥ÄÌôòÌï¥Î≤ÑÎ¶º)
                    if num_check < 10 or (df.isna().sum().sum() > df.size * 0.5):
                        print(f"Merge Cells Detected in {s}. Switching to Text Parser.")
                        # ÏóëÏÖÄ ÎÇ¥Ïö©ÏùÑ CSV ÌÖçÏä§Ìä∏Î°ú Îç§ÌîÑ (Î©îÎ™®Î¶¨ ÏÉÅÏóêÏÑú)
                        csv_buffer = io.StringIO()
                        df.to_csv(csv_buffer, index=False, header=False)
                        csv_content = csv_buffer.getvalue()
                        
                        # ÌÖçÏä§Ìä∏ ÌååÏÑú Ìò∏Ï∂ú (Robust CSV Reader Ïû¨ÏÇ¨Ïö©)
                        text_dfs = ScienceProcessorV22_1.read_robust_text(csv_content)
                        dfs.extend(text_dfs)
                    else:
                        # Ï†ïÏÉÅÏù¥Î©¥ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
                        if not df.empty: dfs.append(df)
                
                if dfs: return dfs
            except Exception as e:
                print(f"Excel Parse Error: {e}. Fallback to Text.")

        # 2. Text/CSV ÏóîÏßÑ ÏãúÎèÑ (Fallback & Non-Excel)
        return ScienceProcessorV22_1.read_robust_csv_bytes(content)

    @staticmethod
    def read_robust_text(text_content: str) -> List[pd.DataFrame]:
        """Î¨∏ÏûêÏó¥(String)ÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Î∏îÎ°ù Ï∂îÏ∂ú"""
        valid_dfs = []
        lines = text_content.splitlines()
        separators = [',', '\t', ';', '\s+']
        
        # Line Scan
        data_start = -1
        delimiter = None
        
        for i, line in enumerate(lines[:100]):
            for sep in separators:
                parts = line.split() if sep=='\s+' else line.split(sep)
                nums = sum(1 for p in parts if re.match(r'^-?\d+(\.\d+)?$', p.strip()))
                if nums >= 2:
                    data_start = i; delimiter = sep; break
            if data_start != -1: break
            
        if data_start != -1:
            try:
                data_str = "\n".join(lines[data_start:])
                sep_arg = '\s+' if delimiter=='\s+' else delimiter
                df = pd.read_csv(io.StringIO(data_str), sep=sep_arg, header=None, engine='python')
                df_clean = df.apply(pd.to_numeric, errors='coerce').dropna(how='all', axis=0).dropna(how='all', axis=1)
                if df_clean.shape[0] > 2: valid_dfs.append(df_clean.reset_index(drop=True))
            except: pass
        return valid_dfs

    @staticmethod
    def read_robust_csv_bytes(content: bytes) -> List[pd.DataFrame]:
        """Î∞îÏù¥Ìä∏(Bytes)ÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Î∏îÎ°ù Ï∂îÏ∂ú"""
        # Ïù∏ÏΩîÎî© ÏàúÌöåÌïòÎ©∞ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò ÌõÑ read_robust_text Ìò∏Ï∂ú
        for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
            try:
                text = content.decode(enc)
                dfs = ScienceProcessorV22_1.read_robust_text(text)
                if dfs: return dfs
            except: continue
        return []

    # --- [B] Hybrid Parser (V21) ---
    @staticmethod
    def parse_hybrid_block(df_block: pd.DataFrame) -> List[Dict]:
        extracted_series = []
        try:
            df_num = df_block.apply(pd.to_numeric, errors='coerce')
            is_meta_row = (df_block.notna() & df_num.isna()).any(axis=1)
            
            meta_text = " | ".join([x.strip() for x in df_block[is_meta_row].fillna('').values.flatten().astype(str) if x.strip()])
            data_rows = df_num[~is_meta_row].dropna(how='all')
            
            if data_rows.shape[0] < 5: return []
            vals = data_rows.values
            cols = vals.shape[1]
            
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x, y = vals[:, i], vals[:, i+1]
                    if np.sum(~np.isnan(x) & ~np.isnan(y)) > 5:
                        extracted_series.append({"x": x, "y": y, "name": f"Set-{i//2+1}", "meta": meta_text})
            elif cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    if np.sum(~np.isnan(x) & ~np.isnan(y)) > 5:
                        extracted_series.append({"x": x, "y": y, "name": f"Col-{i}", "meta": meta_text})
            elif cols == 1:
                y = vals[:, 0]
                extracted_series.append({"x": np.arange(len(y)), "y": y, "name": "Single", "meta": meta_text})
        except: pass
        return extracted_series

    # --- [C] Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
            if len(s) > 51: s = savgol_filter(s, 51, 3)
            return s
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            # Í≤∞Ï∏°Ïπò Ï†úÍ±∞
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if len(x) < 5: raise ValueError("Not enough data")

            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15
            if mode == "AI-Adaptive" and "noise" in goal.lower(): win = 31
            
            base = ScienceProcessorV22_1.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "stats": "Error"}

    # --- [D] Image Logic (V20) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV22_1.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            sh = int(h * 0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            idx = np.argmax(row_sums)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
        
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV22_1.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV22_1.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV22_1.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum data ({equipment}). Explain physical meaning. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V22.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V22.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Universal Parser)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Universal Read (Excel or Text)
                    dfs = ScienceProcessorV22_1.read_any_format(c, n)
                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    res_list = []
                    for i, df in enumerate(dfs):
                        # 2. Block Detection (Pandas Native)
                        blocks = detect_excel_blocks(df)
                        if not blocks: blocks = [df]

                        for block in blocks:
                            # 3. Hybrid Parsing
                            series_list = ScienceProcessorV22_1.parse_hybrid_block(block)
                            for s in series_list:
                                try:
                                    res = ScienceProcessorV22_1.process_spectrum(s['x'], s['y'], m, g)
                                    # Chart data
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    
                                    ctx = f"Data: {s['name']}\nMeta: {s.get('meta','')}\nStats: {res['stats']}"
                                    interp = await interpret_spectrum_data(ctx, e)
                                    
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                        "raw_context": f"{ctx}\nInterpretation: {interp}",
                                        "chart_data": chart, "log": res["log"], "interpretation": interp
                                    })
                                except: pass
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Series"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV22_1.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)






Î∏åÏù¥21.1
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V21.1 Í≥ºÌïô ÏóîÏßÑ
# ==========================================
class ScienceProcessorV21:
    
    # --- [A] Hybrid Data Parser (Strict Numeric) ---
    @staticmethod
    def parse_hybrid_block(df_block: pd.DataFrame) -> List[Dict]:
        """
        [V21.1 Fix] ÏóÑÍ≤©Ìïú Îç∞Ïù¥ÌÑ∞ Ìñâ ÌåêÎ≥Ñ
        - Î¨∏ÏûêÍ∞Ä ÌïòÎÇòÎùºÎèÑ ÏÑûÏó¨ ÏûàÏúºÎ©¥ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞Î°ú Î∂ÑÎ•ò
        - Ïò§ÏßÅ Ïà´Ïûê(ÎòêÎäî ÎπàÏπ∏)Îßå ÏûàÎäî ÌñâÎßå Îç∞Ïù¥ÌÑ∞Î°ú ÏÇ¨Ïö©
        """
        extracted_series = []
        try:
            # 1. Ïà´Ïûê Î≥ÄÌôò ÏãúÎèÑ (Î¨∏ÏûêÎäî NaNÏù¥ Îê®)
            df_num = df_block.apply(pd.to_numeric, errors='coerce')
            
            # 2. ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäîÎç∞ Ïà´ÏûêÎ°ú Î≥ÄÌôò Ïïà Îêú Í≤É Ï∞æÍ∏∞
            # notna() : ÏõêÎ≥∏Ïóê Í∞íÏù¥ ÏûàÏùå
            # df_num.isna() : Ïà´ÏûêÎ°ú Î≥ÄÌôò Ïã§Ìå®Ìï®
            # Ïù¥ Îëê Ï°∞Í±¥Ïù¥ ÎèôÏãúÏóê ÎßåÏ°±ÎêòÎ©¥ "Î¨∏ÏûêÏó¥Ïù¥ Ìè¨Ìï®Îêú ÏÖÄ"ÏûÑ
            has_text = df_block.notna() & df_num.isna()
            
            # Ìñâ Îã®ÏúÑÎ°ú "Î¨∏ÏûêÏó¥Ïù¥ ÌïòÎÇòÎùºÎèÑ ÏûàÎäîÏßÄ" ÌôïÏù∏
            is_metadata_row = has_text.any(axis=1)
            is_data_row = ~is_metadata_row # Î¨∏ÏûêÍ∞Ä ÌïòÎÇòÎèÑ ÏóÜÏñ¥Ïïº Îç∞Ïù¥ÌÑ∞ Ìñâ
            
            # 3. Extract Metadata
            meta_rows = df_block[is_metadata_row].fillna('')
            meta_text = ""
            if not meta_rows.empty:
                flat_text = meta_rows.astype(str).values.flatten()
                clean_text = [t.strip() for t in flat_text if t.strip() and t.lower() != 'nan']
                meta_text = " | ".join(clean_text)
                
            # 4. Extract Numeric Data
            data_rows = df_num[is_data_row].dropna(how='all')
            
            # Ïú†Ìö®ÏÑ± Í≤ÄÏÇ¨
            if data_rows.shape[0] < 5: return []
            
            vals = data_rows.values
            cols = vals.shape[1]
            
            # [Logic] Column Splitting
            if cols >= 2 and cols % 2 == 0: # ÏßùÏàò Ïó¥ (Pairs)
                for i in range(0, cols, 2):
                    x = vals[:, i]
                    y = vals[:, i+1]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        extracted_series.append({
                            "x": x[mask], "y": y[mask], 
                            "name": f"Set-{i//2+1}", "meta": meta_text
                        })
            elif cols >= 3: # Í≥µÏú† XÏ∂ï
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        extracted_series.append({
                            "x": x[mask], "y": y[mask], 
                            "name": f"Col-{i}", "meta": meta_text
                        })
            elif cols == 1: # Y Only
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    extracted_series.append({
                        "x": np.arange(len(y))[mask], "y": y[mask], 
                        "name": "Single", "meta": meta_text
                    })
                
        except Exception as e:
            print(f"Hybrid Parse Error: {e}")
            
        return extracted_series

    # --- [B] Spectrum ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
            if len(s) > 51: s = savgol_filter(s, 51, 3)
            return s
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV21.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV21.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV21.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic (V20) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV21.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Interface Tracking (Green Line)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
        
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV21.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV21.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, _, l = ScienceProcessorV21.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V21.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V21.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V21 Hybrid
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    dfs = []
                    if n.endswith(('.csv', '.txt')):
                        # Robust Read CSV
                        for enc in ['utf-8', 'cp949', 'latin1']:
                            if dfs: break
                            for sep in [None, ',', '\t', ';']:
                                try:
                                    # Ìó§Îçî Ìè¨Ìï® Ï†ÑÏ≤¥ ÏùΩÍ∏∞
                                    temp = pd.read_csv(io.BytesIO(c), sep=sep, encoding=enc, engine='python', header=None)
                                    if temp.shape[1] > 0: dfs = [temp]; break
                                except: pass
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        dfs = [pd.read_excel(xls, sheet_name=s, header=None) for s in xls.sheet_names]

                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    res_list = []
                    for i, df in enumerate(dfs):
                        # [V21] Island Detection -> Hybrid Parsing
                        blocks = detect_excel_blocks(df)
                        for b_idx, block in enumerate(blocks):
                            # Hybrid Parsing Call
                            series_list = ScienceProcessorV21.parse_hybrid_block(block)
                            
                            for s in series_list:
                                try:
                                    res = ScienceProcessorV21.process_spectrum(s['x'], s['y'], mode, g)
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    
                                    # Augment Context
                                    ctx = f"Data: {s['name']}\nMetadata: {s.get('meta','')}\nStats: {res['stats']}"
                                    
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                        "raw_context": ctx, "chart_data": chart, "log": res["log"]
                                    })
                                except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image (V20 Hybrid Crop)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV21.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



Î∏åÏù¥20.1
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V20.1 Í≥ºÌïô ÏóîÏßÑ (Logic Restored)
# ==========================================
class ScienceProcessor:
    
    # --- [A] Thin Film Engine (Fixed) ---
    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        h, w = img_rotated.shape[:2]
        if abs(angle_deg) < 1.0: return img_rotated
        cy, cx = h // 2, w // 2
        crop_h, crop_w = int(h * 0.7), int(w * 0.7)
        y1, x1 = max(0, cy - crop_h // 2), max(0, cx - crop_w // 2)
        return img_rotated[y1:min(h, y1+crop_h), x1:min(w, x1+crop_w)]

    @staticmethod
    def analyze_thin_film(img_gray):
        """
        [V20.1 Fix] Í≥ÑÎ©¥ Ï†ïÎ∞Ä Ï∂îÏ†Å (Green Line) Î∞è Í±∞Ïπ†Í∏∞ Î∂ÑÏÑù Î≥µÍµ¨
        """
        h_orig, w_orig = img_gray.shape
        log = []
        
        # 1. Auto-Rotation
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
            
        log.append(f"Auto-Rotation: {best_angle}¬∞")
        
        # 2. Process Image
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        h, w = img_crop.shape
        
        # 3. Global Interface Search (Red Line Candidates)
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces_approx, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        log.append(f"Global Layers: {len(interfaces_approx)}")
        
        # 4. Local Interface Tracking (Green Line Calculation)
        # Í∞Å Ïª¨ÎüºÎ≥ÑÎ°ú ÏµúÎåÄ Gradient ÏúÑÏπòÎ•º Ï∂îÏ†ÅÌïòÏó¨ Íµ¨Î∂àÍµ¨Î∂àÌïú ÏÑ†ÏùÑ Ï∞æÏùå
        interface_paths = [] 
        grad_img = np.abs(np.gradient(img_blur, axis=0)) # YÏ∂ï ÎØ∏Î∂Ñ
        
        for y_approx in interfaces_approx:
            path = []
            search_range = 15 # ÏÉÅÌïò 15ÌîΩÏÖÄ ÌÉêÏÉâ
            
            for x in range(w):
                y_start = max(0, y_approx - search_range)
                y_end = min(h, y_approx + search_range)
                
                local_col = grad_img[y_start:y_end, x]
                if len(local_col) == 0: 
                    path.append(y_approx)
                    continue
                    
                local_max_idx = np.argmax(local_col)
                path.append(y_start + local_max_idx)
            
            # ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Smoothing Path)
            if len(path) > 31:
                path_smooth = savgol_filter(path, window_length=31, polyorder=2)
            else:
                path_smooth = path
            interface_paths.append(path_smooth)

        # 5. Metrology & Visualization
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        roughness_stats = []
        thickness_stats = []
        
        # Draw Interfaces
        for idx, path in enumerate(interface_paths):
            x_axis = np.arange(len(path))
            
            # A. Roughness Calculation (Actual - Average)
            avg_y = np.mean(path)
            residuals = path - avg_y
            rms = np.sqrt(np.mean(residuals**2)) # Rq
            ra = np.mean(np.abs(residuals))      # Ra
            roughness_stats.append(f"Layer {idx+1}: Ra={ra:.2f}px, Rq={rms:.2f}px")
            
            # B. Draw Green Line (Actual Profile)
            pts = np.array([np.transpose(np.vstack([x_axis, path]))], np.int32)
            cv2.polylines(overlay, pts, isClosed=False, color=(0, 255, 0), thickness=2)
            
            # C. Draw Red Line (Average Level)
            cv2.line(overlay, (0, int(avg_y)), (w, int(avg_y)), (0, 0, 255), 1)

        # Calculate Thickness
        if len(interface_paths) >= 2:
            for i in range(len(interface_paths) - 1):
                diff = np.array(interface_paths[i+1]) - np.array(interface_paths[i])
                mean_t = np.mean(diff)
                std_t = np.std(diff)
                thickness_stats.append(f"L{i+1}-L{i+2}: {mean_t:.1f}¬±{std_t:.1f}px")
                
                # Draw Text on Image
                mid_y = int((np.mean(interface_paths[i]) + np.mean(interface_paths[i+1])) / 2)
                cv2.putText(overlay, f"{mean_t:.1f}px", (w//2, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        stats = {
            "type": "Thin Film Metrology",
            "angle": best_angle,
            "roughness": roughness_stats,
            "thickness": thickness_stats
        }
        
        return overlay, stats, log

    # --- [B] Image Detectors (Hawk Eye) ---
    @staticmethod
    def detect_embedded_metadata(img_array):
        """ÏûÑÎ≤†Îî© ÌÖçÏä§Ìä∏ Í∞êÏßÄ (Í≤ΩÍ≥ÑÏÑ† ÏóÜÏùÑ Îïå)"""
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h * 0.15)
            roi = img_array[h-roi_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            
            edges = cv2.Canny(gray, 50, 150)
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))
            dilated = cv2.dilate(edges, kernel, iterations=2)
            contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            min_y = roi_h
            found = False
            for c in contours:
                x, y, cw, ch = cv2.boundingRect(c)
                if cw > w * 0.05 and ch > 5 and (y + ch) > (roi_h * 0.7):
                    min_y = min(min_y, y)
                    found = True
            
            return (h - roi_h) + min_y - 10 if found else None
        except: return None

    @staticmethod
    def detect_footer_boundary(img_array):
        """Í≤ΩÍ≥ÑÏÑ†(Î∞ïÏä§) Í∞êÏßÄ"""
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    # --- [C] Spectrum & Data Processors ---
    @staticmethod
    def read_robust_csv(content: bytes) -> List[pd.DataFrame]:
        valid_dfs = []
        encodings = ['utf-8', 'cp949', 'latin1']
        separators = [None, ',', '\t', ';', ' ']
        
        for enc in encodings:
            if valid_dfs: break
            for sep in separators:
                try:
                    buf = io.BytesIO(content)
                    if sep is None: df = pd.read_csv(buf, sep=None, engine='python', encoding=enc, header=None)
                    else: df = pd.read_csv(buf, sep=sep, encoding=enc, header=None)
                    
                    df_num = df.apply(pd.to_numeric, errors='coerce')
                    df_clean = df_num.dropna(how='all', axis=0).dropna(how='all', axis=1)
                    if df_clean.shape[0] > 5 and df_clean.shape[1] >= 1:
                        valid_dfs.append(df_clean.reset_index(drop=True))
                        break
                except: continue
        return valid_dfs

    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            # Fitting logic (Simplified for length)
            fits = [] 
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits}
        except: return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": []}

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        
        # 1. Hybrid Smart Crop
        split_y = ScienceProcessor.detect_footer_boundary(img_raw)
        method = "Line Detect"
        if split_y is None:
            split_y = ScienceProcessor.detect_embedded_metadata(img_raw)
            method = "Embedded Detect"
            
        body_img, footer_img = img_raw, None
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append(f"Crop: {method}")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body_img)
        foot_b64 = to_b64(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": process_log}

        # 2. Analysis
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body_img.copy(); stats = {}
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, l = ScienceProcessor.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs); stats["type"] = "Atoms"
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts); stats["type"] = "Particles"

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": process_log}

# [4] Helper & Extract
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V20.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V20.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Literature", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Literature", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                        sheet_name = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=0, header=None)
                        blocks = detect_excel_blocks(df)
                        sheet_name = "Sheet1"

                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Valid Data"}]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            if not num_block.empty and num_block.shape[0] > 5:
                                if num_block.shape[1] == 1: x = np.arange(len(num_block)); y = num_block.iloc[:, 0].values
                                else: x = num_block.iloc[:, 0].values; y = num_block.iloc[:, 1].values
                                
                                res = ScienceProcessor.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                
                                stats_summary = f"Peaks: {len(res['peaks'])}"
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1})", "equipment": e,
                                    "raw_context": f"Spectrum {e}. {stats_summary}", 
                                    "chart_data": chart, "log": res["log"]
                                })
                        except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Fail"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)




Î∏åÏù¥20
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V20 Í≥ºÌïô ÏóîÏßÑ (Hawk Eye)
# ==========================================
class ScienceProcessor:
    
    # --- [New] Embedded Metadata Detector ---
    @staticmethod
    def detect_embedded_metadata(img_array):
        """
        [V20 New] Í≤ΩÍ≥ÑÏÑ†Ïù¥ ÏóÜÎäî ÏûÑÎ≤†Îî© ÌÖçÏä§Ìä∏/Ïä§ÏºÄÏùºÎ∞î Í∞êÏßÄ
        """
        try:
            h, w = img_array.shape[:2]
            # ÌïòÎã® 15%Îßå ÏßëÏ§ë Î∂ÑÏÑù
            roi_h = int(h * 0.15)
            roi = img_array[h-roi_h:, :]
            
            # Í∑∏Î†àÏù¥Ïä§ÏºÄÏùº Î≥ÄÌôò
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            
            # 1. Ïó£ÏßÄ Í≤ÄÏ∂ú (Í∏ÄÏûêÎäî Ïó£ÏßÄÍ∞Ä ÎßéÏùå)
            edges = cv2.Canny(gray, 50, 150)
            
            # 2. ÌåΩÏ∞Ω (Dilation) - Í∏ÄÏûêÎì§ÏùÑ ÌïòÎÇòÏùò Îç©Ïñ¥Î¶¨Î°ú Î≠âÏπ®
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3)) # Í∞ÄÎ°úÎ°ú Í∏¥ Ïª§ÎÑê
            dilated = cv2.dilate(edges, kernel, iterations=2)
            
            # 3. Ïª®Ìà¨Ïñ¥(Îç©Ïñ¥Î¶¨) Ï∞æÍ∏∞
            contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            min_y_local = roi_h # Ï¥àÍ∏∞Í∞í: Î∞îÎã•
            found_candidate = False
            
            for c in contours:
                x, y, cw, ch = cv2.boundingRect(c)
                # ÎÑàÎ¨¥ ÏûëÏùÄ ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞, ÎÑàÎ¨¥ ÏúÑÏóê ÏûàÎäî Í≤É Ï†úÍ±∞
                if cw > w * 0.05 and ch > 5: # ÎÑàÎπÑÍ∞Ä 5% Ïù¥ÏÉÅÏù∏ Îç©Ïñ¥Î¶¨Îßå
                    # Îç©Ïñ¥Î¶¨Í∞Ä Î∞îÎã• Î∂ÄÍ∑ºÏóê ÏûàÏñ¥Ïïº Ìï®
                    if (y + ch) > (roi_h * 0.7):
                        min_y_local = min(min_y_local, y)
                        found_candidate = True
            
            if found_candidate:
                # Ï∞æÏùÄ Îç©Ïñ¥Î¶¨Ïùò ÏúóÎ∂ÄÎ∂Ñ + Ïó¨Ïú† Í≥µÍ∞Ñ(Padding 10px)
                cut_y = (h - roi_h) + min_y_local - 10
                return cut_y
                
            return None
        except: return None

    @staticmethod
    def detect_footer_boundary(img_array):
        """Í∏∞Ï°¥ Î∞©Ïãù: Î™ÖÌôïÌïú Í≤ΩÍ≥ÑÏÑ†(Î∞ïÏä§) Í∞êÏßÄ"""
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    # --- Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            # Fitting Logic Omitted for brevity but assumed present
            fits = []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats_summary": stats_txt}
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": [], "stats_summary": "Error"}

    # --- Image Logic ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        # Auto-Rotation
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Angle: {best_angle}")
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        
        # [V20 Hybrid Smart Crop]
        # 1. Try Line Detection first (Strong Box)
        split_y = ScienceProcessor.detect_footer_boundary(img_raw)
        crop_method = "Line Detect"
        
        # 2. If no line, try Embedded Text Detection
        if split_y is None:
            split_y = ScienceProcessor.detect_embedded_metadata(img_raw)
            crop_method = "Embedded Text Detect"
            
        body_img, footer_img = img_raw, None
        
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append(f"Smart Crop ({crop_method}): Footer Removed")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body_img); foot_b64 = to_b64(footer_img) if footer_img is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": process_log, "summary": "Raw"}
        
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body_img.copy(); stats = {}; summary = ""; l = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, summary, l = ScienceProcessor.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "summary": summary, "log": process_log}

    # --- [E] Robust Data Parser ---
    @staticmethod
    def read_robust_csv(content: bytes) -> List[pd.DataFrame]:
        valid_dfs = []
        encodings = ['utf-8', 'cp949', 'latin1']
        separators = [None, ',', '\t', ';', ' ']
        
        # Text decoding first
        text_content = ""
        for enc in encodings:
            try: text_content = content.decode(enc); break
            except: continue
        
        if not text_content: return []

        # Line scan for numeric blocks
        lines = text_content.splitlines()
        data_start = -1; delimiter = None
        
        for i, line in enumerate(lines[:100]):
            for sep in separators:
                parts = line.split() if sep==' ' else line.split(sep)
                # Count numbers
                nums = sum(1 for p in parts if re.match(r'^-?\d+(\.\d+)?$', p.strip()))
                if nums >= 2:
                    if i+1 < len(lines): # check next line
                        nxt = lines[i+1].split() if sep==' ' else lines[i+1].split(sep)
                        if len(nxt) == len(parts):
                            data_start = i; delimiter = sep; break
            if data_start != -1: break
            
        if data_start != -1:
            try:
                data_str = "\n".join(lines[data_start:])
                df = pd.read_csv(io.StringIO(data_str), sep=delimiter, header=None, engine='python')
                df = df.apply(pd.to_numeric, errors='coerce').dropna(how='all')
                if df.shape[0] > 2: valid_dfs.append(df)
            except: pass
            
        if not valid_dfs: # Fallback
            try:
                df = pd.read_csv(io.BytesIO(content), sep=None, engine='python', header=None)
                df = df.apply(pd.to_numeric, errors='coerce').dropna(how='all')
                if df.shape[0]>5: valid_dfs.append(df)
            except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        series_list = []
        try:
            df_num = df.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
            vals = df_num.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Even Pairs
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x, y = vals[:, i], vals[:, i+1]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5: series_list.append({"x": x[mask], "y": y[mask], "name": f"Set{i//2+1}"})
            # Shared X
            elif cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]; mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5: series_list.append({"x": x[mask], "y": y[mask], "name": f"Col{i}"})
            # Single Y
            elif cols == 1:
                y = vals[:, 0]; mask = ~np.isnan(y)
                if np.sum(mask) > 5: series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V20")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V20 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    # ... (PPT Logic V17Í≥º ÎèôÏùº) ...
                    return {"type": "doc", "filename": n, "equipment": "Lit", "raw_context": "Doc", "summary": "Processed"}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V19.5 Logic
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        for s in xls.sheet_names:
                            df = pd.read_excel(xls, sheet_name=s, header=None)
                            blocks.append(df)

                    res_list = []
                    for df in blocks:
                        series = ScienceProcessor.extract_series_from_df(df)
                        for s in series:
                            try:
                                res = ScienceProcessor.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": n, "equipment": e,
                                    "raw_context": f"Peaks: {len(res['peaks'])}",
                                    "chart_data": chart, "log": res["log"]
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image - V20 Logic
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





Î∏åÏù¥19
import os
import io
import asyncio
import base64
import json
import re
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V19 Í≥ºÌïô ÏóîÏßÑ (Robust & Simple)
# ==========================================
class ScienceProcessorV19:
    
    # --- [A] New Data Parser (Pandas Native) ---
    @staticmethod
    def parse_data_robust(df: pd.DataFrame) -> List[Dict]:
        """
        [V19] Î≥µÏû°Ìïú Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ ÏóÜÏù¥ PandasÎ°úÎßå Îç∞Ïù¥ÌÑ∞ Î∏îÎ°ùÍ≥º ÏåçÏùÑ Ï∂îÏ∂ú
        """
        extracted_series = []
        
        try:
            # 1. Ïà´ÏûêÎßå ÎÇ®Í∏∞Í∏∞ (Î¨∏ÏûêÏó¥ -> NaN)
            df_num = df.apply(pd.to_numeric, errors='coerce')
            
            # 2. Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî ÌñâÎßå ÎÇ®Í∏∞Í∏∞ (Îπà Ï§Ñ Ï†úÍ±∞)
            # ÎåÄÏö©Îüâ ÌååÏùº(6000Ìñâ)ÎèÑ Ïó¨Í∏∞ÏÑú ÍπîÎÅîÌïòÍ≤å Ï†ïÎ¶¨Îê®
            df_clean = df_num.dropna(how='all') 
            
            if df_clean.empty: return []
            
            # 3. Îπà ÌñâÏùÑ Í∏∞Ï§ÄÏúºÎ°ú Î∏îÎ°ù ÎÇòÎàÑÍ∏∞ (Pandas Groupby Ïù¥Ïö©)
            # Ïù∏Îç±Ïä§Í∞Ä Ïó∞ÏÜçÏ†ÅÏù¥ÏßÄ ÏïäÏùÄ Íµ¨Í∞ÑÏùÑ Ï∞æÏïÑÏÑú Í∑∏Î£πÌïë
            # (ÏõêÎûò ÏóëÏÖÄÏóêÏÑú Îñ®Ïñ¥Ï†∏ ÏûàÎçò ÌëúÎì§Ïù¥ Ïó¨Í∏∞ÏÑú Î∂ÑÎ¶¨Îê®)
            df_clean['group'] = (df_clean.index.to_series().diff() > 1).cumsum()
            
            for _, group in df_clean.groupby('group'):
                # group ÎÇ¥ÏóêÏÑú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÎäî Ïó¥(Column) Ï†úÍ±∞
                block = group.drop(columns=['group']).dropna(how='all', axis=1)
                
                if block.shape[0] < 5: continue # ÎÑàÎ¨¥ ÏßßÏúºÎ©¥ Ìå®Ïä§
                
                vals = block.values
                cols = vals.shape[1]
                
                # [Logic] Ïª¨Îüº Ïåç Ï∂îÏ∂ú
                # Case A: ÏßùÏàò Ïª¨Îüº (X1, Y1, X2, Y2 ...) -> "Ï∂ï|Îç∞Ïù¥ÌÑ∞|Ï∂ï|Îç∞Ïù¥ÌÑ∞" ÎåÄÏùë
                if cols >= 2 and cols % 2 == 0:
                    for i in range(0, cols, 2):
                        x = vals[:, i]
                        y = vals[:, i+1]
                        # Ïú†Ìö® Îç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅ
                        mask = ~np.isnan(x) & ~np.isnan(y)
                        if np.sum(mask) > 5:
                            extracted_series.append({
                                "x": x[mask], "y": y[mask], 
                                "name": f"Block{_}-Set{i//2+1}"
                            })
                            
                # Case B: ÌôÄÏàò Ïª¨Îüº or 1Ïó¥ (Index, Y1, Y2... or Y only)
                else:
                    x = vals[:, 0]
                    # Ï≤´ Ïó¥Ïù¥ XÎùºÍ≥† Í∞ÄÏ†ïÌïòÍ≥† ÎÇòÎ®∏ÏßÄ YÎì§ Îß§Ïπ≠
                    if cols > 1:
                        for i in range(1, cols):
                            y = vals[:, i]
                            mask = ~np.isnan(x) & ~np.isnan(y)
                            if np.sum(mask) > 5:
                                extracted_series.append({
                                    "x": x[mask], "y": y[mask], 
                                    "name": f"Block{_}-Col{i}"
                                })
                    # 1Ïó¥Îßå ÏûàÏúºÎ©¥ IndexÎ•º XÎ°ú
                    elif cols == 1:
                        y = vals[:, 0]
                        mask = ~np.isnan(y)
                        if np.sum(mask) > 5:
                            extracted_series.append({
                                "x": np.arange(len(y))[mask], "y": y[mask], 
                                "name": f"Block{_}-Single"
                            })
                            
        except Exception as e:
            print(f"Parser Error: {e}")
            
        return extracted_series

    # --- [B] Spectrum Processing ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): 
        return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV19.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            
            # Mode: None
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {
                    "x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y),
                    "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks],
                    "log": ["Raw Data"], "fits": [], 
                    "stats_summary": f"Raw Data. Peaks: {len(peaks)}"
                }

            # Mode: Auto / AI-Adaptive
            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            # Baseline & Smoothing
            base = ScienceProcessorV19.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win:
                y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV19.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, MaxY: {np.max(y):.1f}, Peaks: {len(peaks)}"

            return {
                "x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base,
                "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks],
                "log": ["Processed"], "fits": fits, "stats_summary": stats_txt
            }
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": [], "stats_summary": "Error"}

    # --- [C] Image Logic (V15 Same) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        # Auto-Rotation
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV19.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        summary = f"Thin Film: {len(interfaces)} layers. Angle: {best_angle}. Avg Thickness: {np.mean(thk) if thk else 0:.1f}px"
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, summary, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel)), axis=1)
            if np.max(row_sums) < (w*30): return None
            idx = np.argmax(row_sums)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV19.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": [], "summary": "Raw Image"}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; summary = ""; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, summary, log = ScienceProcessorV19.analyze_thin_film(gray)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            cnt = 0
            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                cnt = len(blobs); stats["type"] = "Atoms"
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                cnt = len(cnts); stats["type"] = "Particles"
            
            stats["count"] = cnt
            summary = f"Detected {cnt} {stats.get('type','features')}."

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "summary": summary, "log": log}

# [4] Helper
async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V19")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V19 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V19 Robust Parser
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    dfs = []
                    # 1. Load Data
                    if n.endswith(('.csv', '.txt')):
                        for enc in ['utf-8', 'cp949', 'latin1']:
                            if dfs: break
                            for sep in [None, ',', '\t']:
                                try:
                                    temp = pd.read_csv(io.BytesIO(c), sep=sep, encoding=enc, engine='python', header=None)
                                    if temp.shape[1] > 0: dfs = [temp]; break
                                except: pass
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        dfs = [pd.read_excel(xls, sheet_name=s, header=None) for s in xls.sheet_names]

                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    # 2. Extract & Process
                    res_list = []
                    for i, df in enumerate(dfs):
                        series = ScienceProcessorV19.parse_data_robust(df)
                        for s in series:
                            res = ScienceProcessorV19.process_spectrum(s['x'], s['y'], mode, g)
                            # Downsample for Chart
                            step = max(1, len(s['x'])//100)
                            chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                            
                            res_list.append({
                                "type": "spectrum", "filename": f"{n} ({s['name']})", 
                                "equipment": e, 
                                "raw_context": f"Spectrum {s['name']}: {res['stats_summary']}",
                                "chart_data": chart, "log": res["log"], "fits": res["fits"]
                            })
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Numeric Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV19.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('summary','')}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)




Î∏åÏù¥18.1
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V18.1 Í≥ºÌïô ÏóîÏßÑ
# ==========================================
class ScienceProcessor:
    
    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [Optimization] Ï†ÑÏ≤¥ ÏãúÌä∏ÏóêÏÑú (X,Y) Ïåç Í≥†ÏÜç Ï∂îÏ∂ú
        """
        series_list = []
        try:
            # 1. Ï†ÑÏ≤¥ Ïà´Ïûê Î≥ÄÌôò (Coerce errors)
            # ÎåÄÏö©Îüâ Ï≤òÎ¶¨ Ïãú Ïó¨Í∏∞ÏÑú ÏãúÍ∞ÑÏù¥ Ï°∞Í∏à Í±∏Î¶¥ Ïàò ÏûàÏßÄÎßå, label() Î≥¥Îã® Îπ†Î¶Ñ
            df_num = df.apply(pd.to_numeric, errors='coerce')
            
            # 2. Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎäî Ìñâ/Ïó¥Îßå ÎÇ®Í∏∞Í∏∞ (Trim)
            df_clean = df_num.dropna(how='all', axis=0).dropna(how='all', axis=1)
            
            if df_clean.empty: return []
            
            vals = df_clean.values
            rows, cols = vals.shape
            
            if rows < 5: return [] 

            # A. ÏßùÏàò Ïª¨Îüº Íµ¨Ï°∞ (X, Y, X, Y ...)
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x = vals[:, i]
                    y = vals[:, i+1]
                    # Ïú†Ìö® Îç∞Ïù¥ÌÑ∞(NaN ÏïÑÎãò) ÌïÑÌÑ∞ÎßÅ
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Set {i//2+1}"})
            
            # B. Í≥µÏú† XÏ∂ï Íµ¨Ï°∞ (X, Y1, Y2 ...) - AÏóêÏÑú Î™ª Ï∞æÏïòÏùÑ Îïå ÏãúÎèÑ
            if not series_list and cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Col {i}"})
            
            # C. 1Ïó¥ Îç∞Ïù¥ÌÑ∞ (Y only)
            if not series_list and cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    x = np.arange(len(y))[mask] # Index as X
                    series_list.append({"x": x, "y": y[mask], "name": "Single"})
                    
        except Exception as e:
            print(f"Extraction Error: {e}")
            
        return series_list

    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            # Downsampling for Chart (Ï§ëÏöî: 6000Í∞ú Îã§ Í∑∏Î¶¨Î©¥ ÎäêÎ¶º)
            # ÏõêÎ≥∏ Î∂ÑÏÑùÏùÄ Ï†ÑÏ≤¥Î°ú ÌïòÎêò, Ï∞®Ìä∏Ïö©ÏùÄ Ï§ÑÏûÑ (Ïó¨Í∏∞ÏÑ† Î∂ÑÏÑùÏö© Î¶¨ÌÑ¥)
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            # Stats Summary for LLM
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, MaxY: {np.max(y):.1f}, Peaks: {len(peaks)}"
            
            return {
                "x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, 
                "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], 
                "log": ["Processed"], "fits": [], "stats_summary": stats_txt
            }
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": [], "stats_summary": "Error"}

    # ... Image Logic (Same as V15.5) ...
    @staticmethod
    def detect_footer_boundary(img):
        try:
            h, w = img.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img[h-sh:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        layers, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        ov = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y in layers: cv2.line(ov, (0, y), (ov.shape[1], y), (0, 0, 255), 2)
        thk = np.diff(layers).tolist() if len(layers)>=2 else []
        summary = f"Thin Film: {len(layers)} layers. Angle: {best_angle}. Avg Thickness: {np.mean(thk) if thk else 0:.1f}px"
        return ov, {"type":"Thin Film", "layers":len(layers), "angle":best_angle}, summary, log

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessor.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "summary": "Raw Image", "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; summary = ""; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, summary, log = ScienceProcessor.analyze_thin_film(gray)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            cnt = 0
            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                cnt = len(blobs); stats["type"] = "Atoms"
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                cnt = len(cnts); stats["type"] = "Particles"
            
            stats["count"] = cnt
            summary = f"Detected {cnt} {stats.get('type','features')}."

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "summary": summary, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    # Î©îÎ™®Î¶¨ Ï†àÏïΩÏùÑ ÏúÑÌï¥ boolean maskÎßå ÏÇ¨Ïö©
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V18.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V18.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                # (V15.5 Logic Same)
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - ‚òÖ Optimized Strategy
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    res_list = []
                    sheet_name = "Data"
                    
                    # 1. CSV Handler
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                        for i, df in enumerate(blocks):
                            # CSVÎäî Î≥¥ÌÜµ Series Íµ¨Ï°∞Í∞Ä Î™ÖÌôïÌï®
                            series = ScienceProcessor.extract_series_from_df(df)
                            for s in series:
                                res = ScienceProcessor.process_spectrum(s['x'], s['y'], mode, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                    "raw_context": f"Stats: {res.get('stats_summary', 'N/A')}",
                                    "chart_data": chart, "log": res["log"]
                                })
                    
                    # 2. Excel Handler (Optimized)
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        for sname in xls.sheet_names:
                            df = pd.read_excel(xls, sheet_name=sname, header=None)
                            
                            # Strategy A: Fast Column Scan (for 6000+ rows)
                            series = ScienceProcessor.extract_series_from_df(df)
                            if series:
                                for s in series:
                                    res = ScienceProcessor.process_spectrum(s['x'], s['y'], mode, g)
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({sname}-{s['name']})", "equipment": e,
                                        "raw_context": f"Stats: {res.get('stats_summary', 'N/A')}",
                                        "chart_data": chart, "log": res["log"]
                                    })
                            else:
                                # Strategy B: Island Detection (Fallback)
                                blocks = detect_excel_blocks(df)
                                for i, block in enumerate(blocks):
                                    # ... (Same Block Logic) ...
                                    # (Í∞ÑÏÜåÌôîÎ•º ÏúÑÌï¥ ÏÉùÎûµ, ÏúÑ extract_seriesÍ∞Ä Ïã§Ìå®ÌñàÏùÑ ÎïåÎßå Ïã§ÌñâÎê®)
                                    pass

                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('summary','')}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{})
                    }
                except: return {"type": "error", "filename": n, "msg": "Error"}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    # Sanitize
    final_results = sanitize_json(final_results)

    # Synthesis
    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
            
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





Î∏åÏù¥18
import os
import io
import asyncio
import base64
import json
import re
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- [V18 Fix] JSON Sanitizer ---
def sanitize_json(obj):
    """JSON Ï†ÑÏÜ° Ï†Ñ NaN/Inf Ï≤≠ÏÜå"""
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0 # None ÎåÄÏã† 0.0ÏúºÎ°ú Ï≤òÎ¶¨Ìï¥ ÌîåÎ°Ø ÏóêÎü¨ Î∞©ÏßÄ
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V18 Í≥ºÌïô ÏóîÏßÑ
# ==========================================
class ScienceProcessorV18:
    
    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [V18 New] ÏóëÏÖÄ/CSV Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ ÏûêÎèô ÌåêÎ≥Ñ Î∞è Ï∂îÏ∂ú
        Returns: List of {'x': array, 'y': array, 'name': str}
        """
        series_list = []
        try:
            # 1. Ïà´ÏûêÎßå ÎÇ®Í∏∞Í∏∞
            df_num = df.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
            if df_num.empty: return []
            
            vals = df_num.values
            cols = vals.shape[1]
            rows = vals.shape[0]
            
            if rows < 5: return [] # ÎÑàÎ¨¥ ÏßßÏúºÎ©¥ Ìå®Ïä§

            # Case A: ÏßùÏàò Ïª¨Îüº (X, Y), (X, Y) ...
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x = vals[:, i]
                    y = vals[:, i+1]
                    # Ïú†Ìö® Îç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅ (NaN Ï†úÍ±∞)
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Set {i//2+1}"})
            
            # Case B: ÌôÄÏàò Ïª¨Îüº or Í≥µÏú† XÏ∂ï (X, Y1, Y2 ...)
            # (ÏúÑ Case AÏóêÏÑú Í±∏Îü¨ÏßÄÏßÄ ÏïäÏùÄ Í≤ΩÏö∞, ÌòπÏùÄ ÏÇ¨Ïö©ÏûêÍ∞Ä Î™ÖÏãúÏ†ÅÏúºÎ°ú Í≥µÏú†Ï∂ïÏùÑ ÏõêÌï† Îïå)
            # Ïó¨Í∏∞ÏÑúÎäî ÏïàÏ†ÑÌïòÍ≤å: ÎßåÏïΩ Case AÎ°ú ÌïòÎÇòÎèÑ Î™ª Ï∞æÏïòÎã§Î©¥ Case B ÏãúÎèÑ
            if not series_list and cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Col {i}"})
            
            # Case C: 1Ïó¥ Îç∞Ïù¥ÌÑ∞ (Y only)
            if not series_list and cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    x = np.arange(len(y))[mask]
                    series_list.append({"x": x, "y": y[mask], "name": "Single Series"})
                    
        except Exception as e:
            print(f"Extraction Error: {e}")
            
        return series_list

    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            # Parameters
            win = 15
            do_fit = False
            
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            # Process
            if mode == "None":
                y_base = np.zeros_like(y)
                y_proc = y
            else:
                y_base = ScienceProcessorV18.simple_baseline(y)
                y_proc = np.maximum(y - y_base, 0)
                if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            # Peaks
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            # [V18] LLMÏùÑ ÏúÑÌïú ÌÜµÍ≥Ñ ÏöîÏïΩ ÏÉùÏÑ± (Raw Text ÎåÄÏã† ÏÇ¨Ïö©)
            stats_summary = (
                f"Range X: {np.min(x):.2f}~{np.max(x):.2f}, "
                f"Max Y: {np.max(y_proc):.2f}, "
                f"Detected Peaks: {len(peaks)} points. "
                f"Top Peaks at X: {[float(f'{x[p]:.1f}') for p in peaks[:5]]}"
            )

            return {
                "x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": y_base,
                "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks],
                "log": ["Processed"], 
                "stats_summary": stats_summary # LLMÏö© ÌÖçÏä§Ìä∏
            }
        except Exception as e:
            return {"x": [], "stats_summary": f"Error: {e}", "log": ["Fail"]}

    # --- Image Logic (Same as V15.5) ---
    @staticmethod
    def detect_footer_boundary(img):
        try:
            h, w = img.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img[h-sh:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def analyze_thin_film(img_gray):
        # (V15 Thin Film Logic)
        h, w = img_gray.shape
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        
        # Valid Crop
        cy, cx = img_rot.shape[0]//2, img_rot.shape[1]//2
        ch, cw = int(h*0.7), int(w*0.7)
        img_crop = img_rot[max(0, cy-ch//2):min(img_rot.shape[0], cy+ch//2), max(0, cx-cw//2):min(img_rot.shape[1], cx+cw//2)]
        
        img_blur = gaussian_filter(img_crop, 3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        layers, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        ov = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y in layers: cv2.line(ov, (0, y), (ov.shape[1], y), (0, 0, 255), 2)
        
        # LLMÏö© ÏöîÏïΩ ÌÖçÏä§Ìä∏ ÏÉùÏÑ±
        thk = np.diff(layers).tolist() if len(layers)>=2 else []
        summary = f"Thin Film Analysis: Rotation {best_angle}deg. Found {len(layers)} interfaces. Avg Thickness: {np.mean(thk) if thk else 0:.2f} px."
        
        return ov, {"type":"Thin Film", "angle":best_angle, "layers":len(layers)}, summary

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV18.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        b_raw = to_b64(body); b_foot = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": b_raw, "proc_b64": b_raw, "footer_b64": b_foot, "stats": {"info": "Raw"}, "summary": "Raw Image"}

        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; summary = ""
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, summary = ScienceProcessorV18.analyze_thin_film(gray)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            cnt = 0
            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                cnt = len(blobs); stats["type"] = "Atoms"
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                cnt = len(cnts); stats["type"] = "Particles"
            
            stats["count"] = cnt
            summary = f"Detected {cnt} {stats.get('type','features')}."

        return {"raw_b64": b_raw, "proc_b64": to_b64(overlay), "footer_b64": b_foot, "stats": stats, "summary": summary}

# [4] Helper
async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        return res['message']['content']
    except Exception as e: return f"Vision Error: {e}"

# [5] App
app = FastAPI(title="Analyst V18")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V18 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    # ... (PPT Logic omitted for brevity, assumes V17 logic is here) ...
                    return {"type": "doc", "filename": n, "equipment": "Lit", "raw_context": "Doc", "summary": "Processed"}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Robust V18)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. ÌååÏùº ÏùΩÍ∏∞ (Î™®Îì† Î∞©Î≤ï ÎèôÏõê)
                    dfs = []
                    if n.endswith(('.csv', '.txt')):
                        # V15.6 Logic: Header Hunter
                        text_content = ""
                        try: text_content = c.decode('utf-8')
                        except: 
                            try: text_content = c.decode('cp949')
                            except: pass
                        
                        if text_content:
                            lines = text_content.splitlines()
                            data_start = 0
                            # Îç∞Ïù¥ÌÑ∞ ÏãúÏûëÏ†ê Ï∞æÍ∏∞ (Ïà´Ïûê 2Í∞ú Ïù¥ÏÉÅ)
                            for i, line in enumerate(lines[:50]):
                                parts = re.split(r'[,\t\s]+', line.strip())
                                nums = [p for p in parts if re.match(r'^-?\d+(\.\d+)?$', p)]
                                if len(nums) >= 2: data_start = i; break
                            
                            try:
                                dfs = [pd.read_csv(io.StringIO("\n".join(lines[data_start:])), sep=None, engine='python', header=None)]
                            except: pass
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        dfs = [pd.read_excel(xls, sheet_name=s, header=None) for s in xls.sheet_names]

                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    # 2. Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú Î∞è Ï≤òÎ¶¨
                    res_list = []
                    for i, df in enumerate(dfs):
                        series = ScienceProcessorV18.extract_series_from_df(df)
                        for s in series:
                            res = ScienceProcessorV18.process_spectrum(s['x'], s['y'], mode, g)
                            # Chart Data
                            step = max(1, len(s['x'])//100)
                            chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                            
                            res_list.append({
                                "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                "raw_context": f"Spectrum ({e}): {res['stats_summary']}", # ‚òÖ LLMÏö© ÏöîÏïΩ ÌÖçÏä§Ìä∏ ÏÇ¨Ïö©
                                "chart_data": chart, "log": res["log"]
                            })
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Numeric Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image (V18)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV18.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read text.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. {g}. {vis_res.get('summary','')}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nCV Analysis: {vis_res.get('summary','')}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{})
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    # [V18 Fix] Sanitize ALL results (NaN -> 0.0)
    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    for r in final_results:
        if r.get("type") != "error":
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
            
    final_report = "Fail"
    if data_ctx or lit_ctx:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ÏàòÏÑù Ïó∞Íµ¨Ïõê. ÌïúÍ∏Ä. Ìëú ÌôúÏö©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



Î∏åÏù¥17
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- [V17 Fix] JSON Sanitizer (Top Level) ---
def sanitize_json(obj):
    """NaN, Inf -> None Î≥ÄÌôò (Ïû¨Í∑ÄÌï®Ïàò)"""
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return None
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return None
        return float(obj)
    return obj

# ==========================================
# [3] V17 Í≥ºÌïô ÏóîÏßÑ
# ==========================================
class ScienceProcessorV17:
    
    @staticmethod
    def extract_data_pairs_from_sheet(df: pd.DataFrame) -> List[pd.DataFrame]:
        """
        [V17 New] ÏãúÌä∏ Ï†ÑÏ≤¥Î•º Ïª¨Îüº Îã®ÏúÑÎ°ú Ïä§Ï∫îÌïòÏó¨ (X, Y) ÏåçÏùÑ Ï∂îÏ∂ú
        'Ï∂ï|Îç∞Ïù¥ÌÑ∞|Ï∂ï|Îç∞Ïù¥ÌÑ∞' Ï≤òÎüº Î∂ôÏñ¥ÏûàÎäî Í≤ΩÏö∞Î•º Ìï¥Í≤∞Ìï®
        """
        valid_pairs = []
        
        # 1. Ï†ÑÏ≤¥Î•º Ïà´ÏûêÎ°ú Î≥ÄÌôò ÏãúÎèÑ (Î¨∏ÏûêÎäî NaN)
        df_num = df.apply(pd.to_numeric, errors='coerce')
        
        num_cols = df_num.shape[1]
        
        # 2. 2Ïó¥Ïî© ÏßùÏßÄÏñ¥ Í≤ÄÏÇ¨ (0-1, 2-3, ...)
        # ÌôÄÏàò Ïó¥Ïù¥ ÎÇ®ÏúºÎ©¥ ÎßàÏßÄÎßâÏùÄ Î¨¥ÏãúÌïòÍ±∞ÎÇò Index-ValueÎ°ú Ï≤òÎ¶¨ Í∞ÄÎä•
        # Ïó¨Í∏∞ÏÑúÎäî Î™ÖÏãúÏ†ÅÏù∏ Ïåç(Pair) Íµ¨Ï°∞Î•º Ïö∞ÏÑ†Ìï®
        
        processed_cols = set()
        
        # Strategy A: ÏßùÏàò Îã®ÏúÑ Ïä§Ï∫î (Col 0&1, Col 2&3...)
        for i in range(0, num_cols - 1, 2):
            try:
                # Îëê Ïª¨ÎüºÏùÑ ÎΩëÏùå
                sub_df = df_num.iloc[:, i:i+2].copy()
                # Îëò Îã§ NaNÏù∏ Ìñâ Ï†úÍ±∞
                sub_df = sub_df.dropna(how='any') # XÎÇò Y Ï§ë ÌïòÎÇòÎùºÎèÑ ÏóÜÏúºÎ©¥ Î¨¥Ìö®
                
                # Ïú†Ìö® Îç∞Ïù¥ÌÑ∞Í∞Ä Ï∂©Î∂ÑÌûà(5Í∞ú Ïù¥ÏÉÅ) ÏûàÏúºÎ©¥ Îç∞Ïù¥ÌÑ∞Î°ú Ïù∏Ï†ï
                if sub_df.shape[0] > 5:
                    # ÏõêÎ≥∏ Ìó§ÎçîÎÇò Ï†ïÎ≥¥Î•º Ïú†ÏßÄÌïòÍ∏∞ ÏúÑÌï¥, Îç∞Ïù¥ÌÑ∞Í∞Ä ÏãúÏûëÎêòÎäî ÏúÑÏπò Ï∞æÍ∏∞
                    # (Ïó¨Í∏∞ÏÑúÎäî Îã®ÏàúÌôîÌïòÏó¨ Ïà´Ïûê Îç∞Ïù¥ÌÑ∞Îßå Ï∂îÏ∂ú)
                    sub_df.columns = [0, 1] # Ïª¨ÎüºÎ™Ö Ï¥àÍ∏∞Ìôî
                    valid_pairs.append({
                        "x": sub_df[0].values,
                        "y": sub_df[1].values,
                        "col_idx": i
                    })
                    processed_cols.add(i)
                    processed_cols.add(i+1)
            except: pass
            
        return valid_pairs

    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        h, w = img_rotated.shape[:2]
        if abs(angle_deg) < 1.0: return img_rotated
        cy, cx = h // 2, w // 2
        crop_h, crop_w = int(h * 0.7), int(w * 0.7)
        y1, x1 = max(0, cy - crop_h // 2), max(0, cx - crop_w // 2)
        return img_rotated[y1:min(h, y1+crop_h), x1:min(w, x1+crop_w)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h_orig, w_orig = img_gray.shape
        log = []
        
        # Rotation
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Auto-Rotation: {best_angle}¬∞")
        
        # Process
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV17.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        log.append(f"Layers: {len(interfaces)}")
        thicknesses = np.diff(interfaces).tolist() if len(interfaces) >= 2 else []
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces:
            cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
            
        return overlay, {
            "type": "Thin Film", "angle": best_angle, "layers": len(interfaces),
            "thickness_px": thicknesses, "avg_thickness": float(np.mean(thicknesses)) if thicknesses else 0
        }, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        body_img, footer_img = img_raw, None
        split_y = ScienceProcessorV17.detect_footer_boundary(img_raw)
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append("Footer Removed")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        b64_raw = to_b64(body_img)
        b64_footer = to_b64(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": b64_raw, "proc_b64": b64_raw, "footer_b64": b64_footer, "stats": {"info": "Raw"}, "log": process_log}

        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, l = ScienceProcessorV17.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": b64_raw, "proc_b64": to_b64(overlay), "footer_b64": b64_footer, "stats": stats, "log": process_log}

    # --- Spectrum ---
    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV17.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        log = []
        y_raw = y.copy()
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}
        
        win = 15
        do_fit = False
        if mode == "AI-Adaptive":
            if "noise" in goal.lower(): win = 31
            if "fit" in goal.lower(): do_fit = True
        
        base = ScienceProcessorV17.simple_baseline(y)
        y_proc = np.maximum(y - base, 0)
        if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
        fits = ScienceProcessorV17.fit_peaks(x, y_proc, peaks) if do_fit else []
        
        return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits}

# [4] Helper
async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V17")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V17 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Literature", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Literature", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V17 Column Scanner
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    res_list = []
                    # 1. Load DataFrame (Robust)
                    dfs = []
                    if n.endswith(('.csv', '.txt')):
                        try: dfs = [pd.read_csv(io.BytesIO(c), sep=None, engine='python', header=None)]
                        except: dfs = [pd.read_csv(io.BytesIO(c), header=None)]
                        sheet_prefix = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        for s in xls.sheet_names:
                            dfs.append(pd.read_excel(xls, sheet_name=s, header=None))
                        sheet_prefix = "Sheet"

                    # 2. Column-wise Pair Extraction
                    for i, df in enumerate(dfs):
                        pairs = ScienceProcessorV17.extract_data_pairs_from_sheet(df)
                        for p_idx, pair in enumerate(pairs):
                            try:
                                x, y = pair['x'], pair['y']
                                res = ScienceProcessorV17.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                
                                res_list.append({
                                    "type": "spectrum", 
                                    "filename": f"{n} ({sheet_prefix}{i}-Pair{p_idx})", 
                                    "equipment": e, 
                                    "raw_context": f"Peaks: {len(res['peaks'])}", 
                                    "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                })
                            except: pass
                            
                    if not res_list: return [{"type": "error", "filename": n, "msg": "No Valid Pairs Found"}]
                    return res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV17.process_image(c, e, m, g)
                    if not vis_res: return {"type": "error", "filename": n, "msg": "Fail"}
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. Î™©Ìëú:{g}. ÌÜµÍ≥Ñ:{vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    # [Sanitize] Final check for NaN/Inf
    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r and r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ÏàòÏÑù Ïó∞Íµ¨Ïõê. ÌïúÍ∏Ä. Ìëú ÌôúÏö©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



Î∏åÏù¥16
import os
import io
import asyncio
import base64
import json
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- [V16 Fix] JSON Sanitizer ---
def sanitize_for_json(obj):
    """NaN, InfinityÎ•º JSON ÌëúÏ§ÄÏù∏ NoneÏúºÎ°ú Î≥ÄÌôò"""
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return None
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_for_json(v) for v in obj]
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        if np.isnan(obj) or np.isinf(obj): return None
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return sanitize_for_json(obj.tolist())
    return obj

# ==========================================
# [3] V16 Í≥ºÌïô ÏóîÏßÑ
# ==========================================
class ScienceProcessor:
    
    @staticmethod
    def read_robust_csv(content: bytes) -> List[pd.DataFrame]:
        valid_dfs = []
        encodings = ['utf-8', 'cp949', 'latin1']
        separators = [None, ',', '\t', ';', ' '] 
        
        for enc in encodings:
            if valid_dfs: break
            for sep in separators:
                try:
                    buf = io.BytesIO(content)
                    if sep is None:
                        df = pd.read_csv(buf, sep=None, engine='python', encoding=enc, header=None)
                    else:
                        df = pd.read_csv(buf, sep=sep, encoding=enc, header=None)
                    
                    df_num = df.apply(pd.to_numeric, errors='coerce')
                    df_clean = df_num.dropna(how='all', axis=0).dropna(how='all', axis=1)
                    
                    if df_clean.shape[0] > 5 and df_clean.shape[1] >= 1:
                        valid_dfs.append(df_clean.reset_index(drop=True))
                        break
                except: continue
        return valid_dfs

    # --- Spectrum Logic ---
    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessor.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessor.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits}
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": []}

    # --- Image Logic (V15 Same) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        return overlay, {"type": "Thin Film", "layers": len(interfaces), "angle": best_angle}, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel)), axis=1)
            if np.max(row_sums) < (w*30): return None
            idx = np.argmax(row_sums)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessor.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, l = ScienceProcessor.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V16")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V16 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V16 Multi-Column Pair Support
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []
                    # Parsing
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                        sheet_name = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=0, header=None)
                        blocks = detect_excel_blocks(df)
                        sheet_name = "Sheet1"

                    if not blocks: return [{"type": "error", "filename": n, "msg": "No valid data"}]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            # Ïà´Ïûê Î≥ÄÌôò
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            
                            # [V16 NEW] Multi-Column Splitter (Pair Loop)
                            num_cols = num_block.shape[1]
                            
                            # 2Ïó¥ Ïù¥ÏÉÅÏù¥Í≥† ÏßùÏàò Ïª¨ÎüºÏù¥Î©¥ (X,Y), (X,Y) Íµ¨Ï°∞Î°ú Í∞ÑÏ£º
                            # (Îã®, 2Ïó¥Ïù∏ Í≤ΩÏö∞ÎèÑ Ïù¥ Î£®ÌîÑÏóê Ìè¨Ìï®Îê®)
                            if num_cols >= 2 and num_cols % 2 == 0:
                                for k in range(0, num_cols, 2):
                                    x = num_block.iloc[:, k].values
                                    y = num_block.iloc[:, k+1].values
                                    if len(x) < 5: continue
                                    
                                    res = ScienceProcessor.process_spectrum(x, y, mode, g)
                                    step = max(1, len(x)//100)
                                    chart = [{"x": float(res["x"][idx]), "y_proc": float(res["y_proc"][idx]), "y_raw": float(res["y_raw"][idx]), "y_base": float(res["y_base"][idx])} for idx in range(0, len(x), step)]
                                    
                                    series_name = f"Series-{k//2+1}" if num_cols > 2 else ""
                                    
                                    res_list.append({
                                        "type": "spectrum", 
                                        "filename": f"{n} ({sheet_name}-{i+1} {series_name})", 
                                        "equipment": e, 
                                        "raw_context": f"Spectrum {series_name}. Peaks: {len(res['peaks'])}", 
                                        "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                    })
                            
                            # ÌôÄÏàò Ïª¨Îüº or 1Ïó¥ (Index + Data or Just Data)
                            elif num_cols >= 1:
                                if num_cols == 1:
                                    x = np.arange(len(num_block))
                                    y = num_block.iloc[:, 0].values
                                else:
                                    # 3Ïó¥, 5Ïó¥ Îì± Ïï†Îß§Ìïú Í≤ΩÏö∞: 0Ïó¥ÏùÑ X, ÎÇòÎ®∏ÏßÄÎ•º YÎ°ú
                                    x = num_block.iloc[:, 0].values
                                    for k in range(1, num_cols):
                                        y = num_block.iloc[:, k].values
                                        res = ScienceProcessor.process_spectrum(x, y, mode, g)
                                        step = max(1, len(x)//100)
                                        chart = [{"x": float(res["x"][idx]), "y_proc": float(res["y_proc"][idx]), "y_raw": float(res["y_raw"][idx]), "y_base": float(res["y_base"][idx])} for idx in range(0, len(x), step)]
                                        res_list.append({
                                            "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1} Col{k})", "equipment": e,
                                            "raw_context": f"Spectrum. Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                        })

                        except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Process Fail"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"Analyze {e}.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}", "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{})
                    }
                except: return {"type": "error", "filename": n, "msg": "Error"}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    # [V16 Fix] Sanitize JSON before sending
    final_results = sanitize_for_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





Î∏åÏù¥15.6

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# ==========================================
# [3] V15.6 Í≥ºÌïô ÏóîÏßÑ (Header Hunter)
# ==========================================
class ScienceProcessor:
    
    @staticmethod
    def read_robust_csv(content: bytes) -> List[pd.DataFrame]:
        """
        [V15.6 New] Ìó§Îçî Ïä§ÌÇ§Ìïë Î°úÏßÅ Í∞ïÌôî
        ÌååÏùºÏùÑ ÎùºÏù∏ Îã®ÏúÑÎ°ú Î∂ÑÏÑùÌïòÏó¨ Ïà´Ïûê Îç∞Ïù¥ÌÑ∞ Î∏îÎ°ùÏùÑ ÏßÅÏ†ë Ï∞æÏïÑÎÉÖÎãàÎã§.
        """
        valid_dfs = []
        
        # 1. ÌÖçÏä§Ìä∏Î°ú ÎîîÏΩîÎî© ÏãúÎèÑ (Ïù∏ÏΩîÎî© Ï∞æÍ∏∞)
        text_content = ""
        decoded = False
        for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
            try:
                text_content = content.decode(enc)
                decoded = True
                break
            except: continue
            
        if not decoded: return [] # ÌÖçÏä§Ìä∏ ÏïÑÎãò

        # 2. ÎùºÏù∏ Îã®ÏúÑ Î∂ÑÏÑù (Data Hunting)
        lines = text_content.splitlines()
        data_start_idx = -1
        delimiter = None
        
        # Íµ¨Î∂ÑÏûê ÌõÑÎ≥¥
        separators = [',', '\t', ';', '\s+'] 
        
        # "Ïà´ÏûêÍ∞Ä 2Í∞ú Ïù¥ÏÉÅ ÏûàÎäî Ìñâ"Ïù¥ Ïñ¥ÎîîÏÑúÎ∂ÄÌÑ∞ ÏãúÏûëÎêòÎäîÏßÄ ÌÉêÏÉâ
        for i, line in enumerate(lines[:100]): # Ï≤òÏùå 100Ï§ÑÎßå Í≤ÄÏÇ¨
            line = line.strip()
            if not line: continue
            
            # Íµ¨Î∂ÑÏûê Ï∂îÏ†ï
            for sep in separators:
                if sep == '\s+': parts = line.split()
                else: parts = line.split(sep)
                
                # Ïà´Ïûê Î≥ÄÌôò Í∞ÄÎä•ÌïúÏßÄ Ï≤¥ÌÅ¨
                num_count = 0
                for p in parts:
                    try: 
                        float(p.strip())
                        num_count += 1
                    except: pass
                
                # Ìïú Ï§ÑÏóê Ïà´ÏûêÍ∞Ä 2Í∞ú Ïù¥ÏÉÅÏù¥Î©¥ Îç∞Ïù¥ÌÑ∞ ÏãúÏûëÏúºÎ°ú ÏùòÏã¨
                if num_count >= 2:
                    # Îã§Ïùå Ï§ÑÎèÑ ÌôïÏù∏Ìï¥ÏÑú ÌôïÏã†ÏùÑ Í∞ÄÏßê
                    if i + 1 < len(lines):
                        next_parts = lines[i+1].split() if sep == '\s+' else lines[i+1].split(sep)
                        if len(next_parts) == len(parts): # Ïª¨Îüº Ïàò ÎπÑÏä∑ÌïòÎ©¥ ÌôïÏ†ï
                            data_start_idx = i
                            delimiter = sep
                            break
            if data_start_idx != -1: break
            
        # 3. Îç∞Ïù¥ÌÑ∞ Î°úÎìú
        if data_start_idx != -1:
            try:
                # Ï∞æÏùÄ ÏúÑÏπòÎ∂ÄÌÑ∞ Îã§Ïãú ÏùΩÍ∏∞ (StringIO ÏÇ¨Ïö©)
                data_str = "\n".join(lines[data_start_idx:])
                if delimiter == '\s+':
                    df = pd.read_csv(io.StringIO(data_str), sep='\s+', header=None, engine='python')
                else:
                    df = pd.read_csv(io.StringIO(data_str), sep=delimiter, header=None, engine='python')
                
                # Ïà´ÏûêÎßå ÎÇ®Í∏∞Í∏∞ (Double Check)
                df_num = df.apply(pd.to_numeric, errors='coerce')
                df_clean = df_num.dropna(how='all', axis=0).dropna(how='all', axis=1)
                
                if df_clean.shape[0] > 2:
                    valid_dfs.append(df_clean.reset_index(drop=True))
            except: pass
            
        # 4. Ïã§Ìå® Ïãú Í∏∞Ï°¥(ÌÜµÏß∏Î°ú ÏùΩÍ∏∞) Î∞©Ïãù ÏãúÎèÑ (Fallback)
        if not valid_dfs:
            try:
                df = pd.read_csv(io.BytesIO(content), sep=None, engine='python', header=None)
                df_num = df.apply(pd.to_numeric, errors='coerce').dropna(how='all')
                if df_num.shape[0] > 5: valid_dfs.append(df_num)
            except: pass
            
        return valid_dfs

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            fits = [] # (Fitting Logic Omitted for Brevity - Same as V15)
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits}
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": []}

    # ... (Image / Helper Logic V15 Same) ...
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        return overlay, {"type": "Thin Film", "layers": len(interfaces), "angle": best_angle}, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel)), axis=1)
            if np.max(row_sums) < (w*30): return None
            idx = np.argmax(row_sums)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessor.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ"]):
            overlay, stats, l = ScienceProcessor.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V15.6")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V15.6 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Literature", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Literature", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []
                    # Robust CSV
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                        sheet_name = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=0, header=None)
                        blocks = detect_excel_blocks(df)
                        sheet_name = "Sheet1"

                    if not blocks: return [{"type": "error", "filename": n, "msg": "No valid data"}]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            if block.shape[1] == 1: x = np.arange(len(block)); y = block.iloc[:, 0].values
                            else: x = block.iloc[:, 0].values; y = block.iloc[:, 1].values
                            
                            if len(x) < 5: continue
                            res = ScienceProcessor.process_spectrum(x, y, mode, g)
                            step = max(1, len(x)//100)
                            chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                            
                            res_list.append({
                                "type": "spectrum", "filename": f"{n}-{i}", "equipment": e,
                                "raw_context": f"Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"]
                            })
                        except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Parse Error"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"Analyze {e}.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}", "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{})
                    }
                except: return {"type": "error", "filename": n, "msg": "Error"}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    data_ctx, lit_ctx = "", ""
    has_content = False
    for r in final_results:
        if r.get("type") != "error":
            has_content = True
            raw = r.get("raw_context") or ""
            if r.get("equipment") == "Literature": lit_ctx += f"\nFile {r['filename']}: {raw[:3000]}"
            else: data_ctx += f"\nFile {r['filename']}: {raw[:3000]}"
    
    final_report = "Fail"
    if has_content:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean Report.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)




Î∏åÏù¥15.3
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# ==========================================
# [3] Í≥ºÌïô Ï≤òÎ¶¨ ÏóîÏßÑ (V15.3 Core)
# ==========================================
class ScienceProcessor:
    
    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        h, w = img_rotated.shape[:2]
        if abs(angle_deg) < 1.0: return img_rotated
        cy, cx = h // 2, w // 2
        crop_h, crop_w = int(h * 0.7), int(w * 0.7)
        y1, x1 = max(0, cy - crop_h // 2), max(0, cx - crop_w // 2)
        return img_rotated[y1:min(h, y1+crop_h), x1:min(w, x1+crop_w)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h_orig, w_orig = img_gray.shape
        log = []
        
        # 1. Auto-Rotation
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
            
        log.append(f"Auto-Rotation: {best_angle}¬∞")
        
        # 2. Process
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        log.append(f"Layers: {len(interfaces)}")
        thicknesses = np.diff(interfaces).tolist() if len(interfaces) >= 2 else []
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces:
            cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
            
        return overlay, {
            "type": "Thin Film", "angle": best_angle, "layers": len(interfaces),
            "thickness_px": thicknesses, "avg_thickness": float(np.mean(thicknesses)) if thicknesses else 0
        }, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        body_img, footer_img = img_raw, None
        split_y = ScienceProcessor.detect_footer_boundary(img_raw)
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append("Footer Removed")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        b64_raw = to_b64(body_img)
        b64_footer = to_b64(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": b64_raw, "proc_b64": b64_raw, "footer_b64": b64_footer, "stats": {"info": "Raw"}, "log": process_log}

        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body_img.copy()
        stats = {}
        
        if any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ", "ÎëêÍªò"]):
            overlay, stats, l = ScienceProcessor.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ÏõêÏûê"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ÏûÖÏûê"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": b64_raw, "proc_b64": to_b64(overlay), "footer_b64": b64_footer, "stats": stats, "log": process_log}

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessor.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        log = []
        y_raw = y.copy()
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}
        
        win = 15
        do_fit = False
        if mode == "AI-Adaptive":
            if "noise" in goal.lower(): win = 31
            if "fit" in goal.lower(): do_fit = True
        
        base = ScienceProcessor.simple_baseline(y)
        y_proc = np.maximum(y - base, 0)
        if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
        
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
        fits = ScienceProcessor.fit_peaks(x, y_proc, peaks) if do_fit else []
        
        return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits}

# [4] Ìó¨Ìçº
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V15.3")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V15.3 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document Path (Literature)
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))

        # [B] Spectrum Path (Excel/CSV) - Fix: elif ÏÇ¨Ïö©
        elif fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []; sheet_name = "Data"
                    if n.endswith(('.csv', '.txt')):
                        success = False
                        for enc in ['utf-8', 'cp949', 'latin1']:
                            if success: break
                            for sep in [None, ',', '\t', ';']:
                                try:
                                    df = pd.read_csv(io.BytesIO(c), sep=sep, encoding=enc, engine='python', header=None)
                                    # Ïà´ÏûêÎßå ÏûàÎäîÏßÄ Ï≤¥ÌÅ¨
                                    num = df.apply(pd.to_numeric, errors='coerce').dropna(how='all')
                                    if num.shape[0] > 2:
                                        blocks = [df]; success = True; break
                                except: pass
                        if not blocks: return {"type": "error", "filename": n, "msg": "CSV Read Failed"}
                        sheet_name = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=xls.sheet_names[0], header=None)
                        blocks = detect_excel_blocks(df)
                        sheet_name = xls.sheet_names[0]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            if not num_block.empty and num_block.shape[0] > 5:
                                x = num_block.iloc[:, 0].fillna(0).values; y = num_block.iloc[:, 1].fillna(0).values
                                res = ScienceProcessor.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1})", "equipment": e,
                                    "raw_context": f"Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                })
                        except: pass
                    
                    if not res_list: return {"type": "error", "filename": n, "msg": "No valid data"}
                    return res_list[0] if len(res_list)==1 else res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image Path - Fix: elif ÏÇ¨Ïö©
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    if not vis_res: return {"type": "error", "filename": n, "msg": "Fail"}
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. Î™©Ìëú:{g}. ÌÜµÍ≥Ñ:{vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    data_ctx, lit_ctx = "", ""
    has_data = False
    for r in final_results:
        if r.get("type") != "error":
            has_data = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_data and (data_ctx or lit_ctx):
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ÏàòÏÑù Ïó∞Íµ¨Ïõê. ÌïúÍ∏Ä. Ìëú ÌôúÏö©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





Î∏åÏù¥15
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# ==========================================
# [3] V15 Í≥ºÌïô ÏóîÏßÑ (Interface Metrology)
# ==========================================
class ScienceProcessorV15:
    
    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        h, w = img_rotated.shape[:2]
        if abs(angle_deg) < 1.0: return img_rotated # ÏûëÏùÄ Í∞ÅÎèÑÎäî Î¨¥Ïãú
        
        # Í∞ÑÎã®Ìïú Ï§ëÏïôÎ∂Ä Crop (ÎßàÎ¶ÑÎ™® Î¨∏Ï†ú ÌöåÌîº)
        # ÏïàÏ†ÑÌïòÍ≤å Ï§ëÏïô 70% ÏòÅÏó≠Îßå ÏÇ¨Ïö© (Î≥µÏû°Ìïú Í∏∞ÌïòÌïô Í≥ÑÏÇ∞ ÎåÄÏã† ÏïàÏ†ïÏÑ± ÌÉùÌï®)
        cy, cx = h // 2, w // 2
        crop_h, crop_w = int(h * 0.7), int(w * 0.7)
        y1 = max(0, cy - crop_h // 2)
        x1 = max(0, cx - crop_w // 2)
        y2 = min(h, y1 + crop_h)
        x2 = min(w, x1 + crop_w)
        return img_rotated[y1:y2, x1:x2]

    @staticmethod
    def analyze_thin_film(img_gray):
        """
        [V15] Í≥ÑÎ©¥ Ï∂îÏ†Å Î∞è Í±∞Ïπ†Í∏∞/ÎëêÍªò Ï†ïÎ∞Ä Î∂ÑÏÑù
        """
        h_orig, w_orig = img_gray.shape
        log = []
        
        # 1. Auto-Rotation
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0
        max_var = -1
        
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
            
        log.append(f"Auto-Rotation: {best_angle}¬∞")
        
        # 2. Rotate & Valid Crop
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV15.crop_valid_rotated_region(img_rot, best_angle)
        h, w = img_crop.shape
        
        # 3. Global Peak Search (Approximate Locations)
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        # Ï£ºÏöî Í≥ÑÎ©¥ Ï∞æÍ∏∞
        interfaces_approx, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        log.append(f"Global Layers Found: {len(interfaces_approx)}")
        
        # 4. Local Interface Tracking (Pixel-wise)
        # Í∞Å xÏ¢åÌëúÎßàÎã§ gradientÍ∞Ä ÏµúÎåÄÏù∏ yÎ•º Ï∞æÏùå (Window Search)
        interface_paths = [] # List of [y_0, y_1, ..., y_w]
        
        grad_img = np.abs(np.gradient(img_blur, axis=0)) # YÏ∂ï Î∞©Ìñ• ÎØ∏Î∂Ñ Ïù¥ÎØ∏ÏßÄ
        
        for y_approx in interfaces_approx:
            path = []
            search_range = 15 # ÏÉÅÌïò 15ÌîΩÏÖÄ ÌÉêÏÉâ
            
            for x in range(w):
                # Í≤ÄÏÉâ Î≤îÏúÑ ÏÑ§Ï†ï
                y_start = max(0, y_approx - search_range)
                y_end = min(h, y_approx + search_range)
                
                # Ìï¥Îãπ Ïª¨Îüº(x)Ïùò Î°úÏª¨ ÏòÅÏó≠ÏóêÏÑú ÏµúÎåÄ Gradient ÏúÑÏπò Ï∞æÍ∏∞
                local_col = grad_img[y_start:y_end, x]
                if len(local_col) == 0: 
                    path.append(y_approx)
                    continue
                    
                local_max_idx = np.argmax(local_col)
                real_y = y_start + local_max_idx
                path.append(real_y)
            
            # ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Median Filter on Path)
            path_smooth = savgol_filter(path, window_length=31, polyorder=2)
            interface_paths.append(path_smooth)

        # 5. Analysis: Roughness & Thickness
        roughness_stats = []
        thickness_stats = {}
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        
        # Draw Paths
        for idx, path in enumerate(interface_paths):
            # A. Polynomial Fit (Trend) - 3Ï∞® Ìï®Ïàò
            x_axis = np.arange(len(path))
            coeffs = np.polyfit(x_axis, path, 3)
            poly_func = np.poly1d(coeffs)
            trend_line = poly_func(x_axis)
            
            # B. Roughness (Actual - Trend)
            residuals = path - trend_line
            rms = np.sqrt(np.mean(residuals**2)) # Rq
            ra = np.mean(np.abs(residuals))      # Ra
            roughness_stats.append(f"Layer {idx+1}: Rq={rms:.2f}px, Ra={ra:.2f}px")
            
            # C. Draw
            # Actual Path (Green)
            pts = np.array([np.transpose(np.vstack([x_axis, path]))], np.int32)
            cv2.polylines(overlay, pts, isClosed=False, color=(0, 255, 0), thickness=2)
            # Trend Line (Red Dashed - Simulated by drawing line)
            pts_trend = np.array([np.transpose(np.vstack([x_axis, trend_line]))], np.int32)
            cv2.polylines(overlay, pts_trend, isClosed=False, color=(0, 0, 255), thickness=1)

        # Thickness Distribution
        if len(interface_paths) >= 2:
            # Îëê Í≥ÑÎ©¥ ÏÇ¨Ïù¥Ïùò Í±∞Î¶¨ (Point-to-Point)
            t_dist = []
            for i in range(len(interface_paths) - 1):
                diff = np.array(interface_paths[i+1]) - np.array(interface_paths[i])
                mean_t = np.mean(diff)
                std_t = np.std(diff)
                t_dist.append(f"L{i+1}-L{i+2}: Avg={mean_t:.1f}px (¬±{std_t:.2f})")
                
                # ÏãúÍ∞ÅÌôî (Ï§ëÍ∞Ñ ÏßÄÏ†êÏóê ÌÖçÏä§Ìä∏)
                mid_y = int((np.mean(interface_paths[i]) + np.mean(interface_paths[i+1])) / 2)
                cv2.putText(overlay, f"{mean_t:.1f}px", (w//2, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            
            thickness_stats["distribution"] = t_dist
            
        stats = {
            "type": "Thin Film Metrology",
            "angle": best_angle,
            "roughness": roughness_stats,
            "thickness": thickness_stats
        }
        
        return overlay, stats, log

    @staticmethod
    def detect_footer_boundary(img_array):
        # (Í∏∞Ï°¥ V14 ÎèôÏùº)
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        
        # 1. Smart Crop
        body_img, footer_img, split_y = img_raw, None, ScienceProcessorV15.detect_footer_boundary(img_raw)
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append("Smart Crop: Footer removed")
        
        # Helper Encoders
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        b64_raw = to_b64(body_img)
        b64_footer = to_b64(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": b64_raw, "proc_b64": b64_raw, "footer_b64": b64_footer, "stats": {"info": "Raw"}, "log": process_log}

        # 2. Logic Branch
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        
        processed_overlay = body_img.copy()
        stats = {}
        
        # [V15] Thin Film Metrology
        is_film = any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ", "ÎëêÍªò", "Í≥ÑÎ©¥", "roughness", "Í±∞Ïπ†Í∏∞"])
        
        if is_film:
            processed_overlay, f_stats, f_log = ScienceProcessorV15.analyze_thin_film(gray)
            stats.update(f_stats)
            process_log.extend(f_log)
        else:
            # Particle / Atom
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = False
            detect_particles = False
            
            if mode == "AI-Adaptive":
                if any(x in kwd for x in ["atom", "ÏõêÏûê"]): detect_atoms = True
                if any(x in kwd for x in ["particle", "ÏûÖÏûê"]): detect_particles = True
            elif mode == "Auto":
                if equipment in ["STEM", "TEM"]: detect_atoms = True
                if equipment in ["SEM", "Optical"]: detect_particles = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(processed_overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                process_log.append(f"Atoms: {len(blobs)}")
            elif detect_particles:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(processed_overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                process_log.append(f"Particles: {len(cnts)}")

        return {
            "raw_b64": b64_raw,
            "proc_b64": to_b64(processed_overlay),
            "footer_b64": b64_footer,
            "stats": stats,
            "log": process_log
        }

    # --- Spectrum & Helper ---
    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV15.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        log = []
        y_raw = y.copy()
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}
        
        win = 15
        do_fit = False
        if mode == "AI-Adaptive":
            if "noise" in goal.lower(): win = 31
            if "fit" in goal.lower(): do_fit = True
        
        base = ScienceProcessorV15.simple_baseline(y)
        y_proc = np.maximum(y - base, 0)
        if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
        fits = ScienceProcessorV15.fit_peaks(x, y_proc, peaks) if do_fit else []
        
        return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits}

def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# --- App ---
app = FastAPI(title="Analyst V15")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V15 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Data (Spectrum)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    if n.endswith(('.csv', '.txt')):
                        try: df = pd.read_csv(io.BytesIO(c))
                        except: df = pd.read_csv(io.BytesIO(c), delimiter='\t')
                        blocks = [df]; sheet_name="CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=xls.sheet_names[0], header=None)
                        blocks = detect_excel_blocks(df); sheet_name=xls.sheet_names[0]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            if not num_block.empty and num_block.shape[0] > 5:
                                x = num_block.iloc[:, 0].fillna(0).values; y = num_block.iloc[:, 1].fillna(0).values
                                res = ScienceProcessorV15.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1})", "equipment": e,
                                    "raw_context": f"Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                })
                        except: pass
                    return res_list[0] if len(res_list)==1 else res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            pass

        # [C] Data (Image)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV15.process_image(c, e, m, g)
                    if not vis_res: return {"type": "error", "filename": n, "msg": "Fail"}
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. Î™©Ìëú:{g}. ÌÜµÍ≥Ñ:{vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    data_ctx, lit_ctx = "", ""
    for r in final_results:
        if r.get("type") != "error":
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if data_ctx or lit_ctx:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ÏàòÏÑù Ïó∞Íµ¨Ïõê. ÌïúÍ∏Ä. Ìëú ÌôúÏö©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



Î∏åÏù¥14

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] Î≥¥Ïïà ÏÑ§Ï†ï
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# Í≥ºÌïô Ïó∞ÏÇ∞
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ÏÑ§Ï†ï
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# [3] V14 Í≥ºÌïô ÏóîÏßÑ (Lossless Projection)
class ScienceProcessorV14:
    
    # --- [A] Geometry Helpers ---
    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        """
        [V14 New] ÌöåÏ†ÑÎêú Ïù¥ÎØ∏ÏßÄÏóêÏÑú Í≤ÄÏùÄÏÉâ(Îπà Í≥µÍ∞Ñ)ÏùÑ Ï†úÏô∏Ìïú
        'Í∞ÄÏû• ÌÅ∞ ÎÇ¥Î∂Ä ÏßÅÏÇ¨Í∞ÅÌòï(Largest Inscribed Rectangle)'ÏùÑ Ï∞æÏïÑ ÏûòÎùºÎÉÖÎãàÎã§.
        """
        h, w = img_rotated.shape[:2]
        angle_rad = math.radians(abs(angle_deg))
        
        # Í∏∞ÌïòÌïôÏ†Å Í≥ÑÏÇ∞ (ÏõêÎ≥∏ ÎπÑÏú® Ïú†ÏßÄ Í∞ÄÏ†ï)
        # sin/cos Í∞íÏóê Îî∞Îùº Ïú†Ìö® ÏòÅÏó≠Ïùò ÎÑàÎπÑ/ÎÜíÏù¥ Í≥ÑÏÇ∞
        sin_a = math.sin(angle_rad)
        cos_a = math.cos(angle_rad)
        
        # ÌöåÏ†Ñ ÌõÑ Ï§ëÏã¨ Í∏∞Ï§Ä Ïú†Ìö® Î∞ïÏä§ ÌÅ¨Í∏∞ Ï∂îÏ†ï (Í∞ÑÏÜåÌôîÎêú Î°úÏßÅ)
        # Ïã§Ï†úÎ°úÎäî ÏõêÎ≥∏ h0, w0Î•º ÏïåÏïÑÏïº Ï†ïÌôïÌïòÏßÄÎßå, Ïó¨Í∏∞ÏÑúÎäî ÌöåÏ†ÑÎêú Ïù¥ÎØ∏ÏßÄ ÎÇ¥ÏóêÏÑú
        # Í≤ÄÏùÄÏÉâÏù¥ ÏïÑÎãå ÏòÅÏó≠ÏùÑ Ï∞æÎäî Î∞©ÏãùÏúºÎ°ú Íµ¨ÌòÑ (Îçî Î≤îÏö©Ï†Å)
        
        # 1. Grayscale & Threshold to find content
        if len(img_rotated.shape) == 3:
            gray = cv2.cvtColor(img_rotated, cv2.COLOR_BGR2GRAY)
        else:
            gray = img_rotated
            
        # ÌöåÏ†Ñ Ïãú Îπà Í≥µÍ∞ÑÏùÄ Î≥¥ÌÜµ 0(Í≤ÄÏùÄÏÉâ) ÎòêÎäî Î≥¥Í∞ÑÎêú Í∞í
        # ÏïàÏ†ÑÌïòÍ≤å 0Ïù¥ ÏïÑÎãå ÌîΩÏÖÄÏùò Bounding BoxÎ•º Íµ¨Ìï® (ÌïòÏßÄÎßå Ïù¥Í±¥ ÎßàÎ¶ÑÎ™®ÏûÑ)
        # ÎßàÎ¶ÑÎ™® ÏïàÏùò ÏßÅÏÇ¨Í∞ÅÌòïÏùÑ Íµ¨Ìï¥Ïïº Ìï®.
        
        # Í∞ÑÎã®ÌïòÍ≥† Í∞ïÎ†•Ìïú Î∞©Î≤ï: Ï§ëÏã¨ÏóêÏÑú Ï°∞Í∏àÏî© Î∞ñÏúºÎ°ú ÎÇòÍ∞ÄÎ©∞ Í≤ÄÏùÄÏÉâÏùÑ ÎßåÎÇ† ÎïåÍπåÏßÄ ÌôïÏû•
        cy, cx = h // 2, w // 2
        
        # XÏ∂ï ÌÉêÏÉâ
        valid_w = 0
        for x in range(cx, w):
            if gray[cy, x] == 0: break
            valid_w += 1
        
        # YÏ∂ï ÌÉêÏÉâ
        valid_h = 0
        for y in range(cy, h):
            if gray[y, cx] == 0: break
            valid_h += 1
            
        # ÏïàÏ†Ñ ÎßàÏßÑ (90%)
        crop_w = int(valid_w * 2 * 0.9)
        crop_h = int(valid_h * 2 * 0.9)
        
        # Crop
        x1 = cx - crop_w // 2
        y1 = cy - crop_h // 2
        
        # Î≤îÏúÑ Ï≤¥ÌÅ¨
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x1 + crop_w), min(h, y1 + crop_h)
        
        return img_rotated[y1:y2, x1:x2]

    # --- [B] Analysis Engines ---
    @staticmethod
    def analyze_thin_film(img_gray):
        """
        Î∞ïÎßâ Î∂ÑÏÑù (ÌöåÏ†Ñ -> Ïú†Ìö® ÌÅ¨Î°≠ -> ÌîÑÎ°úÌååÏùºÎßÅ)
        """
        h_orig, w_orig = img_gray.shape
        log = []
        
        # 1. Angle Detection (Low Res for Speed)
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0
        max_var = -1
        
        # Í∞ÅÎèÑ Ï†ïÎ∞Ä ÌÉêÏÉâ
        for ang in range(-90, 91, 2):
            # ÌöåÏ†Ñ Ïãú bicubic ÏÇ¨Ïö© (ÌÉêÏÉâÏö©)
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var:
                max_var = var
                best_angle = ang
        
        log.append(f"Detected Angle: {best_angle}¬∞")
        
        # 2. High-Quality Rotation (Lanczos4)
        # LanczosÎäî Sinc Ìï®Ïàò Í∏∞Î∞òÏù¥Îùº Edge Î≥¥Ï°¥Î†•Ïù¥ Í∞ÄÏû• Ï¢ãÏùå
        img_rot = rotate(img_gray, best_angle, reshape=True, order=4, mode='constant', cval=0)
        
        # 3. [V14] Valid Area Crop (Remove Black Borders)
        img_crop = ScienceProcessorV14.crop_valid_rotated_region(img_rot, best_angle)
        h_c, w_c = img_crop.shape
        log.append(f"Valid Region Cropped: {w_c}x{h_c}")
        
        # 4. Profile & Interface
        # Ïù¥Ï†ú ÎßàÎ¶ÑÎ™®Í∞Ä ÏïÑÎãå ÏßÅÏÇ¨Í∞ÅÌòï Îç∞Ïù¥ÌÑ∞Ïù¥ÎØÄÎ°ú ÏàòÏßÅ ÌèâÍ∑†Ïù¥ Ï†ïÌôïÌï®
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        # 5. Visualization (Overlay on the Cropped Image)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces:
            cv2.line(overlay, (0, y_pos), (w_c, y_pos), (0, 0, 255), 2)
            
        # Thickness Calculation
        thicknesses = []
        if len(interfaces) >= 2:
            thicknesses = np.diff(interfaces).tolist()
            
        stats = {
            "type": "Thin Film",
            "angle": best_angle,
            "layers": len(interfaces),
            "thickness_px": thicknesses,
            "avg_thickness": float(np.mean(thicknesses)) if thicknesses else 0
        }
        
        # Encode cropped image for display
        return overlay, stats, log

    @staticmethod
    def detect_footer_boundary(img_array):
        # (Í∏∞Ï°¥Í≥º ÎèôÏùº)
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        
        # 1. Smart Crop (Footer Removal)
        body_img = img_raw
        footer_img = None
        split_y = ScienceProcessorV14.detect_footer_boundary(img_raw)
        
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append("Smart Crop: Footer removed")
        
        # Encoding Helpers
        def encode_img(img):
            _, buf = cv2.imencode('.jpg', img)
            return base64.b64encode(buf).decode('utf-8')

        b64_raw = encode_img(body_img)
        b64_footer = encode_img(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": b64_raw, "proc_b64": b64_raw, "footer_b64": b64_footer, "stats": {"info": "Raw"}, "log": process_log}

        # 2. Analysis Branch
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        
        processed_overlay = body_img.copy()
        stats = {}
        
        # [V14] Thin Film Check
        is_film = any(x in kwd for x in ["film", "layer", "thick", "Î∞ïÎßâ", "ÎëêÍªò", "Í≥ÑÎ©¥"])
        
        if is_film:
            # V14 Engine Call (Returns Cropped & Rotated Image)
            processed_overlay, f_stats, f_log = ScienceProcessorV14.analyze_thin_film(gray)
            stats.update(f_stats)
            process_log.extend(f_log)
            # Thin Film Î™®ÎìúÏóêÏÑúÎäî ÏõêÎ≥∏(Raw) ÎåÄÏã† Ï≤òÎ¶¨Îêú(Rotated) Ïù¥ÎØ∏ÏßÄÎ•º Î©îÏù∏ÏúºÎ°ú Î≥¥Ïó¨Ï£ºÎäîÍ≤å ÎÇòÏùå
            # ÌïòÏßÄÎßå ÎπÑÍµêÎ•º ÏúÑÌï¥ RawÎäî Í∑∏ÎåÄÎ°ú Îë†
        else:
            # Particle / Atom Check
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = False
            detect_particles = False
            
            if mode == "AI-Adaptive":
                if any(x in kwd for x in ["atom", "ÏõêÏûê"]): detect_atoms = True
                if any(x in kwd for x in ["particle", "ÏûÖÏûê"]): detect_particles = True
            elif mode == "Auto":
                if equipment in ["STEM", "TEM"]: detect_atoms = True
                if equipment in ["SEM", "Optical"]: detect_particles = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(processed_overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                process_log.append(f"Atoms: {len(blobs)}")
            elif detect_particles:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(processed_overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                process_log.append(f"Particles: {len(cnts)}")

        b64_proc = encode_img(processed_overlay)
        
        return {
            "raw_b64": b64_raw,
            "proc_b64": b64_proc,
            "footer_b64": b64_footer,
            "stats": stats,
            "log": process_log
        }

    # --- Spectrum & Helper ---
    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV14.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        log = []
        y_raw = y.copy()
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}
        
        win = 15
        do_fit = False
        if mode == "AI-Adaptive":
            if "noise" in goal.lower(): win = 31
            if "fit" in goal.lower(): do_fit = True
        
        base = ScienceProcessorV14.simple_baseline(y)
        y_proc = np.maximum(y - base, 0)
        if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
        
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
        fits = ScienceProcessorV14.fit_peaks(x, y_proc, peaks) if do_fit else []
        
        return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits}

def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# --- App ---
app = FastAPI(title="Analyst V14")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"üöÄ V14 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "ÌïúÍ∏Ä ÏöîÏïΩ.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ÌïúÍ∏Ä ÏÑ§Î™Ö.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Data (Spectrum)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    if n.endswith(('.csv', '.txt')):
                        try: df = pd.read_csv(io.BytesIO(c))
                        except: df = pd.read_csv(io.BytesIO(c), delimiter='\t')
                        blocks = [df]; sheet_name="CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=xls.sheet_names[0], header=None)
                        blocks = detect_excel_blocks(df); sheet_name=xls.sheet_names[0]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            if not num_block.empty and num_block.shape[0] > 5:
                                x = num_block.iloc[:, 0].fillna(0).values; y = num_block.iloc[:, 1].fillna(0).values
                                res = ScienceProcessorV14.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1})", "equipment": e,
                                    "raw_context": f"Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                })
                        except: pass
                    return res_list[0] if len(res_list)==1 else res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            pass # (Ïä§ÌéôÌä∏Îüº Î°úÏßÅÏùÄ gather Ï≤òÎ¶¨Î•º ÏúÑÌï¥ ÎûòÌïë ÌïÑÏöî - V13Í≥º ÎèôÏùº)

        # [C] Data (Image)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV14.process_image(c, e, m, g)
                    if not vis_res: return {"type": "error", "filename": n, "msg": "Fail"}
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"ÌïúÍ∏Ä Î∂ÑÏÑù. {e}. Î™©Ìëú:{g}. ÌÜµÍ≥Ñ:{vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    data_ctx, lit_ctx = "", ""
    for r in final_results:
        if r.get("type") != "error":
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if data_ctx or lit_ctx:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ÏàòÏÑù Ïó∞Íµ¨Ïõê. ÌïúÍ∏Ä. Ìëú ÌôúÏö©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



Î∏åÏù¥14
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>AI Research Center V14.1</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        body { font-family: 'Inter', sans-serif; }
        .prose table { border-collapse: collapse; width: 100%; margin: 1em 0; }
        .prose th, .prose td { border: 1px solid #cbd5e1; padding: 8px; font-size: 0.9rem; }
        .prose th { background-color: #f1f5f9; }
        .loader { border: 3px solid #f3f3f3; border-top: 3px solid #0ea5e9; border-radius: 50%; width: 20px; height: 20px; animation: spin 1s linear infinite; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-slate-100 text-slate-800">
    <div id="app" class="min-h-screen p-6">
        <header class="max-w-7xl mx-auto mb-6 flex items-center gap-3">
            <div class="bg-indigo-600 p-2 rounded-lg shadow"><i data-lucide="microscope" class="w-6 h-6 text-white"></i></div>
            <div><h1 class="text-2xl font-bold">AI Research Center V14.1</h1><p class="text-xs text-slate-500">Lossless Projection ‚Ä¢ Smart UX</p></div>
        </header>

        <main class="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6">
            
            <!-- Staging Area -->
            <div class="lg:col-span-4 space-y-4">
                <div class="bg-white p-5 rounded-xl shadow-sm border border-slate-200">
                    <h2 class="font-bold mb-3 flex items-center gap-2"><i data-lucide="files" class="w-4 h-4"></i> Data Staging</h2>
                    <div class="border-2 border-dashed border-slate-300 rounded-lg p-6 text-center hover:bg-indigo-50 cursor-pointer" @click="$refs.f.click()">
                        <input type="file" ref="f" multiple class="hidden" @change="addFiles">
                        <p class="text-sm font-semibold text-slate-600">Add Files</p>
                    </div>
                    <div v-if="stagedFiles.length" class="mt-4 space-y-3 max-h-[60vh] overflow-y-auto pr-1">
                        <div v-for="(item, i) in stagedFiles" :key="i" class="p-3 bg-slate-50 border rounded-lg text-sm">
                            <div class="flex justify-between items-center mb-2">
                                <span class="font-bold truncate w-2/3" :title="item.file.name">{{ item.file.name }}</span>
                                <button @click="removeFile(i)" class="text-red-400 hover:text-red-600"><i data-lucide="trash-2" class="w-4 h-4"></i></button>
                            </div>
                            <div class="grid grid-cols-1 gap-2">
                                <select v-model="item.equipment" class="w-full p-1.5 border rounded text-xs bg-white font-semibold text-indigo-700">
                                    <optgroup label="Literature">
                                        <option value="Document">Document (PDF/PPT)</option>
                                    </optgroup>
                                    <optgroup label="Spectroscopy">
                                        <option value="XRD">XRD</option>
                                        <option value="EDS">EDS / EDX</option>
                                        <option value="EELS">EELS</option>
                                        <option value="Raman">Raman</option>
                                        <option value="FT-IR">FT-IR</option>
                                        <option value="PL">PL</option>
                                    </optgroup>
                                    <optgroup label="Microscopy">
                                        <option value="SEM">SEM</option>
                                        <option value="TEM">TEM (Thin Film)</option>
                                        <option value="STEM">STEM (Thin Film)</option>
                                        <option value="AFM">AFM</option>
                                        <option value="Optical BF">Optical (BF)</option>
                                    </optgroup>
                                </select>
                                <select v-if="item.equipment !== 'Document'" v-model="item.mode" class="w-full p-1.5 border rounded text-xs bg-white text-indigo-700">
                                    <option value="Auto">‚ú® Auto Process</option>
                                    <option value="None">üö´ None (Raw)</option>
                                    <option value="AI-Adaptive">üß† AI-Adaptive</option>
                                </select>
                                <input v-if="item.equipment !== 'Document'" v-model="item.goal" type="text" placeholder="Goal (e.g. Measure thickness)" class="w-full p-1.5 border rounded text-xs">
                            </div>
                        </div>
                    </div>
                    <button @click="analyze" :disabled="isAnalyzing || stagedFiles.length===0" class="w-full mt-4 py-3 bg-indigo-600 text-white rounded-lg font-bold flex justify-center gap-2 shadow hover:bg-indigo-700 disabled:opacity-50">
                        <div v-if="isAnalyzing" class="loader"></div>
                        <span>Generate Synthesis Report</span>
                    </button>
                </div>
            </div>

            <!-- Report Area -->
            <div class="lg:col-span-8">
                <div v-if="result" class="space-y-6 animate-fade-in">
                    
                    <!-- Tools -->
                    <div class="flex justify-between items-center bg-white p-2 rounded-xl shadow-sm border border-slate-200">
                        <div class="flex gap-2">
                            <button @click="setLang('ko')" :class="lang==='ko'?'bg-indigo-100 text-indigo-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">üá∞üá∑ ÌïúÍ∏Ä</button>
                            <button @click="setLang('en')" :class="lang==='en'?'bg-blue-100 text-blue-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">
                                <div v-if="isTranslating" class="w-3 h-3 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                                <span v-else>üá∫üá∏</span> English
                            </button>
                        </div>
                        <button @click="dlPDF" class="px-3 py-1.5 bg-slate-800 text-white text-xs rounded">PDF Export</button>
                    </div>

                    <div id="report-view" class="bg-white p-8 rounded-xl shadow-sm border border-slate-200">
                        
                        <!-- Synthesis -->
                        <section class="mb-10">
                            <h2 class="text-lg font-bold text-indigo-700 mb-3 border-b pb-1">1. Synthesis</h2>
                            <div class="prose prose-sm text-slate-700 max-w-none" v-html="md(displayReport)"></div>
                        </section>

                        <!-- Details -->
                        <section>
                            <h2 class="text-lg font-bold text-slate-800 mb-5 border-b pb-1">2. Data Evidence</h2>
                            
                            <div v-for="(item, idx) in result.results" :key="idx" class="mb-8 p-4 bg-slate-50 rounded-lg border break-inside-avoid">
                                <div class="flex items-center justify-between mb-3">
                                    <div class="flex items-center gap-2">
                                        <span class="px-2 py-0.5 bg-white border rounded text-[10px] font-bold uppercase text-slate-500">{{ item.equipment }}</span>
                                        <h3 class="font-bold text-sm">{{ item.filename }}</h3>
                                    </div>
                                    <!-- Toggle Button -->
                                    <button @click="item.showDocs = !item.showDocs" class="text-xs text-indigo-600 font-bold hover:underline flex items-center gap-1">
                                        <i :data-lucide="item.showDocs ? 'eye-off' : 'eye'" class="w-3 h-3"></i>
                                        {{ item.showDocs ? 'Hide Text' : 'Show Text' }}
                                    </button>
                                </div>

                                <!-- Spectrum Chart -->
                                <div v-if="item.chart_data" class="bg-white p-2 rounded border mb-3">
                                    <div :id="'chart-'+idx" class="w-full h-60"></div>
                                </div>

                                <!-- Image Viewer -->
                                <div v-if="item.raw_b64" class="bg-white p-2 rounded border mb-3">
                                    <div class="flex gap-2 mb-2 text-xs justify-center">
                                        <button @click="item.view='proc'" :class="item.view!=='raw'?'font-bold text-indigo-600':''">Processed</button>
                                        <span class="text-slate-300">|</span>
                                        <button @click="item.view='raw'" :class="item.view==='raw'?'font-bold text-indigo-600':''">Original</button>
                                        <span class="text-slate-300" v-if="item.footer_b64">|</span>
                                        <button v-if="item.footer_b64" @click="item.view='footer'" :class="item.view==='footer'?'font-bold text-indigo-600':''">Info Bar</button>
                                    </div>
                                    <img v-if="item.view!=='footer'" :src="'data:image/jpeg;base64,' + (item.view==='raw' ? item.raw_b64 : item.proc_b64)" class="max-h-80 mx-auto object-contain bg-black">
                                    <img v-if="item.view==='footer'" :src="'data:image/jpeg;base64,' + item.footer_b64" class="max-h-24 mx-auto object-contain border mt-2">
                                </div>

                                <!-- [Fix] PDF Pages -->
                                <div v-if="item.pages" class="space-y-4">
                                    <div v-for="p in item.pages" :key="p.page_num" class="flex gap-4 bg-white p-3 rounded border">
                                        <!-- Image always visible -->
                                        <div :class="item.showDocs ? 'w-1/3' : 'w-full text-center'">
                                            <img :src="'data:image/jpeg;base64,'+p.image_b64" class="max-h-60 object-contain border shadow-sm mx-auto">
                                            <p class="text-center text-[10px] text-slate-400 mt-1">Page {{p.page_num}}</p>
                                        </div>
                                        <!-- Text toggled -->
                                        <div v-if="item.showDocs" class="w-2/3 text-xs prose" v-html="md(lang === 'en' ? (p.desc_en || p.desc) : p.desc)"></div>
                                    </div>
                                </div>

                                <!-- [Fix] PPT Slides -->
                                <div v-if="item.slides" class="space-y-4">
                                    <div v-for="s in item.slides" :key="s.slide_num" class="bg-white p-3 rounded border">
                                        <div class="flex justify-between mb-2">
                                            <div class="text-xs font-bold text-indigo-600">Slide {{s.slide_num}}</div>
                                        </div>
                                        
                                        <!-- Extracted Images (Always Visible) -->
                                        <div v-if="s.images && s.images.length" class="grid grid-cols-2 gap-2 mb-2">
                                            <div v-for="(img, imx) in s.images" :key="imx" class="bg-slate-50 p-2 text-center">
                                                <img :src="'data:image/jpeg;base64,'+img.b64" class="max-h-40 mx-auto object-contain bg-white border">
                                                <!-- Image Description Toggle -->
                                                <p v-if="item.showDocs" class="text-[10px] text-slate-500 mt-1 bg-white p-1 rounded">{{ img.desc }}</p>
                                            </div>
                                        </div>

                                        <!-- Slide Text (Toggled) -->
                                        <div v-if="item.showDocs" class="text-xs prose border-t pt-2 mt-2 whitespace-pre-wrap max-h-32 overflow-y-auto bg-slate-50 p-2 rounded">
                                            {{ s.text }}
                                        </div>
                                    </div>
                                </div>

                                <!-- Summary Text (Toggled) -->
                                <div v-if="item.showDocs" class="text-xs text-slate-600 mt-2 prose bg-slate-50 p-3 rounded" v-html="md(lang === 'en' ? (item.summary_en || item.summary) : item.summary)"></div>
                                
                                <!-- Log (Toggled) -->
                                <div v-if="item.log && item.log.length > 0 && item.showDocs" class="mt-2 p-2 bg-gray-100 rounded border text-[10px] font-mono text-gray-600">
                                    <strong>‚öôÔ∏è Log:</strong> {{ item.log.join(' ‚Üí ') }}
                                </div>

                            </div>
                        </section>
                    </div>
                </div>
            </div>
        </main>
    </div>
    <script>
        const { createApp, ref, computed, nextTick } = Vue;
        createApp({
            setup() {
                const stagedFiles = ref([]);
                const isAnalyzing = ref(false);
                const isTranslating = ref(false);
                const result = ref(null);
                const lang = ref('ko'); 
                const translatedReport = ref('');
                const md = (t) => marked.parse(t||'');

                const displayReport = computed(() => lang.value === 'en' && translatedReport.value ? translatedReport.value : (result.value ? result.value.final_report : ''));

                const addFiles = (e) => {
                    Array.from(e.target.files).forEach(f => {
                        let eq = 'General';
                        if(f.name.match(/\.(pdf|ppt|pptx)$/i)) eq = 'Document';
                        stagedFiles.value.push({ file: f, equipment: eq, goal: '', mode: 'Auto', view: 'proc', showDocs: true });
                    });
                    e.target.value = ''; 
                };
                const removeFile = (i) => stagedFiles.value.splice(i, 1);

                const analyze = async () => {
                    isAnalyzing.value = true;
                    lang.value = 'ko'; 
                    translatedReport.value = '';
                    const fd = new FormData();
                    const configs = {};
                    stagedFiles.value.forEach(item => {
                        fd.append('files', item.file);
                        configs[item.file.name] = { equipment: item.equipment, goal: item.goal, mode: item.mode };
                    });
                    fd.append('file_configs', JSON.stringify(configs));

                    try {
                        const res = await fetch('/api/analyze', { method: 'POST', body: fd });
                        const data = await res.json();
                        // Initialize showDocs to true
                        if(data.results) data.results.forEach(r => r.showDocs = true);
                        result.value = data;
                        await nextTick();
                        
                        data.results.forEach((item, i) => {
                            if(item.chart_data) {
                                const raw = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_raw), mode:'lines', name:'Raw', line:{color:'#cbd5e1', width:1} };
                                const proc = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_proc), mode:'lines', name:'Proc', line:{color:'#4f46e5', width:2} };
                                const base = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_base), mode:'lines', name:'Base', line:{color:'#f59e0b', width:1, dash:'dot'} };
                                Plotly.newPlot('chart-'+i, [raw, base, proc], {margin:{t:10,b:30,l:40,r:10}, showlegend:false}, {displayModeBar:false});
                            }
                        });
                        lucide.createIcons();
                    } catch(e) { alert(e); } 
                    finally { isAnalyzing.value = false; }
                };

                const setLang = async (target) => {
                    if (target === 'ko') { lang.value = 'ko'; return; }
                    if (target === 'en') {
                        if (translatedReport.value) { lang.value = 'en'; return; }
                        isTranslating.value = true;
                        try {
                            const res = await fetch('/api/translate', {
                                method: 'POST', headers: {'Content-Type': 'application/json'},
                                body: JSON.stringify({ text: result.value.final_report })
                            });
                            const data = await res.json();
                            translatedReport.value = data.translated;
                            lang.value = 'en';
                        } catch(e) { alert("Trans Error: " + e); }
                        finally { isTranslating.value = false; }
                    }
                };
                
                const dlPDF = () => html2pdf().set({ margin:10, filename:'V14_1_Report.pdf', image:{type:'jpeg',quality:0.98}, html2canvas:{scale:2}, jsPDF:{unit:'mm',format:'a4'} }).from(document.getElementById('report-view')).save();

                setTimeout(()=>lucide.createIcons(), 100);
                return { stagedFiles, isAnalyzing, isTranslating, result, lang, displayReport, addFiles, removeFile, analyze, md, dlPDF, setLang };
            }
        }).mount('#app');
    </script>
</body>
</html>


