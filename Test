ë¸Œì´10 ìˆ˜ì •
import os
import io
import asyncio
import base64
import json
import re
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# ==========================================
# [1] ë„¤íŠ¸ì›Œí¬/ë³´ì•ˆ ì„¤ì • (í•„ìˆ˜)
# ==========================================
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚° ë° ì´ë¯¸ì§€ ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
from scipy.signal import find_peaks, savgol_filter
from scipy.ndimage import label, find_objects
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# ==========================================
# [2] ëª¨ë¸ ë° ì„œë²„ ì„¤ì •
# ==========================================
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)

VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# ==========================================
# [3] ê³¼í•™ ì²˜ë¦¬ ì—”ì§„ (Science Core)
# ==========================================
class ScienceProcessorV10:
    
    @staticmethod
    def detect_footer_boundary(img_array):
        """ì´ë¯¸ì§€ í•˜ë‹¨ ì •ë³´ë°”(Info Bar) ìŠ¤ë§ˆíŠ¸ ê°ì§€"""
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            
            # í•˜ë‹¨ 25%ë§Œ íƒìƒ‰
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            
            # ì—£ì§€ ê²€ì¶œ ë° ìˆ˜í‰ íˆ¬ì˜
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            
            if np.max(row_sums) < (w * 30): return None # ì—£ì§€ê°€ ì•½í•˜ë©´ ì •ë³´ë°” ì—†ìŒ
            
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None # ë§¨ ëì´ë©´ ë¬´ì‹œ
            
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def simple_baseline(y):
        """ë² ì´ìŠ¤ë¼ì¸ ì¶”ì •"""
        window = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=window, center=True).min()
        baseline = s.bfill().ffill().values 
        
        if len(baseline) > 51:
            baseline = savgol_filter(baseline, window_length=51, polyorder=3)
        return baseline

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        """ìŠ¤í™íŠ¸ëŸ¼ ë°ì´í„° ì „ì²˜ë¦¬"""
        y_raw = y.copy()
        
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {
                "x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y),
                "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks],
                "log": ["Raw Data (No Processing)"]
            }

        # íŒŒë¼ë¯¸í„° ì„¤ì •
        window = 15
        if mode == "AI-Adaptive" and "noise" in goal.lower(): window = 31
        
        # ì²˜ë¦¬: Baseline -> Smoothing -> Peak Finding
        base = ScienceProcessorV10.simple_baseline(y)
        y_proc = np.maximum(y - base, 0)
        
        if len(y_proc) > window:
            y_proc = savgol_filter(y_proc, window, 3)
        
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)

        return {
            "x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base,
            "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks],
            "log": ["Processed"]
        }

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        # 1. Smart Crop
        body_img = img_raw
        footer_img = None
        split_y = ScienceProcessorV10.detect_footer_boundary(img_raw)
        
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
        
        # ì¸ì½”ë”© ì¤€ë¹„
        _, buf_body = cv2.imencode('.jpg', body_img)
        b64_body = base64.b64encode(buf_body).decode('utf-8')
        
        b64_footer = None
        if footer_img is not None:
            _, buf_f = cv2.imencode('.jpg', footer_img)
            b64_footer = base64.b64encode(buf_f).decode('utf-8')

        # Mode: Noneì´ë©´ ì—¬ê¸°ì„œ ì¢…ë£Œ
        if mode == "None":
            return {
                "raw_b64": b64_body, "proc_b64": b64_body, "footer_b64": b64_footer,
                "stats": {"info": "Cropped Raw Image"}
            }

        # 2. Auto-Invert (í° ë°°ê²½ ëŒ€ì‘)
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        is_bright = np.mean(gray) > 127
        gray_proc = cv2.bitwise_not(gray) if is_bright else gray
        
        # Denoise
        gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
        overlay = body_img.copy()
        stats = {"bg": "Bright (Inverted)" if is_bright else "Dark"}

        # 3. Detection Logic
        detect_atoms = False
        detect_particles = False
        
        kwd = (equipment + " " + goal).lower()
        if any(x in kwd for x in ["atom", "stem", "tem"]): detect_atoms = True
        if any(x in kwd for x in ["particle", "sem", "optical", "bf", "pl"]): detect_particles = True

        if detect_atoms:
            blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
            for y, x, r in blobs:
                cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
            stats["count"] = len(blobs)
            stats["type"] = "Atoms"
            
        elif detect_particles:
            _, thresh = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            cnts, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
            stats["count"] = len(cnts)
            stats["type"] = "Particles"

        _, buf_proc = cv2.imencode('.jpg', overlay)
        
        return {
            "raw_b64": b64_body,
            "proc_b64": base64.b64encode(buf_proc).decode('utf-8'),
            "footer_b64": b64_footer,
            "stats": stats
        }

# ==========================================
# [4] í—¬í¼ í•¨ìˆ˜
# ==========================================
def detect_excel_blocks(df):
    """ì—‘ì…€ ì•„ì¼ëœë“œ ê°ì§€"""
    blocks = []
    if df.empty: return blocks
    mask = ~df.isnull().to_numpy()
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    """Vision LLM í˜¸ì¶œ Wrapper"""
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(
            ollama_client.chat, 
            model=VISION_MODEL, 
            messages=[{'role':'user','content':prompt,'images':[b64]}]
        )
        return res['message']['content']
    except Exception as e: return f"[Vision Error: {e}]"

# ==========================================
# [5] FastAPI ë¼ìš°í„° ë° ë¡œì§
# ==========================================
app = FastAPI(title="Analyst V10 Full")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# ë²ˆì—­ ìš”ì²­ ëª¨ë¸
class TranslateReq(BaseModel):
    text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    """ì˜ë¬¸ ë²ˆì—­ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        sys_prompt = "You are a professional scientific translator. Translate the text to English. Preserve markdown."
        res = await asyncio.to_thread(
            ollama_client.chat,
            model=TEXT_MODEL,
            messages=[{'role': 'system', 'content': sys_prompt}, {'role': 'user', 'content': req.text}]
        )
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": f"Error: {e}"}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V10 Processing {len(files)} files")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        
        eq = config.get("equipment", "General")
        goal = config.get("goal", "")
        mode = config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # -------------------------------------------------
        # [A] Document Path (PDF/PPT) - ì „ì²˜ë¦¬ ê±´ë„ˆëœ€
        # -------------------------------------------------
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def process_doc(c, n, e):
                try:
                    # PDF ì²˜ë¦¬
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10] # ìµœëŒ€ 10í˜ì´ì§€
                        full_txt = ""
                        pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO()
                            img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            
                            # â˜… ê°•ì œ í•œê¸€ ìš”ì•½
                            desc = await analyze_vision_ollama(buf.getvalue(), "ì´ í˜ì´ì§€ ë‚´ìš©ì„ í•œê¸€ë¡œ ìš”ì•½í•´ì¤˜. í‘œë‚˜ ê·¸ë¦¼ì´ ìˆë‹¤ë©´ ì„¤ëª…í•´ì¤˜.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                            
                        return {
                            "type": "pdf", "filename": n, "equipment": "Literature",
                            "raw_context": full_txt, "pages": pages 
                        }
                    
                    # PPT ì²˜ë¦¬
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []
                        full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""
                            imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        idesc = await analyze_vision_ollama(s.image.blob, "ì´ ê·¸ë¦¼ì„ í•œê¸€ë¡œ ì„¤ëª…í•´.")
                                        imgs.append({"b64": ib64, "desc": idesc})
                                    except: pass
                            
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                            
                        return {
                            "type": "ppt", "filename": n, "equipment": "Literature",
                            "raw_context": full_txt, "slides": slides
                        }
                        
                except Exception as e:
                    return {"type": "error", "filename": n, "msg": str(e)}
            
            tasks.append(process_doc(content, filename, eq))
            continue

        # -------------------------------------------------
        # [B] Data Path (Excel/Image/CSV) - ì „ì²˜ë¦¬ ìˆ˜í–‰
        # -------------------------------------------------
        
        # 1. Excel (Spectrum)
        if fname_lower.endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for sheet_name in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=sheet_name, header=None)
                    blocks = detect_excel_blocks(df)
                    for i, block in enumerate(blocks):
                        async def proc_xls(blk, sname, idx):
                            try:
                                num_block = blk.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                                if not num_block.empty and num_block.shape[0] > 5:
                                    x = num_block.iloc[:, 0].fillna(0).values
                                    y = num_block.iloc[:, 1].fillna(0).values
                                    
                                    # V10 Process
                                    res = ScienceProcessorV10.process_spectrum(x, y, mode, goal)
                                    
                                    step = max(1, len(x)//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                    
                                    # Contextìš© í…ìŠ¤íŠ¸
                                    txt = block.to_csv(index=False, header=False)[:500]
                                    return {
                                        "type": "spectrum", "filename": f"{filename} ({sname}-{idx+1})",
                                        "equipment": eq,
                                        "raw_context": f"Spectrum Data ({eq}). Peaks: {len(res['peaks'])}\n{txt}",
                                        "chart_data": chart, "log": res["log"]
                                    }
                            except: return None
                        tasks.append(proc_xls(block, sheet_name, i))
            except Exception as e: pass

        # 2. Image (Microscopy)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    # V10 Process (Smart Crop -> Invert -> Analysis)
                    vis_res = ScienceProcessorV10.process_image(c, e, m, g)
                    if not vis_res: return {"type": "error", "filename": n, "msg": "Image failed"}
                    
                    # Footer OCR (ë©”íƒ€ë°ì´í„° ì½ê¸°)
                    meta_text = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta_text = await analyze_vision_ollama(fb, "Read scale bar, voltage, magnification.")
                    
                    # Body Analysis (í•œê¸€ ê°•ì œ)
                    body_bytes = base64.b64decode(vis_res["proc_b64"])
                    prompt = f"""
                    ì´ {e} ì´ë¯¸ì§€ë¥¼ í•œê¸€ë¡œ ì •ë°€ ë¶„ì„í•´ì¤˜.
                    ì‚¬ìš©ì ëª©í‘œ: {g}.
                    ì´ë¯¸ì§€ í†µê³„(CV): {vis_res['stats']}.
                    ë©”íƒ€ë°ì´í„°: {meta_text}.
                    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³¼í•™ì  ì˜ë¯¸ë¥¼ í•´ì„í•´.
                    """
                    desc = await analyze_vision_ollama(body_bytes, prompt)
                    
                    return {
                        "type": "image", "filename": n, "equipment": e,
                        "summary": desc,
                        "raw_context": f"Image Analysis ({e}): {desc}\nMetadata: {meta_text}\nStats: {vis_res['stats']}",
                        "raw_b64": vis_res["raw_b64"],
                        "proc_b64": vis_res["proc_b64"],
                        "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res["stats"]
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))
            
        # 3. CSV Spectrum
        elif fname_lower.endswith(('.csv', '.txt')):
             async def proc_csv(c, n, e, g, m):
                try:
                    try: df = pd.read_csv(io.BytesIO(c))
                    except: df = pd.read_csv(io.BytesIO(c), delimiter='\t')
                    x = df.iloc[:, 0].values
                    y = df.iloc[:, 1].values
                    res = ScienceProcessorV10.process_spectrum(x, y, mode, g)
                    step = max(1, len(x)//100)
                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                    return {
                        "type": "spectrum", "filename": n, "equipment": e,
                        "chart_data": chart,
                        "raw_context": f"Spectrum Peaks: {len(res['peaks'])}",
                        "log": res["log"]
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
             tasks.append(proc_csv(content, filename, eq, goal, mode))

    if tasks:
        # 500 ì—ëŸ¬ ë°©ì§€ìš© return_exceptions=True
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, dict): final_results.append(r)

    # Synthesis (Korean Default)
    data_ctx, lit_ctx = "", ""
    for r in final_results:
        if r and r.get("type") != "error":
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
            
    final_report = "ë¶„ì„ ì‹¤íŒ¨"
    if data_ctx or lit_ctx:
        try:
            # â˜… ê°•ì œ í•œê¸€ ì¢…í•© ë¦¬í¬íŠ¸
            prompt = """
            ë‹¹ì‹ ì€ ìˆ˜ì„ ì—°êµ¬ì›ì…ë‹ˆë‹¤.
            ì œê³µëœ 'ì‹¤í—˜ ë°ì´í„°(Data)'ì™€ 'ì°¸ê³  ë¬¸í—Œ(Literature)'ì„ ì¢…í•©í•˜ì—¬, ë…¼ë¦¬ì ì´ê³  ê³¼í•™ì ì¸ ì—°êµ¬ ë³´ê³ ì„œë¥¼ **í•œê¸€**ë¡œ ì‘ì„±í•˜ì„¸ìš”.
            ë§ˆí¬ë‹¤ìš´ í‘œ(Table)ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì¹˜ë¥¼ ë¹„êµí•˜ì„¸ìš”.
            """
            final_input = f"--- Data ---\n{data_ctx}\n\n--- Literature ---\n{lit_ctx}"
            
            res = await asyncio.to_thread(
                ollama_client.chat,
                model=TEXT_MODEL,
                messages=[{'role':'system','content':prompt}, {'role':'user','content':final_input}]
            )
            final_report = res['message']['content']
        except Exception as e: final_report = f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

    return {"results": final_results, "final_report": final_report}

# â˜… [Fix] ëˆ„ë½ë˜ì—ˆë˜ HTML ì„œë¹™ ë¼ìš°í„° ë³µêµ¬
@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>index.html not found. Please upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)








ë¸Œì´10
import os
import io
import asyncio
import base64
import json
from typing import List, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆë§/í”„ë¡ì‹œ ìš°íšŒ
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.ndimage import label, find_objects
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- V10 ê³¼í•™ ì—”ì§„ (V9ì™€ ë™ì¼, ì•ˆì „ì„± ìœ ì§€) ---
class ScienceProcessorV10:
    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        y_raw = y.copy()
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks]}

        window = 15
        if mode == "AI-Adaptive" and "noise" in goal.lower(): window = 31
        
        # V9 Fix: Pandas Future Warning í•´ê²°
        s = pd.Series(y).rolling(window=max(5, len(y)//10), center=True).min()
        baseline = s.bfill().ffill().values 
        if len(baseline) > 51: baseline = savgol_filter(baseline, 51, 3)
        
        y_proc = np.maximum(y - baseline, 0)
        if len(y_proc) > window: y_proc = savgol_filter(y_proc, window, 3)
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)

        return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": baseline, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks]}

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        # Smart Crop
        body_img, footer_img, split_y = img_raw, None, ScienceProcessorV10.detect_footer_boundary(img_raw)
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
        
        _, buf_body = cv2.imencode('.jpg', body_img)
        b64_body = base64.b64encode(buf_body).decode('utf-8')
        b64_footer = None
        if footer_img is not None:
            _, buf_f = cv2.imencode('.jpg', footer_img)
            b64_footer = base64.b64encode(buf_f).decode('utf-8')

        if mode == "None":
            return {"raw_b64": b64_body, "proc_b64": b64_body, "footer_b64": b64_footer, "stats": {"info": "Cropped Raw"}}

        # Auto-Invert
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        is_bright = np.mean(gray) > 127
        gray_proc = cv2.bitwise_not(gray) if is_bright else gray
        gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
        overlay = body_img.copy()
        
        stats = {"bg": "Bright (Inverted)" if is_bright else "Dark"}
        kwd = (equipment + " " + goal).lower()
        
        # Detection
        if any(x in kwd for x in ["atom", "stem", "tem"]):
            blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
            for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
            stats["count"] = len(blobs)
        elif any(x in kwd for x in ["particle", "sem", "optical", "bf", "pl"]):
            _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
            stats["count"] = len(cnts)

        _, buf_proc = cv2.imencode('.jpg', overlay)
        return {"raw_b64": b64_body, "proc_b64": base64.b64encode(buf_proc).decode('utf-8'), "footer_b64": b64_footer, "stats": stats}

# --- Helper ---
def detect_excel_blocks(df):
    blocks = []
    if df.empty: return blocks
    mask = ~df.isnull().to_numpy()
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        return res['message']['content']
    except Exception as e: return str(e)

# --- API ---
app = FastAPI(title="Analyst V10")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# [New] ë²ˆì—­ ìš”ì²­ ëª¨ë¸
class TranslateReq(BaseModel):
    text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    """í…ìŠ¤íŠ¸ë¥¼ ì˜ë¬¸ìœ¼ë¡œ ë²ˆì—­í•˜ëŠ” ì „ìš© ì—”ë“œí¬ì¸íŠ¸"""
    try:
        system_prompt = "You are a professional translator. Translate the following scientific text into English. Maintain markdown formatting (headers, tables, bold)."
        res = await asyncio.to_thread(
            ollama_client.chat,
            model=TEXT_MODEL,
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': req.text}
            ]
        )
        return {"translated": res['message']['content']}
    except Exception as e:
        return {"translated": f"[Translation Error] {str(e)}"}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V10 Processing {len(files)} files")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq = config.get("equipment", "General")
        goal = config.get("goal", "")
        mode = config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document (Literature)
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def process_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""
                        pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO()
                            img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            # â˜… ê°•ì œ í•œê¸€ ìš”ì•½
                            desc = await analyze_vision_ollama(buf.getvalue(), "ì´ í˜ì´ì§€ë¥¼ í•œê¸€ë¡œ ìš”ì•½í•´ì¤˜. í‘œë‚˜ ê·¸ë¦¼ì´ ìˆë‹¤ë©´ ìì„¸íˆ ì„¤ëª…í•´ì¤˜.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Literature", "raw_context": full_txt, "pages": pages}
                    
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []
                        full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""
                            imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "ì´ ê·¸ë¦¼ì„ í•œê¸€ë¡œ ì„¤ëª…í•´ì¤˜.")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Literature", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(process_doc(content, filename, eq))
            continue

        # [B] Data (Spectrum/Image)
        if fname_lower.endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for sheet_name in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=sheet_name, header=None)
                    blocks = detect_excel_blocks(df)
                    for i, block in enumerate(blocks):
                        async def proc_xls(blk, sname, idx):
                            try:
                                num_block = blk.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                                if not num_block.empty and num_block.shape[0] > 5:
                                    x = num_block.iloc[:, 0].fillna(0).values
                                    y = num_block.iloc[:, 1].fillna(0).values
                                    res = ScienceProcessorV10.process_spectrum(x, y, mode, goal)
                                    step = max(1, len(x)//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                    return {
                                        "type": "spectrum", "filename": f"{filename} ({sname}-{idx+1})",
                                        "equipment": eq, "raw_context": f"Spectrum Data. Peaks: {len(res['peaks'])}",
                                        "chart_data": chart
                                    }
                            except: return None
                        tasks.append(proc_xls(block, sheet_name, i))
            except: pass

        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV10.process_image(c, e, m, g)
                    body = base64.b64decode(vis_res["proc_b64"])
                    # â˜… ê°•ì œ í•œê¸€ ë¶„ì„
                    desc = await analyze_vision_ollama(body, f"ì´ {e} ì´ë¯¸ì§€ë¥¼ í•œê¸€ë¡œ ë¶„ì„í•´ì¤˜. ëª©í‘œ: {g}. íŠ¹ì§•: {vis_res['stats']}")
                    
                    return {
                        "type": "image", "filename": n, "equipment": e,
                        "summary": desc, "raw_context": f"Image: {desc}\nStats: {vis_res['stats']}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res["stats"]
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))
            
        elif fname_lower.endswith(('.csv', '.txt')):
             async def proc_csv(c, n, e, g, m):
                try:
                    try: df = pd.read_csv(io.BytesIO(c))
                    except: df = pd.read_csv(io.BytesIO(c), delimiter='\t')
                    x = df.iloc[:, 0].values
                    y = df.iloc[:, 1].values
                    res = ScienceProcessorV10.process_spectrum(x, y, mode, g)
                    step = max(1, len(x)//100)
                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                    return {"type": "spectrum", "filename": n, "equipment": e, "chart_data": chart, "raw_context": f"Spectrum Peaks: {len(res['peaks'])}"}
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
             tasks.append(proc_csv(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, dict): final_results.append(r)

    # Synthesis (Korean Default)
    data_ctx, lit_ctx = "", ""
    for r in final_results:
        if r and r.get("type") != "error":
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
            
    final_report = "ë¶„ì„ ì‹¤íŒ¨"
    if data_ctx or lit_ctx:
        try:
            # â˜… ê°•ì œ í•œê¸€ ì¢…í•©
            prompt = "ë‹¹ì‹ ì€ ìˆ˜ì„ ì—°êµ¬ì›ì…ë‹ˆë‹¤. ì‹¤í—˜ ë°ì´í„°(Data)ì™€ ë¬¸í—Œ(Literature)ì„ ì¢…í•©í•˜ì—¬ í•œê¸€ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”. í‘œ(Table)ë¥¼ ì ê·¹ í™œìš©í•˜ì„¸ìš”."
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':prompt}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLiterature:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>AI Research Center V10</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        body { font-family: 'Inter', sans-serif; }
        .prose table { border-collapse: collapse; width: 100%; margin: 1em 0; }
        .prose th, .prose td { border: 1px solid #cbd5e1; padding: 8px; font-size: 0.9rem; }
        .prose th { background-color: #f1f5f9; }
        .loader { border: 3px solid #f3f3f3; border-top: 3px solid #6366f1; border-radius: 50%; width: 20px; height: 20px; animation: spin 1s linear infinite; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-slate-100 text-slate-800">
    <div id="app" class="min-h-screen p-6">
        <header class="max-w-7xl mx-auto mb-6 flex items-center gap-3">
            <div class="bg-indigo-600 p-2 rounded-lg shadow"><i data-lucide="globe" class="w-6 h-6 text-white"></i></div>
            <div><h1 class="text-2xl font-bold">AI Research Center V10</h1><p class="text-xs text-slate-500">Global Language Hub â€¢ Translation Tab</p></div>
        </header>

        <main class="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6">
            
            <!-- Staging -->
            <div class="lg:col-span-4 space-y-4">
                <div class="bg-white p-5 rounded-xl shadow-sm border border-slate-200">
                    <h2 class="font-bold mb-3 flex items-center gap-2"><i data-lucide="files" class="w-4 h-4"></i> Data Staging</h2>
                    <div class="border-2 border-dashed border-slate-300 rounded-lg p-6 text-center hover:bg-indigo-50 cursor-pointer" @click="$refs.f.click()">
                        <input type="file" ref="f" multiple class="hidden" @change="addFiles">
                        <p class="text-sm font-semibold text-slate-600">Add Files</p>
                    </div>
                    <div v-if="stagedFiles.length" class="mt-4 space-y-3 max-h-[60vh] overflow-y-auto pr-1">
                        <div v-for="(item, i) in stagedFiles" :key="i" class="p-3 bg-slate-50 border rounded-lg text-sm">
                            <div class="flex justify-between items-center mb-2">
                                <span class="font-bold truncate w-2/3" :title="item.file.name">{{ item.file.name }}</span>
                                <button @click="removeFile(i)" class="text-red-400 hover:text-red-600"><i data-lucide="trash-2" class="w-4 h-4"></i></button>
                            </div>
                            <div class="grid grid-cols-1 gap-2">
                                <select v-model="item.equipment" class="w-full p-1.5 border rounded text-xs bg-white font-semibold text-indigo-700">
                                    <optgroup label="Literature">
                                        <option value="Document">Document (PDF/PPT)</option>
                                    </optgroup>
                                    <optgroup label="Spectroscopy">
                                        <option value="XRD">XRD</option>
                                        <option value="EDS">EDS / EDX</option>
                                        <option value="EELS">EELS</option>
                                        <option value="Raman">Raman</option>
                                        <option value="FT-IR">FT-IR</option>
                                        <option value="NMR">NMR</option>
                                        <option value="XPS">XPS</option>
                                        <option value="PL">Photo-Luminescence</option>
                                        <option value="Mass">Mass Spectroscopy</option>
                                    </optgroup>
                                    <optgroup label="Microscopy">
                                        <option value="SEM">SEM</option>
                                        <option value="TEM">TEM</option>
                                        <option value="STEM">STEM</option>
                                        <option value="AFM">AFM</option>
                                        <option value="Optical BF">Optical (Bright Field)</option>
                                        <option value="Optical PL">Optical (PL)</option>
                                    </optgroup>
                                </select>
                                <select v-if="item.equipment !== 'Document'" v-model="item.mode" class="w-full p-1.5 border rounded text-xs bg-white text-indigo-700">
                                    <option value="Auto">âœ¨ Auto Process</option>
                                    <option value="None">ğŸš« None (Raw)</option>
                                    <option value="AI-Adaptive">ğŸ§  AI-Adaptive</option>
                                </select>
                                <input v-if="item.equipment !== 'Document'" v-model="item.goal" type="text" placeholder="Goal (e.g. Count particles)" class="w-full p-1.5 border rounded text-xs">
                            </div>
                        </div>
                    </div>
                    <button @click="analyze" :disabled="isAnalyzing || stagedFiles.length===0" class="w-full mt-4 py-3 bg-indigo-600 text-white rounded-lg font-bold flex justify-center gap-2 shadow hover:bg-indigo-700 disabled:opacity-50">
                        <div v-if="isAnalyzing" class="loader"></div>
                        <span>Generate Report (Korean)</span>
                    </button>
                </div>
            </div>

            <!-- Report Area -->
            <div class="lg:col-span-8">
                <div v-if="result" class="space-y-6 animate-fade-in">
                    
                    <!-- Language Tabs -->
                    <div class="flex items-center gap-2 bg-white p-2 rounded-xl shadow-sm border border-slate-200 w-fit">
                        <button @click="setLang('ko')" :class="lang==='ko'?'bg-indigo-100 text-indigo-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">
                            <span>ğŸ‡°ğŸ‡·</span> í•œê¸€ (Original)
                        </button>
                        <button @click="setLang('en')" :class="lang==='en'?'bg-blue-100 text-blue-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">
                            <div v-if="isTranslating" class="w-3 h-3 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                            <span v-else>ğŸ‡ºğŸ‡¸</span> English (Translate)
                        </button>
                    </div>

                    <div id="report-view" class="bg-white p-8 rounded-xl shadow-sm border border-slate-200">
                        <div class="flex justify-between items-end border-b pb-4 mb-6">
                            <div><h1 class="text-2xl font-bold text-slate-900">Comprehensive Report</h1><p class="text-xs text-slate-500">{{ new Date().toLocaleString() }}</p></div>
                            <button @click="dlPDF" class="px-3 py-1.5 bg-slate-800 text-white text-xs rounded">PDF Export</button>
                        </div>

                        <!-- Synthesis -->
                        <section class="mb-10">
                            <h2 class="text-lg font-bold text-indigo-700 mb-3 border-b pb-1">1. Synthesis</h2>
                            <div class="prose prose-sm text-slate-700 max-w-none" v-html="md(displayReport)"></div>
                        </section>

                        <!-- Details -->
                        <section>
                            <h2 class="text-lg font-bold text-slate-800 mb-5 border-b pb-1">2. Data Evidence</h2>
                            <div v-for="(item, idx) in result.results" :key="idx" class="mb-8 p-4 bg-slate-50 rounded-lg border break-inside-avoid">
                                <div class="flex items-center gap-2 mb-3">
                                    <span class="px-2 py-0.5 bg-white border rounded text-[10px] font-bold uppercase text-slate-500">{{ item.equipment }}</span>
                                    <h3 class="font-bold text-sm">{{ item.filename }}</h3>
                                </div>

                                <!-- Spectrum -->
                                <div v-if="item.chart_data" class="bg-white p-2 rounded border mb-3">
                                    <div :id="'chart-'+idx" class="w-full h-60"></div>
                                </div>

                                <!-- Image -->
                                <div v-if="item.raw_b64" class="bg-white p-2 rounded border mb-3">
                                    <div class="flex gap-2 mb-2 text-xs justify-center">
                                        <button @click="item.view='proc'" :class="item.view!=='raw'?'font-bold text-indigo-600':''">Processed</button>
                                        <span class="text-slate-300">|</span>
                                        <button @click="item.view='raw'" :class="item.view==='raw'?'font-bold text-indigo-600':''">Original</button>
                                        <span class="text-slate-300" v-if="item.footer_b64">|</span>
                                        <button v-if="item.footer_b64" @click="item.view='footer'" :class="item.view==='footer'?'font-bold text-indigo-600':''">Info Bar</button>
                                    </div>
                                    <img v-if="item.view!=='footer'" :src="'data:image/jpeg;base64,' + (item.view==='raw' ? item.raw_b64 : item.proc_b64)" class="max-h-80 mx-auto object-contain bg-black">
                                    <img v-if="item.view==='footer'" :src="'data:image/jpeg;base64,' + item.footer_b64" class="max-h-24 mx-auto object-contain border mt-2">
                                </div>

                                <!-- Docs -->
                                <div v-if="item.pages" class="grid grid-cols-1 gap-4">
                                    <div v-for="p in item.pages" :key="p.page_num" class="flex gap-3 bg-white p-3 rounded border">
                                        <img :src="'data:image/jpeg;base64,'+p.image_b64" class="w-24 object-contain border">
                                        <!-- Document Text Display (Lang aware) -->
                                        <div class="text-xs prose" v-html="md(lang === 'en' ? (p.desc_en || p.desc) : p.desc)"></div>
                                    </div>
                                </div>
                                <div v-if="item.slides" class="text-xs text-slate-600">PPT Slides (Check Synthesis)</div>

                                <!-- Summary Text Display (Lang aware) -->
                                <div class="text-xs text-slate-600 mt-2 prose" v-html="md(lang === 'en' ? (item.summary_en || item.summary) : item.summary)"></div>
                            </div>
                        </section>
                    </div>
                </div>
            </div>
        </main>
    </div>
    <script>
        const { createApp, ref, computed, nextTick } = Vue;
        createApp({
            setup() {
                const stagedFiles = ref([]);
                const isAnalyzing = ref(false);
                const isTranslating = ref(false);
                const result = ref(null);
                const lang = ref('ko'); // 'ko' or 'en'
                const translatedReport = ref('');

                const renderer = new marked.Renderer(); renderer.image = () => ''; marked.use({ renderer });
                const md = (t) => marked.parse(t||'');

                const displayReport = computed(() => lang.value === 'en' && translatedReport.value ? translatedReport.value : (result.value ? result.value.final_report : ''));

                const addFiles = (e) => {
                    Array.from(e.target.files).forEach(f => {
                        let eq = 'General';
                        if(f.name.match(/\.(pdf|ppt|pptx)$/i)) eq = 'Document';
                        stagedFiles.value.push({ file: f, equipment: eq, goal: '', mode: 'Auto', view: 'proc' });
                    });
                    e.target.value = ''; 
                };
                const removeFile = (i) => stagedFiles.value.splice(i, 1);

                const analyze = async () => {
                    isAnalyzing.value = true;
                    lang.value = 'ko'; // Reset to Korean on new analysis
                    translatedReport.value = '';
                    
                    const fd = new FormData();
                    const configs = {};
                    stagedFiles.value.forEach(item => {
                        fd.append('files', item.file);
                        configs[item.file.name] = { equipment: item.equipment, goal: item.goal, mode: item.mode };
                    });
                    fd.append('file_configs', JSON.stringify(configs));

                    try {
                        const res = await fetch('/api/analyze', { method: 'POST', body: fd });
                        const data = await res.json();
                        result.value = data;
                        await nextTick();
                        drawCharts(data.results);
                        lucide.createIcons();
                    } catch(e) { alert(e); } 
                    finally { isAnalyzing.value = false; }
                };

                const setLang = async (target) => {
                    if (target === 'ko') {
                        lang.value = 'ko';
                        return;
                    }
                    if (target === 'en') {
                        if (translatedReport.value) {
                            lang.value = 'en'; // Already translated
                            return;
                        }
                        // Need Translation
                        isTranslating.value = true;
                        try {
                            const res = await fetch('/api/translate', {
                                method: 'POST',
                                headers: {'Content-Type': 'application/json'},
                                body: JSON.stringify({ text: result.value.final_report })
                            });
                            const data = await res.json();
                            translatedReport.value = data.translated;
                            lang.value = 'en';
                        } catch(e) { alert("Translation Failed: " + e); }
                        finally { isTranslating.value = false; }
                    }
                };

                const drawCharts = (res) => {
                    res.forEach((item, i) => {
                        if(item.chart_data) {
                            const raw = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_raw), mode:'lines', name:'Raw', line:{color:'#cbd5e1', width:1} };
                            const proc = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_proc), mode:'lines', name:'Proc', line:{color:'#4f46e5', width:2} };
                            const base = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_base), mode:'lines', name:'Base', line:{color:'#f59e0b', width:1, dash:'dot'} };
                            Plotly.newPlot('chart-'+i, [raw, base, proc], {margin:{t:10,b:30,l:40,r:10}, showlegend:false}, {displayModeBar:false});
                        }
                    });
                };
                
                const dlPDF = () => html2pdf().set({ margin:10, filename:'V10_Report.pdf', image:{type:'jpeg',quality:0.98}, html2canvas:{scale:2}, jsPDF:{unit:'mm',format:'a4'} }).from(document.getElementById('report-view')).save();

                setTimeout(()=>lucide.createIcons(), 100);
                return { stagedFiles, isAnalyzing, isTranslating, result, lang, displayReport, addFiles, removeFile, analyze, md, dlPDF, setLang };
            }
        }).mount('#app');
    </script>
</body>
</html>


