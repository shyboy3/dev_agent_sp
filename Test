ë¸Œì´32 ìˆ˜ì • 

import pandas as pd
import plotly.graph_objects as go
import numpy as np

# ... (ì´ì „ì˜ íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬ ë¶€ë¶„ì€ ìœ ì§€í•œë‹¤ê³  ê°€ì •) ...

def plot_data(df):
    """
    ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ (ì´ìƒí•œ ì§ì„  ë° 3D ì¢Œí‘œ ë¬¸ì œ í•´ê²°)
    """
    
    # 1. ë°ì´í„° ì •ì œ: ê°•ì œë¡œ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•˜ê³  NaN ì œê±°
    # ì—‘ì…€ì˜ ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ì˜¤íƒ€ê°€ ìˆìœ¼ë©´ ê·¸ë˜í”„ê°€ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì»¬ëŸ¼ ì´ë¦„ì´ 'x', 'y'ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤. (ì‹¤ì œ ì»¬ëŸ¼ëª…ì— ë§ì¶° ìˆ˜ì • í•„ìš”)
    if 'x' not in df.columns or 'y' not in df.columns:
        # ì»¬ëŸ¼ ì´ë¦„ì´ ë‹¤ë¥´ë‹¤ë©´ ì²«ë²ˆì§¸, ë‘ë²ˆì§¸ ì»¬ëŸ¼ì„ ì‚¬ìš©
        df.columns = ['x', 'y'] + list(df.columns[2:])
    
    # ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ê°•ì œ ë³€í™˜ (ë¬¸ìê°€ ì„ì—¬ ìˆìœ¼ë©´ NaNìœ¼ë¡œ ë§Œë“¦)
    df['x'] = pd.to_numeric(df['x'], errors='coerce')
    df['y'] = pd.to_numeric(df['y'], errors='coerce')
    
    # NaNì´ í¬í•¨ëœ í–‰ ì œê±° (ì´ê²Œ ì—†ìœ¼ë©´ ì í”„í•˜ëŠ” ì„ ì´ ìƒê¹€)
    df = df.dropna(subset=['x', 'y'])

    # 2. ì¸ë±ìŠ¤ ë¦¬ì…‹ (ì¤‘ìš”!)
    # í•„í„°ë§ í›„ ì¸ë±ìŠ¤ê°€ ë’¤ì£½ë°•ì£½ì´ë©´(ì˜ˆ: 1, 5, 100...) 
    # ê·¸ë˜í”„ íˆ´ì´ ì¸ë±ìŠ¤ë¥¼ Zì¶•ìœ¼ë¡œ ì˜¤í•´í•˜ê±°ë‚˜, ì„  ì—°ê²° ìˆœì„œê°€ ê¼¬ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    df = df.reset_index(drop=True)

    # 3. í”Œë¡¯ ê·¸ë¦¬ê¸° (Plotly ì‚¬ìš© ê°€ì •)
    fig = go.Figure()

    # 3-1. Modeë¥¼ 'lines'ê°€ ì•„ë‹Œ 'markers'ë¡œ ë¨¼ì € í™•ì¸í•´ë³´ê¸° (ë””ë²„ê¹…ìš©)
    # ì„ ì´ íŠ€ëŠ” í˜„ìƒì´ ìˆìœ¼ë©´ ì ìœ¼ë¡œ ë¨¼ì € ì°ì–´ë³´ëŠ” ê²Œ ì¢‹ìŠµë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” ìµœì¢…ì ìœ¼ë¡œ ì„ +ì (lines+markers)ìœ¼ë¡œ ì„¤ì •í•˜ë˜,
    # connectgaps=Falseë¥¼ ì£¼ì–´ ë°ì´í„°ê°€ ëŠê¸´ ê³³ì—ì„œ ì„ ì„ ì‡ì§€ ì•Šê²Œ í•©ë‹ˆë‹¤.
    
    fig.add_trace(go.Scatter(
        x=df['x'],
        y=df['y'],
        mode='lines+markers', # ì„ ê³¼ ì  ëª¨ë‘ í‘œì‹œ
        name='Data Path',
        connectgaps=False,    # ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì„ ì„ ì–µì§€ë¡œ ì‡ì§€ ì•ŠìŒ (ì¤‘ìš”!)
        hovertemplate='X: %{x:.2f}<br>Y: %{y:.2f}<extra></extra>' # íˆ´íŒì— Zê°’(ì¸ë±ìŠ¤) ì•ˆ ë‚˜ì˜¤ê²Œ ê°•ì œ ì„¤ì •
    ))

    # 3-2. ë ˆì´ì•„ì›ƒ ì„¤ì • (2D ê³ ì •)
    fig.update_layout(
        title='2D Data Visualization (Cleaned)',
        xaxis_title='X Axis',
        yaxis_title='Y Axis',
        showlegend=True,
        # í™”ë©´ ë¹„ìœ¨ ê³ ì • (ë°ì´í„° ì™œê³¡ ë°©ì§€)
        yaxis=dict(
            scaleanchor="x",
            scaleratio=1,
        )
    )

    fig.show()

# --- (ì‹¤í–‰ ì˜ˆì‹œ) ---
# ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì‚¬ìš©ìì˜ ì—‘ì…€ íŒŒì¼ì„ ë¡œë“œí•˜ì„¸ìš”.
# df = pd.read_excel('ì‚¬ìš©ìíŒŒì¼.xlsx')
# plot_data(df)

# í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° ìƒì„± (ë¬¸ì œ ì¬í˜„ ì‹œë®¬ë ˆì´ì…˜)
data = {
    'x': [1, 2, 3, 4, 5, 1, 2], # ë§ˆì§€ë§‰ì— ë‹¤ì‹œ ëŒì•„ê°€ëŠ” êµ¬ì¡°
    'y': [1, 2, 1, 5, 2, 1, 2]
}
df_test = pd.DataFrame(data)
plot_data(df_test)




ë¸Œì´32

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, 
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V32 ê³¼í•™ ì—”ì§„ (Multi-Block Purifier)
# ==========================================
class ScienceProcessorV32:
    
    # --- [A] Data Parser (Purifier + Multi-Block) ---
    @staticmethod
    def parse_and_purify_csv(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V32 Fix] í…ìŠ¤íŠ¸ ì˜¤ì—¼ ì œê±° + ë‹¤ì¤‘ ë¸”ë¡ ë³´ì¡´
        """
        text_data = ""
        
        # 1. Excel ì‹œë„
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        # 2. í…ìŠ¤íŠ¸ ë””ì½”ë”©
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 3. ë¼ì¸ í•„í„°ë§ (Strict Numeric Check)
        valid_rows = []
        lines = text_data.splitlines()
        
        for line_idx, line in enumerate(lines):
            line = line.strip()
            if not line: continue
            
            # ìˆ«ì ì¶”ì¶œ
            nums = re.findall(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', line)
            if len(nums) < 2: continue # ìˆ«ìê°€ 1ê°œ ì´í•˜ë©´ ë°ì´í„° ì•„ë‹˜
            
            # ë¬¸ì ì˜¤ì—¼ ê²€ì‚¬ (ì•ŒíŒŒë²³ ì²´í¬)
            remains = re.sub(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', '', line)
            if re.search(r'[a-df-zA-DF-Z]', remains): continue # í—¤ë”ë¡œ ê°„ì£¼
            
            valid_rows.append((line_idx, [float(n) for n in nums]))
            
        if not valid_rows: return []
        
        # 4. ë‹¤ì¤‘ ë°ì´í„° êµ°ì§‘ ì¶”ì¶œ (Multi-Cluster)
        indices = [r[0] for r in valid_rows]
        if not indices: return []
        
        # ì¸ë±ìŠ¤ê°€ ì—°ì†ì ì¸ì§€ í™•ì¸ (Gap > 2ë©´ ë‹¤ë¥¸ ë¸”ë¡)
        diffs = np.diff(indices)
        is_new_block = diffs > 2
        # ê·¸ë£¹ ID ë¶€ì—¬ (0, 0, 0, 1, 1, 1, 2, 2...)
        group_ids = np.concatenate(([0], np.cumsum(is_new_block)))
        
        # [V32 Update] ëª¨ë“  ê·¸ë£¹ ìˆœíšŒ
        final_dfs = []
        unique_groups = np.unique(group_ids)
        
        for gid in unique_groups:
            # í•´ë‹¹ ê·¸ë£¹ì˜ ë°ì´í„°ë§Œ ì¶”ì¶œ
            group_data = [valid_rows[i][1] for i in range(len(valid_rows)) if group_ids[i] == gid]
            
            # ë„ˆë¬´ ì§§ì€ ë¸”ë¡(í—¤ë” ì”ì—¬ë¬¼)ì€ ë¬´ì‹œ (ì˜ˆ: 5ì¤„ ë¯¸ë§Œ)
            if len(group_data) < 5: continue
            
            # ì»¬ëŸ¼ ìˆ˜ í†µì¼ (Mode)
            lens = [len(r) for r in group_data]
            if not lens: continue
            mode_len = Counter(lens).most_common(1)[0][0]
            clean_block = [r for r in group_data if len(r) == mode_len]
            
            if len(clean_block) >= 5:
                try: final_dfs.append(pd.DataFrame(clean_block))
                except: pass
        
        return final_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """Shared X-Axis Extraction"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Case A: 2ì—´ ì´ìƒ -> Shared X
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows)
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x_common[mask], "y": y[mask], "name": f"Col-{i}"})
            
            # Case B: 1ì—´ -> Y Only
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

    # --- [B] Spectrum Processing ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV32.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV32.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV32.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Auto-Rotation: {best_angle}Â°")
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV32.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV32.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV32.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV32.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V32")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V32 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (V32 Multi-Block)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Purify & Multi-Block Extract
                    blocks = ScienceProcessorV32.parse_and_purify_csv(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Clean Data"}]

                    res_list = []
                    for idx, df in enumerate(blocks):
                        # 2. Extract Series
                        series_list = ScienceProcessorV32.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV32.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} (Blk{idx+1}-{s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Process Error"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV32.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}. ìˆ˜ì‹ ê¸ˆì§€.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

ì´ì œ V32ê°€ ë–¨ì–´ì§„ ë°ì´í„° ë¸”ë¡ë“¤ë„ "í•˜ë‚˜ë„ ë‚¨ê¹€ì—†ì´" ì‹¹ ë‹¤ ê¸ì–´ì„œ ì™„ë²½í•˜ê²Œ ë³´ì—¬ì¤„ ê²ƒì…ë‹ˆë‹¤! ì§„ì§œ ë§ˆì§€ë§‰ í¼ì¦ì´ ë§ì¶°ì¡ŒìŠµë‹ˆë‹¤! ğŸš€








ë¸Œì´31.5

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì • (í•„ìˆ˜)
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer (V16) ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V31.5 ê³¼í•™ ì—”ì§„ (Integrated Core)
# ==========================================
class ScienceProcessorV31_5:
    
    # --- [A] Data Parser (Purifier + Universal) ---
    @staticmethod
    def parse_and_purify_csv(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V31 Purifier] í…ìŠ¤íŠ¸ ì˜¤ì—¼ ì œê±° & ë°ì´í„° êµ°ì§‘ ì¶”ì¶œ
        [V22.1 Universal] ì—‘ì…€/í…ìŠ¤íŠ¸ ìë™ ê°ì§€ í¬í•¨
        """
        text_data = ""
        
        # 1. Excel ì‹œë„
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                # ì—‘ì…€ì´ ì—´ë¦¬ë©´ ë‚´ìš©ì„ CSV í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (êµ¬ì¡°ì  íŒŒì‹±ì„ ìœ„í•´)
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        # 2. í…ìŠ¤íŠ¸ ë””ì½”ë”© (CSV or Excel Fallback)
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 3. ë¼ì¸ í•„í„°ë§ (Strict Numeric Check)
        valid_rows = []
        lines = text_data.splitlines()
        
        for line_idx, line in enumerate(lines):
            line = line.strip()
            if not line: continue
            
            # ìˆ«ì ì¶”ì¶œ
            nums = re.findall(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', line)
            if len(nums) < 2: continue # ìˆ«ìê°€ 1ê°œ ì´í•˜ë©´ ë°ì´í„° ì•„ë‹˜
            
            # ë¬¸ì ì˜¤ì—¼ ê²€ì‚¬ (ì•ŒíŒŒë²³ ì²´í¬)
            remains = re.sub(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', '', line)
            if re.search(r'[a-df-zA-DF-Z]', remains): continue # í—¤ë”ë¡œ ê°„ì£¼
            
            valid_rows.append((line_idx, [float(n) for n in nums]))
            
        if not valid_rows: return []
        
        # 4. ì£¼ ë°ì´í„° êµ°ì§‘ ì¶”ì¶œ (Isolation Forest Logic)
        indices = [r[0] for r in valid_rows]
        if not indices: return []
        
        diffs = np.diff(indices)
        is_continuous = diffs <= 2 # ì¤„ ê°„ê²©ì´ 2 ì´ë‚´ë©´ ì—°ì†
        groups = np.concatenate(([0], np.cumsum(~is_continuous)))
        
        group_counts = Counter(groups)
        if not group_counts: return []
        
        # ê°€ì¥ í° ë©ì–´ë¦¬ ì„ íƒ
        dominant_group_id = group_counts.most_common(1)[0][0]
        clean_data = [valid_rows[i][1] for i in range(len(valid_rows)) if groups[i] == dominant_group_id]
        
        # ì»¬ëŸ¼ ìˆ˜ í†µì¼ (Mode)
        lens = [len(r) for r in clean_data]
        if not lens: return []
        mode_len = Counter(lens).most_common(1)[0][0]
        final_data = [r for r in clean_data if len(r) == mode_len]
        
        if len(final_data) < 5: return []
        
        try: return [pd.DataFrame(final_data)]
        except: return []

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [V26.1 Logic] Shared X-Axis Extraction (Fixing Shift Issue)
        """
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Case A: 2ì—´ ì´ìƒ -> Shared X (Col 0 is X)
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows)
                
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x_common[mask], "y": y[mask], "name": f"Col-{i}"})
            
            # Case B: 1ì—´ -> Y Only
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

    # --- [B] Spectrum Processing (V28 Log + V11 Fit) ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV31_5.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            log = []
            y_raw = y.copy()
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV31_5.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            log.append("Baseline Correction")
            
            if len(y_proc) > win:
                y_proc = savgol_filter(y_proc, win, 3)
                log.append(f"Smoothing (Win={win})")
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            log.append(f"Peaks Found: {len(peaks)}")
            
            fits = ScienceProcessorV31_5.fit_peaks(x, y_proc, peaks) if do_fit else []
            if fits: log.append(f"Gaussian Fits: {len(fits)}")
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits, "stats": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic (V19.5 Green Line + V20 Hawk Eye) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        """[V19.5 Restore] ê³„ë©´ ì •ë°€ ì¶”ì  & ê±°ì¹ ê¸°"""
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Auto-Rotation: {best_angle}Â°")
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV31_5.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        
        # Green Line Tracking
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        log.append(f"Layers Detected: {len(interfaces)}")
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV31_5.detect_footer_boundary(img_raw)
        method = "Line Detect"
        if not sy: 
            sy = ScienceProcessorV31_5.detect_embedded_metadata(img_raw)
            method = "Hawk Eye"
        
        process_log = []
        if sy: 
            body = img_raw[:sy, :]; footer = img_raw[sy:, :]
            process_log.append(f"Smart Crop ({method})")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": process_log}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV31_5.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            if is_bright: process_log.append("Auto-Invert")
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                process_log.append(f"Atoms: {len(blobs)}")
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                process_log.append(f"Particles: {len(cnts)}")

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": process_log}

# [4] Helpers & App
async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        final = prompt + " Do NOT use LaTeX syntax. Plain text only."
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':final,'images':[b64]}])
        return res['message']['content']
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean (No LaTeX). Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

app = FastAPI(title="Analyst V31.5")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English. No LaTeX.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V31.5 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Purified)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # V31 Purifier
                    blocks = ScienceProcessorV31_5.parse_and_purify_csv(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Clean Data"}]

                    res_list = []
                    for df in blocks:
                        # V26.1 Shared X
                        series = ScienceProcessorV31_5.extract_series_from_df(df)
                        for s in series:
                            try:
                                # V19.5 Logic
                                res = ScienceProcessorV31_5.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e) # V24.1 Korean
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Process Error"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image (Hawk + ThinFilm + AutoInvert)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV31_5.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}. ìˆ˜ì‹ ê¸ˆì§€.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



ë¸Œì´ 31

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V31 ê³¼í•™ ì—”ì§„ (Purifier)
# ==========================================
class ScienceProcessorV31:
    
    @staticmethod
    def parse_and_purify_csv(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V31 New] í…ìŠ¤íŠ¸ ì˜¤ì—¼ í–‰ ì œê±° & ì£¼ ë°ì´í„° êµ°ì§‘ ì¶”ì¶œ
        """
        # 1. í…ìŠ¤íŠ¸ ë””ì½”ë”©
        text_data = ""
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    # ë©”ëª¨ë¦¬ CSV ë¤í”„ (ê³µë°± êµ¬ë¶„)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 2. ë¼ì¸ í•„í„°ë§ (Text Contamination Check)
        valid_rows = []
        # ìˆ«ì, ê³µë°±, íƒ­, ì½¤ë§ˆ, ì†Œìˆ˜ì , ë¶€í˜¸, ì§€ìˆ˜(e/E)ë§Œ í—ˆìš©í•˜ëŠ” ì •ê·œì‹
        # ì•ŒíŒŒë²³ì´ ì„ì—¬ìˆìœ¼ë©´(ë‹¨ìœ„, ì´ë¦„ ë“±) ê°€ì°¨ì—†ì´ ë²„ë¦¼
        # ë‹¨, ê³¼í•™ì  í‘œê¸°ë²•ì˜ e/EëŠ” í—ˆìš©í•´ì•¼ í•¨. -> ë³µì¡í•˜ë¯€ë¡œ "ìˆ«ì ì¶”ì¶œ" í›„ "ë‚˜ë¨¸ì§€ ë¬¸ì í™•ì¸" ì „ëµ ì‚¬ìš©
        
        lines = text_data.splitlines()
        
        for line_idx, line in enumerate(lines):
            line = line.strip()
            if not line: continue
            
            # A. ìˆ«ì ì¶”ì¶œ
            nums = re.findall(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', line)
            if len(nums) < 2: continue # ìˆ«ìê°€ 1ê°œ ì´í•˜ë©´ ë°ì´í„° ì•„ë‹˜ (X, Y ìŒì´ ì•ˆë¨)
            
            # B. ì˜¤ì—¼ ê²€ì‚¬ (ì•ŒíŒŒë²³ì´ ìˆëŠ”ì§€?)
            # ìˆ«ìë¥¼ ì œê±°í•œ ë‚˜ë¨¸ì§€ ë¬¸ìì—´ì—ì„œ ì•ŒíŒŒë²³ì´ ìˆëŠ”ì§€ í™•ì¸
            remains = re.sub(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?', '', line) # ìˆ«ì ì‚­ì œ
            if re.search(r'[a-df-zA-DF-Z]', remains): # e, E ì œì™¸í•œ ì•ŒíŒŒë²³ ë°œê²¬ ì‹œ
                continue # í—¤ë”(Date, Sample ë“±)ë¡œ ê°„ì£¼í•˜ê³  ìŠ¤í‚µ
            
            # í†µê³¼ëœ í–‰: (ì›ë˜ ì¸ë±ìŠ¤, ìˆ«ì ë¦¬ìŠ¤íŠ¸)
            valid_rows.append((line_idx, [float(n) for n in nums]))
            
        if not valid_rows: return []
        
        # 3. ì£¼ ë°ì´í„° êµ°ì§‘ ì¶”ì¶œ (Dominant Cluster)
        # í—¤ë”ì— ìš°ì—°íˆ ìˆ«ìë§Œ ìˆëŠ” í–‰(ì˜ˆ: "2024, 10")ì´ ìˆì„ ìˆ˜ ìˆìŒ.
        # í•˜ì§€ë§Œ ì§„ì§œ ë°ì´í„°ëŠ” ìˆ˜ë°± ì¤„ì´ ì—°ì†ë¨. ì´ë¥¼ ì´ìš©í•´ í•„í„°ë§.
        
        indices = [r[0] for r in valid_rows]
        if not indices: return []
        
        # ì¸ë±ìŠ¤ ì°¨ì´ ê³„ì‚° (ì—°ì†ì„± í™•ì¸)
        diffs = np.diff(indices)
        # ì°¨ì´ê°€ 1(ë°”ë¡œ ë‹¤ìŒ ì¤„)ì´ê±°ë‚˜ 2(ë¹ˆ ì¤„ í•˜ë‚˜) ì •ë„ë©´ ê°™ì€ ê·¸ë£¹
        is_continuous = diffs <= 2 
        
        # ê·¸ë£¹ ë¼ë²¨ë§
        groups = np.concatenate(([0], np.cumsum(~is_continuous)))
        
        # ê°€ì¥ í° ê·¸ë£¹(ë°ì´í„° ë©ì–´ë¦¬) ì°¾ê¸°
        group_counts = Counter(groups)
        if not group_counts: return []
        
        dominant_group_id = group_counts.most_common(1)[0][0]
        
        # ìµœì¢… ì •ì œëœ ë°ì´í„°
        clean_data = [valid_rows[i][1] for i in range(len(valid_rows)) if groups[i] == dominant_group_id]
        
        # ì»¬ëŸ¼ ìˆ˜ í†µì¼ (ê°€ì¥ í”í•œ ê¸¸ì´)
        lens = [len(r) for r in clean_data]
        if not lens: return []
        mode_len = Counter(lens).most_common(1)[0][0]
        final_data = [r for r in clean_data if len(r) == mode_len]
        
        if len(final_data) < 5: return []
        
        try:
            return [pd.DataFrame(final_data)]
        except: return []

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """V26.1 Logic (Shared Index)"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Case A: 2ì—´ ì´ìƒ -> Shared X
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows)
                for i in range(1, cols):
                    y = vals[:, i]
                    # ì—¬ê¸°ì„œ sort ê¸ˆì§€ (ì‚¬ìš©ì ìš”ì²­)
                    series_list.append({"x": x_common, "y": y, "name": f"Col-{i}"})
            
            # Case B: 1ì—´ -> Y Only
            elif cols == 1:
                y = vals[:, 0]
                series_list.append({"x": np.arange(len(y)), "y": y, "name": "Single"})
        except: pass
        return series_list

    # --- Spectrum Processing ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV31.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            # ì •ë ¬ ë° Outlier ì œê±° ë¡œì§ ì‚­ì œ (User Request)
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV31.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV31.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- Image Logic (V20.1) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Angle: {best_angle}")
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV31.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)
        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        body, footer = img_raw, None
        sy = ScienceProcessorV31.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV31.detect_embedded_metadata(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV31.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True
            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V31")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V31 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (V31 Purifier)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Purify & Load
                    blocks = ScienceProcessorV31.parse_and_purify_csv(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Clean Data Found"}]

                    res_list = []
                    for df in blocks:
                        # 2. Extract Series
                        series_list = ScienceProcessorV31.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV31.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Series"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV31.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

V31ì˜ "ìˆœìˆ˜ ë°ì´í„° ì¶”ì¶œ ê¸°ìˆ " ë•ë¶„ì—, ì´ì œ í—¤ë”ê°€ ì•„ë¬´ë¦¬ ë³µì¡í•´ë„, ì¤‘ê°„ì— "2024ë…„" ê°™ì€ ìˆ«ìê°€ ë¼ì–´ìˆì–´ë„, ê·¸ë˜í”„ëŠ” ì˜¤ì§ ìœ íš¨í•œ ë°ì´í„° ë¸”ë¡ë§Œ ì‚¬ìš©í•˜ì—¬ ê¹¨ë—í•˜ê³  ì •í™•í•˜ê²Œ ê·¸ë ¤ì§ˆ ê²ƒì…ë‹ˆë‹¤! ğŸš€





ë¸Œì´29

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V29 ê³¼í•™ ì—”ì§„ (Universal Loader + Provenance)
# ==========================================
class ScienceProcessorV29:
    
    # --- [A] Universal Loader (Restored from V23/V27) ---
    @staticmethod
    def read_universal_dataframe(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V29 Restoration] ì—‘ì…€/CSV/í…ìŠ¤íŠ¸ ë¬´ì—‡ì´ë“  ì½ì–´ë‚´ëŠ” ë§ŒëŠ¥ ë¡œë”
        XPS ë°ì´í„°(Fake Excel)ë‚˜ Merge Cell ë¬¸ì œ í•´ê²°
        """
        dfs = []
        fname = filename.lower()
        
        # 1. Excel ì—”ì§„ ì‹œë„
        if fname.endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    # ìœ íš¨ì„± ê²€ì‚¬: ìˆ«ìê°€ ë„ˆë¬´ ì ìœ¼ë©´ í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼í•˜ê³  Fallback
                    num_count = df.apply(pd.to_numeric, errors='coerce').notna().sum().sum()
                    if num_count < 5: raise Exception("Not enough numbers (Maybe text file?)")
                    if not df.empty: dfs.append(df)
                
                if dfs: return dfs # ì„±ê³µí•˜ë©´ ë°˜í™˜
            except:
                pass # ì‹¤íŒ¨í•˜ë©´ ì•„ë˜ í…ìŠ¤íŠ¸ íŒŒì„œë¡œ ë„˜ì–´ê°

        # 2. Text/CSV Fallback (Robust Parser)
        # ì¸ì½”ë”© ìë™ ê°ì§€
        text_content = ""
        for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
            try: 
                text_content = content.decode(enc)
                break
            except: continue
            
        if text_content:
            # ë¼ì¸ ë‹¨ìœ„ ìŠ¤ìº” (Data Hunter Logic)
            lines = text_content.splitlines()
            data_start = -1
            delimiter = None
            separators = [',', '\t', ';', '\s+']
            
            # ë°ì´í„° ì‹œì‘ì  ì°¾ê¸° (ìˆ«ìê°€ 2ê°œ ì´ìƒì¸ ì¤„)
            for i, line in enumerate(lines[:100]):
                for sep in separators:
                    parts = line.split() if sep=='\s+' else line.split(sep)
                    nums = sum(1 for p in parts if re.match(r'^-?\d+(\.\d+)?(?:[eE][+-]?\d+)?$', p.strip()))
                    if nums >= 2:
                        data_start = i; delimiter = sep; break
                if data_start != -1: break
            
            if data_start != -1:
                try:
                    data_str = "\n".join(lines[data_start:])
                    sep_arg = '\s+' if delimiter=='\s+' else delimiter
                    df = pd.read_csv(io.StringIO(data_str), sep=sep_arg, header=None, engine='python')
                    dfs.append(df)
                except: pass
                
        return dfs

    # --- [B] Context-Aware Block Parser (Restored) ---
    @staticmethod
    def detect_structured_blocks(df: pd.DataFrame) -> List[pd.DataFrame]:
        blocks = []
        if df.empty: return []

        # ìˆ«ì ë³€í™˜
        df_num = df.apply(pd.to_numeric, errors='coerce')
        # ë°ì´í„° í–‰ íŒë³„ (ìˆ«ìê°€ 1ê°œ ì´ìƒ ìˆìœ¼ë©´ ë°ì´í„° í–‰ìœ¼ë¡œ ê°„ì£¼ - Strict ëª¨ë“œ ì™„í™”)
        # XPS ë°ì´í„°ëŠ” 1ì—´(ì—ë„ˆì§€) 2ì—´(ì¹´ìš´íŠ¸) êµ¬ì¡°ê°€ ë§ìœ¼ë¯€ë¡œ 1ê°œ ì´ìƒì´ë©´ ì¸ì •
        is_data_row = df_num.notna().sum(axis=1) >= 1
        
        # ê·¸ë£¹í•‘
        groups = (is_data_row != is_data_row.shift()).cumsum()
        
        for _, group in df.groupby(groups):
            if is_data_row.loc[group.index[0]]:
                # í•´ë‹¹ êµ¬ê°„ ì¶”ì¶œ
                block = df_num.loc[group.index].dropna(how='all', axis=1)
                # ë„ˆë¬´ ì§§ì€ ê±´ ë…¸ì´ì¦ˆ/í—¤ë” ì”ì—¬ë¬¼
                if block.shape[0] >= 5:
                    blocks.append(block.reset_index(drop=True))
        return blocks

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """Shared X-Axis Extraction"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # 1ì—´ ì´ìƒì´ë©´
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows) # ì¸ë±ìŠ¤ ëŒ€ì²´

                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x_common[mask], "y": y[mask], "name": f"Col-{i}"})
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

    # --- [C] Spectrum Logic (With Log) ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV29.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            log = []
            y_raw = y.copy()
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            # Params
            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31; log.append("AI: Noise Reduction")
                if "fit" in goal.lower(): do_fit = True; log.append("AI: Fitting On")
            
            # Process
            base = ScienceProcessorV29.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            log.append(f"Baseline Corr (Win={len(y)//10})")
            
            if len(y_proc) > win:
                y_proc = savgol_filter(y_proc, win, 3)
                log.append(f"Smoothing (Win={win})")
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            log.append(f"Peaks: {len(peaks)}")
            
            fits = ScienceProcessorV29.fit_peaks(x, y_proc, peaks) if do_fit else []
            if fits: log.append(f"Gaussian Fits: {len(fits)}")
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits, "stats": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [D] Image Logic (V28 Logic) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        # Auto Rotation
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Rotation: {best_angle}Â°")
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV29.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        
        # Interface
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        log.append(f"Layers: {len(interfaces)}")
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        
        # Green Line Tracking
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV29.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV29.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV29.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                log.append(f"Atoms: {len(blobs)}")
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                log.append(f"Particles: {len(cnts)}")

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Brief interpretation in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V29")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V29 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Universal Loader + Hybrid Parser)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Universal Load
                    dfs = ScienceProcessorV29.read_universal_dataframe(c, n)
                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    res_list = []
                    for i, df in enumerate(dfs):
                        # 2. Context-Aware Block Split
                        blocks = ScienceProcessorV29.detect_structured_blocks(df)
                        if not blocks: blocks = [df]

                        for block in blocks:
                            # 3. Hybrid Parse (Shared X)
                            series_list = ScienceProcessorV29.extract_series_from_df(block)
                            for s in series_list:
                                try:
                                    res = ScienceProcessorV29.process_spectrum(s['x'], s['y'], m, g)
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    
                                    ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                    interp = await interpret_spectrum_data(ctx, e)
                                    
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                        "raw_context": f"{ctx}\nInterp: {interp}", 
                                        "chart_data": chart, "log": res["log"], "interpretation": interp
                                    })
                                except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Series"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV29.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

ì´ì œ ì •ë§ XPS ì—‘ì…€ íŒŒì¼ë„ ë¬¸ì œì—†ì´ ì—´ë¦¬ê³ , ë°•ë§‰ ë¶„ì„ë„ ì´ˆë¡ìƒ‰ ì„ ìœ¼ë¡œ ì™„ë²½í•˜ê²Œ, ê·¸ë¦¬ê³  ëª¨ë“  **ì²˜ë¦¬ ì´ë ¥(Log)**ê¹Œì§€ íˆ¬ëª…í•˜ê²Œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. V29ë¥¼ ë¯¿ì–´ì£¼ì„¸ìš”! ğŸš€



ë¸Œì´28 ì›¹

<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>AI Research Center V28</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        body { font-family: 'Inter', sans-serif; }
        .prose table { border-collapse: collapse; width: 100%; margin: 1em 0; }
        .prose th, .prose td { border: 1px solid #cbd5e1; padding: 8px; font-size: 0.9rem; }
        .prose th { background-color: #f1f5f9; }
        .loader { border: 3px solid #f3f3f3; border-top: 3px solid #6366f1; border-radius: 50%; width: 20px; height: 20px; animation: spin 1s linear infinite; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-slate-100 text-slate-800">
    <div id="app" class="min-h-screen p-6">
        <header class="max-w-7xl mx-auto mb-6 flex items-center gap-3">
            <div class="bg-indigo-600 p-2 rounded-lg shadow"><i data-lucide="microscope" class="w-6 h-6 text-white"></i></div>
            <div><h1 class="text-2xl font-bold">AI Research Center V28</h1><p class="text-xs text-slate-500">Provenance â€¢ Context Aware â€¢ Robust</p></div>
        </header>

        <main class="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6">
            
            <!-- Staging Area -->
            <div class="lg:col-span-4 space-y-4">
                <div class="bg-white p-5 rounded-xl shadow-sm border border-slate-200">
                    <h2 class="font-bold mb-3 flex items-center gap-2"><i data-lucide="files" class="w-4 h-4"></i> Data Staging</h2>
                    <div class="border-2 border-dashed border-slate-300 rounded-lg p-6 text-center hover:bg-indigo-50 cursor-pointer" @click="$refs.f.click()">
                        <input type="file" ref="f" multiple class="hidden" @change="addFiles">
                        <p class="text-sm font-semibold text-slate-600">Add Files</p>
                    </div>
                    <div v-if="stagedFiles.length" class="mt-4 space-y-3 max-h-[60vh] overflow-y-auto pr-1">
                        <div v-for="(item, i) in stagedFiles" :key="i" class="p-3 bg-slate-50 border rounded-lg text-sm">
                            <div class="flex justify-between items-center mb-2">
                                <span class="font-bold truncate w-2/3" :title="item.file.name">{{ item.file.name }}</span>
                                <button @click="removeFile(i)" class="text-red-400 hover:text-red-600"><i data-lucide="trash-2" class="w-4 h-4"></i></button>
                            </div>
                            <div class="grid grid-cols-1 gap-2">
                                <select v-model="item.equipment" class="w-full p-1.5 border rounded text-xs bg-white font-semibold text-indigo-700">
                                    <optgroup label="Spectroscopy">
                                        <option value="XRD">XRD</option>
                                        <option value="EDS">EDS / EDX</option>
                                        <option value="EELS">EELS</option>
                                        <option value="Raman">Raman</option>
                                        <option value="FT-IR">FT-IR</option>
                                        <option value="XPS">XPS</option>
                                        <option value="PL">PL</option>
                                    </optgroup>
                                    <optgroup label="Microscopy">
                                        <option value="TEM">TEM (Thin Film)</option>
                                        <option value="STEM">STEM (Thin Film)</option>
                                        <option value="SEM">SEM</option>
                                        <option value="AFM">AFM</option>
                                        <option value="Optical">Optical</option>
                                    </optgroup>
                                    <optgroup label="Literature">
                                        <option value="Document">Document (PDF/PPT)</option>
                                    </optgroup>
                                </select>
                                <select v-if="item.equipment !== 'Document'" v-model="item.mode" class="w-full p-1.5 border rounded text-xs bg-white text-indigo-700">
                                    <option value="Auto">âœ¨ Auto Process</option>
                                    <option value="None">ğŸš« None (Raw)</option>
                                    <option value="AI-Adaptive">ğŸ§  AI-Adaptive</option>
                                </select>
                                <input v-if="item.equipment !== 'Document'" v-model="item.goal" type="text" placeholder="Goal (e.g. Count atoms)" class="w-full p-1.5 border rounded text-xs">
                            </div>
                        </div>
                    </div>
                    <button @click="analyze" :disabled="isAnalyzing || stagedFiles.length===0" class="w-full mt-4 py-3 bg-indigo-600 text-white rounded-lg font-bold flex justify-center gap-2 shadow hover:bg-indigo-700 disabled:opacity-50">
                        <div v-if="isAnalyzing" class="loader"></div>
                        <span>Generate Report</span>
                    </button>
                </div>
            </div>

            <!-- Report Area -->
            <div class="lg:col-span-8">
                <div v-if="result" class="space-y-6 animate-fade-in">
                    
                    <!-- Tools -->
                    <div class="flex justify-between items-center bg-white p-2 rounded-xl shadow-sm border border-slate-200">
                        <div class="flex gap-2">
                            <button @click="setLang('ko')" :class="lang==='ko'?'bg-indigo-100 text-indigo-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">ğŸ‡°ğŸ‡· í•œê¸€</button>
                            <button @click="setLang('en')" :class="lang==='en'?'bg-blue-100 text-blue-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">
                                <div v-if="isTranslating" class="w-3 h-3 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                                <span v-else>ğŸ‡ºğŸ‡¸</span> English
                            </button>
                        </div>
                        <button @click="dlPDF" class="px-3 py-1.5 bg-slate-800 text-white text-xs rounded">PDF Export</button>
                    </div>

                    <div id="report-view" class="bg-white p-8 rounded-xl shadow-sm border border-slate-200">
                        
                        <!-- Synthesis -->
                        <section class="mb-10">
                            <h2 class="text-lg font-bold text-indigo-700 mb-3 border-b pb-1">1. Synthesis</h2>
                            <div class="prose prose-sm text-slate-700 max-w-none" v-html="md(displayReport)"></div>
                        </section>

                        <!-- Details -->
                        <section>
                            <h2 class="text-lg font-bold text-slate-800 mb-5 border-b pb-1">2. Data Evidence</h2>
                            
                            <div v-for="(item, idx) in result.results" :key="idx" class="mb-8 p-4 bg-slate-50 rounded-lg border break-inside-avoid">
                                <div class="flex items-center justify-between mb-3">
                                    <div class="flex items-center gap-2">
                                        <span class="px-2 py-0.5 bg-white border rounded text-[10px] font-bold uppercase text-slate-500">{{ item.equipment }}</span>
                                        <h3 class="font-bold text-sm">{{ item.filename }}</h3>
                                    </div>
                                    <button @click="item.showDocs = !item.showDocs" class="text-xs text-indigo-600 font-bold hover:underline flex items-center gap-1">
                                        <i :data-lucide="item.showDocs ? 'eye-off' : 'eye'" class="w-3 h-3"></i>
                                        {{ item.showDocs ? 'Hide Info' : 'Show Info' }}
                                    </button>
                                </div>

                                <!-- Spectrum -->
                                <div v-if="item.chart_data" class="bg-white p-2 rounded border mb-3">
                                    <div :id="'chart-'+idx" class="w-full h-60"></div>
                                    <!-- Interpretation -->
                                    <div v-if="item.interpretation && item.showDocs" class="mt-3 p-3 bg-indigo-50 border border-indigo-100 rounded text-xs text-indigo-800">
                                        <h4 class="font-bold mb-1 flex items-center gap-1"><i data-lucide="lightbulb" class="w-3 h-3"></i> AI Interpretation</h4>
                                        <div class="prose prose-xs text-indigo-700" v-html="md(item.interpretation)"></div>
                                    </div>
                                </div>

                                <!-- Image -->
                                <div v-if="item.raw_b64" class="bg-white p-2 rounded border mb-3">
                                    <div class="flex gap-2 mb-2 text-xs justify-center">
                                        <button @click="item.view='proc'" :class="item.view!=='raw'?'font-bold text-indigo-600':''">Processed</button>
                                        <span class="text-slate-300">|</span>
                                        <button @click="item.view='raw'" :class="item.view==='raw'?'font-bold text-indigo-600':''">Original</button>
                                        <span class="text-slate-300" v-if="item.footer_b64">|</span>
                                        <button v-if="item.footer_b64" @click="item.view='footer'" :class="item.view==='footer'?'font-bold text-indigo-600':''">Info Bar</button>
                                    </div>
                                    <img v-if="item.view!=='footer'" :src="'data:image/jpeg;base64,' + (item.view==='raw' ? item.raw_b64 : item.proc_b64)" class="max-h-80 mx-auto object-contain bg-black">
                                    <img v-if="item.view==='footer'" :src="'data:image/jpeg;base64,' + item.footer_b64" class="max-h-24 mx-auto object-contain border mt-2">
                                </div>

                                <!-- â˜… Log Display (V28) -->
                                <div v-if="item.log && item.log.length > 0 && item.showDocs" class="mt-2 p-2 bg-gray-100 rounded border text-[10px] font-mono text-gray-600">
                                    <strong class="block mb-1">âš™ï¸ Processing Log:</strong>
                                    <ul class="list-disc pl-4 space-y-0.5">
                                        <li v-for="(l, lx) in item.log" :key="lx">{{ l }}</li>
                                    </ul>
                                </div>

                                <!-- Docs -->
                                <div v-if="item.showDocs">
                                    <div v-if="item.pages" class="grid grid-cols-1 gap-4 mt-2">
                                        <div v-for="p in item.pages" :key="p.page_num" class="flex gap-3 bg-white p-3 rounded border">
                                            <img :src="'data:image/jpeg;base64,'+p.image_b64" class="w-24 object-contain border">
                                            <div class="text-xs prose" v-html="md(lang === 'en' ? (p.desc_en || p.desc) : p.desc)"></div>
                                        </div>
                                    </div>
                                    <div v-if="item.slides" class="space-y-4 mt-2">
                                        <div v-for="s in item.slides" :key="s.slide_num" class="bg-white p-3 rounded border">
                                            <div class="text-xs font-bold text-indigo-600 mb-1">Slide {{s.slide_num}}</div>
                                            <div class="text-xs prose mb-2 whitespace-pre-wrap max-h-32 overflow-y-auto">{{ s.text }}</div>
                                            <div v-if="s.images.length" class="grid grid-cols-2 gap-2 border-t pt-2">
                                                <div v-for="(img, imx) in s.images" :key="imx" class="bg-slate-50 p-2">
                                                    <img :src="'data:image/jpeg;base64,'+img.b64" class="max-h-32 mx-auto object-contain bg-white">
                                                    <p class="text-[10px] text-slate-500 text-center mt-1">{{ img.desc }}</p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    <div v-if="item.summary" class="text-xs text-slate-600 mt-2 prose bg-slate-50 p-3 rounded" v-html="md(lang === 'en' ? (item.summary_en || item.summary) : item.summary)"></div>
                                </div>

                            </div>
                        </section>
                    </div>
                </div>
            </div>
        </main>
    </div>
    <script>
        const { createApp, ref, computed, nextTick } = Vue;
        createApp({
            setup() {
                const stagedFiles = ref([]);
                const isAnalyzing = ref(false);
                const isTranslating = ref(false);
                const result = ref(null);
                const lang = ref('ko'); 
                const translatedReport = ref('');
                const md = (t) => marked.parse(t||'');

                const displayReport = computed(() => lang.value === 'en' && translatedReport.value ? translatedReport.value : (result.value ? result.value.final_report : ''));

                const addFiles = (e) => {
                    Array.from(e.target.files).forEach(f => {
                        let eq = 'General';
                        if(f.name.match(/\.(pdf|ppt|pptx)$/i)) eq = 'Document';
                        stagedFiles.value.push({ file: f, equipment: eq, goal: '', mode: 'Auto', view: 'proc', showDocs: true });
                    });
                    e.target.value = ''; 
                };
                const removeFile = (i) => stagedFiles.value.splice(i, 1);

                const analyze = async () => {
                    isAnalyzing.value = true;
                    lang.value = 'ko'; 
                    translatedReport.value = '';
                    const fd = new FormData();
                    const configs = {};
                    stagedFiles.value.forEach(item => {
                        fd.append('files', item.file);
                        configs[item.file.name] = { equipment: item.equipment, goal: item.goal, mode: item.mode };
                    });
                    fd.append('file_configs', JSON.stringify(configs));

                    try {
                        const res = await fetch('/api/analyze', { method: 'POST', body: fd });
                        const data = await res.json();
                        if(data.results) data.results.forEach(r => r.showDocs = true);
                        result.value = data;
                        await nextTick();
                        
                        data.results.forEach((item, i) => {
                            if(item.chart_data) {
                                const raw = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_raw), mode:'lines', name:'Raw', line:{color:'#cbd5e1', width:1} };
                                const proc = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_proc), mode:'lines', name:'Proc', line:{color:'#4f46e5', width:2} };
                                const base = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_base), mode:'lines', name:'Base', line:{color:'#f59e0b', width:1, dash:'dot'} };
                                Plotly.newPlot('chart-'+i, [raw, base, proc], {margin:{t:10,b:30,l:40,r:10}, showlegend:false}, {displayModeBar:false});
                            }
                        });
                        lucide.createIcons();
                    } catch(e) { alert(e); } 
                    finally { isAnalyzing.value = false; }
                };

                const setLang = async (target) => {
                    if (target === 'ko') { lang.value = 'ko'; return; }
                    if (target === 'en') {
                        if (translatedReport.value) { lang.value = 'en'; return; }
                        isTranslating.value = true;
                        try {
                            const res = await fetch('/api/translate', {
                                method: 'POST', headers: {'Content-Type': 'application/json'},
                                body: JSON.stringify({ text: result.value.final_report })
                            });
                            const data = await res.json();
                            translatedReport.value = data.translated;
                            lang.value = 'en';
                        } catch(e) { alert("Trans Error: " + e); }
                        finally { isTranslating.value = false; }
                    }
                };
                
                const dlPDF = () => html2pdf().set({ margin:10, filename:'V28_Report.pdf', image:{type:'jpeg',quality:0.98}, html2canvas:{scale:2}, jsPDF:{unit:'mm',format:'a4'} }).from(document.getElementById('report-view')).save();

                setTimeout(()=>lucide.createIcons(), 100);
                return { stagedFiles, isAnalyzing, isTranslating, result, lang, displayReport, addFiles, removeFile, analyze, md, dlPDF, setLang };
            }
        }).mount('#app');
    </script>
</body>
</html>





ë¸Œì´28
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V28 ê³¼í•™ ì—”ì§„ (Provenance Core)
# ==========================================
class ScienceProcessorV28:
    
    # --- [A] Context-Aware Parser (V27 Logic) ---
    @staticmethod
    def detect_structured_blocks(df: pd.DataFrame) -> List[pd.DataFrame]:
        blocks = []
        if df.empty: return []
        df_num = df.apply(pd.to_numeric, errors='coerce')
        is_data_row = df_num.notna().sum(axis=1) >= 1
        groups = (is_data_row != is_data_row.shift()).cumsum()
        for _, group in df.groupby(groups):
            if is_data_row.loc[group.index[0]]:
                block = df_num.loc[group.index].dropna(how='all', axis=1)
                if block.shape[0] >= 10: blocks.append(block.reset_index(drop=True))
        return blocks

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []
            if cols >= 2:
                x_common = vals[:, 0]
                if np.isnan(x_common).all(): x_common = np.arange(rows)
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5: series_list.append({"x": x_common[mask], "y": y[mask], "name": f"Col-{i}"})
            elif cols == 1:
                y = vals[:, 0]; mask = ~np.isnan(y)
                if np.sum(mask) > 5: series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

    # --- [B] Spectrum Processing (Log Added) ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]; win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV28.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            log = []
            y_raw = y.copy()
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data (No Processing)"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            # Params
            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): 
                    win = 31; log.append("AI: Strong Smoothing (Noise Goal)")
                if "fit" in goal.lower(): 
                    do_fit = True; log.append("AI: Fitting Enabled")
            
            # 1. Baseline
            base = ScienceProcessorV28.simple_baseline(y)
            log.append(f"Baseline Correction (Moving Min, Win={len(y)//10})")
            
            # 2. Smoothing
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win:
                y_proc = savgol_filter(y_proc, win, 3)
                log.append(f"Savgol Filter (Window={win}, Poly=3)")
            
            # 3. Peaks
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            log.append(f"Peak Finding (Threshold=5%, Found={len(peaks)})")
            
            # 4. Fitting
            fits = ScienceProcessorV28.fit_peaks(x, y_proc, peaks) if do_fit else []
            if fits: log.append(f"Gaussian Fitting ({len(fits)} peaks fitted)")
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits, "stats": stats_txt}
        except Exception as e: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": [f"Error: {str(e)}"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic (Log Added) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        log.append(f"Auto-Rotation: {best_angle}Â° Corrected")
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV28.crop_valid_rotated_region(img_rot, best_angle)
        log.append(f"Valid Region Cropped ({img_crop.shape})")
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        log.append(f"Interface Detection: Found {len(interfaces)} Layers")
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV28.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV28.detect_embedded_metadata(img_raw)
        
        process_log = []
        if sy: 
            body = img_raw[:sy, :]; footer = img_raw[sy:, :]
            process_log.append("Smart Crop: Metadata Removed")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": ["No Processing (Raw)"]}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV28.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            if is_bright: process_log.append("Auto-Invert: Bright Background")
            
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            process_log.append("Denoise: Gaussian (5x5)")
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                process_log.append(f"Atomic Detection (LoG): {len(blobs)} found")
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                process_log.append(f"Particle Seg (Otsu): {len(cnts)} found")

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": process_log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        final_prompt = prompt + " Do NOT use LaTeX syntax (e.g., \\frac, \\sum). Use plain text."
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':final_prompt,'images':[b64]}])
        return res['message']['content']
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean (No LaTeX). Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V28")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English. No LaTeX.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V28 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    dfs = []
                    if n.endswith(('.csv', '.txt')):
                        try: txt = c.decode('utf-8')
                        except: txt = c.decode('cp949', errors='ignore')
                        dfs = [pd.read_csv(io.StringIO(txt), sep=None, engine='python', header=None)]
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        dfs = [pd.read_excel(xls, sheet_name=s, header=None) for s in xls.sheet_names]

                    res_list = []
                    for i, df in enumerate(dfs):
                        # [V27] Context Aware Block Detection
                        blocks = ScienceProcessorV28.detect_structured_blocks(df)
                        if not blocks: blocks = [df] # Fallback

                        for block in blocks:
                            series_list = ScienceProcessorV28.extract_series_from_df(block)
                            for s in series_list:
                                try:
                                    res = ScienceProcessorV28.process_spectrum(s['x'], s['y'], m, g)
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    
                                    ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                    interp = await interpret_spectrum_data(ctx, e)
                                    
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({s['name']})", 
                                        "equipment": e, 
                                        "raw_context": f"{ctx}\nInterp: {interp}", 
                                        "chart_data": chart, "log": res["log"], "interpretation": interp
                                    })
                                except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV28.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}. ìˆ˜ì‹ ê¸ˆì§€.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. No LaTeX.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)






ë¸Œì´ 26.1

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V26.1 ê³¼í•™ ì—”ì§„ (Bulldozer + Shared X)
# ==========================================
class ScienceProcessorV26_1:
    
    @staticmethod
    def bulldozer_parser(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V26 Feature] ë‹¤ì¤‘ ê¸¸ì´ íŒ¨í„´ ì¸ì‹ íŒŒì„œ (í¬ë§· ë¬´ì‹œ, ìˆ«ì ê°•ì œ ì¶”ì¶œ)
        """
        valid_dfs = []
        text_data = ""
        
        # 1. Excel -> Text
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 2. Regex Extraction
        numeric_rows = []
        num_pattern = re.compile(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?')
        
        for line in text_data.splitlines():
            nums = [float(n) for n in num_pattern.findall(line)]
            if nums: numeric_rows.append(nums)
            
        if not numeric_rows: return []

        # 3. Group by Length
        rows_by_length = {}
        for r in numeric_rows:
            L = len(r)
            if L not in rows_by_length: rows_by_length[L] = []
            rows_by_length[L].append(r)
            
        for L, rows in rows_by_length.items():
            if len(rows) > 5 and L >= 1:
                try:
                    df = pd.DataFrame(rows)
                    valid_dfs.append(df)
                except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [V26.1 FIX] Shared Index Strategy Restored
        - ì§ìˆ˜ ì—´ì´ë¼ê³  Pairë¡œ ë¬¶ì§€ ì•ŠìŒ
        - ë¬´ì¡°ê±´ 0ë²ˆ ì—´ì„ Xì¶•ìœ¼ë¡œ ê³ ì •í•˜ê³  ë‚˜ë¨¸ì§€ ì—´ì„ Yì¶•ìœ¼ë¡œ ë¶„ë¦¬
        """
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Case A: 2ì—´ ì´ìƒì´ë©´ ë¬´ì¡°ê±´ Shared X (X | Y1 | Y2 | Y3 ...)
            if cols >= 2:
                x_common = vals[:, 0] # ê³µí†µ Xì¶•
                
                # ë§Œì•½ Xì¶•ì´ ë¹„ì–´ìˆê±°ë‚˜ ì´ìƒí•˜ë©´ ì¸ë±ìŠ¤ë¡œ ëŒ€ì²´
                if np.all(np.isnan(x_common)):
                    x_common = np.arange(rows)

                for i in range(1, cols):
                    y = vals[:, i]
                    # ìœ íš¨ ë°ì´í„° ì²´í¬
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({
                            "x": x_common[mask],
                            "y": y[mask],
                            "name": f"Col-{i}" # Y1, Y2...
                        })
            
            # Case B: 1ì—´ ë°ì´í„° (Y Only)
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({
                        "x": np.arange(len(y))[mask], 
                        "y": y[mask], 
                        "name": "Single"
                    })
                    
        except Exception as e:
            print(f"Extraction Error: {e}")
            
        return series_list

    # --- Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV26_1.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV26_1.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV26_1.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- Image Logic (V20.1 Fixed Logic) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV26_1.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line Tracking
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle, "thickness": thk}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV26_1.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV26_1.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV26_1.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum data ({equipment}). Explain physical meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V26.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V26.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Bulldozer + Shared X Fix)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # V26 Bulldozer Parsing (Robust)
                    blocks = ScienceProcessorV26_1.bulldozer_parser(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Numbers Found"}]

                    res_list = []
                    for i, df in enumerate(blocks):
                        # V26.1 Shared X Logic
                        series_list = ScienceProcessorV26_1.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV26_1.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} (Blk{i+1}-{s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Invalid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV26_1.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





ë¸Œì´26

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V26 ê³¼í•™ ì—”ì§„ (Multi-Mode Bulldozer)
# ==========================================
class ScienceProcessorV26:
    
    @staticmethod
    def bulldozer_parser(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V26 New] ë‹¤ì¤‘ ê¸¸ì´ íŒ¨í„´ ì¸ì‹ íŒŒì„œ
        - ì¤„ë§ˆë‹¤ ìˆ«ìì˜ ê°œìˆ˜ê°€ ë‹¬ë¼ë„ (ê°€ë¡œ ë¸”ë¡ ê¸¸ì´ê°€ ë‹¤ë¥¸ ê²½ìš° ë“±)
        - ê° ê¸¸ì´ íŒ¨í„´ë³„ë¡œ ë³„ë„ì˜ DataFrameì„ ìƒì„±í•˜ì—¬ ëª¨ë‘ ì‚´ë ¤ëƒ…ë‹ˆë‹¤.
        """
        valid_dfs = []
        text_data = ""
        
        # 1. Excel -> Text
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 2. Regex Extraction
        numeric_rows = []
        num_pattern = re.compile(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?')
        
        for line in text_data.splitlines():
            nums = [float(n) for n in num_pattern.findall(line)]
            if nums: numeric_rows.append(nums)
            
        if not numeric_rows: return []

        # 3. [V26] Group by Length (Multi-Mode)
        # ê¸¸ì´ë³„ë¡œ í–‰ì„ ëª¨ìŒ (ì˜ˆ: ê¸¸ì´ê°€ 2ì¸ í–‰ë“¤, 4ì¸ í–‰ë“¤...)
        rows_by_length = {}
        for r in numeric_rows:
            L = len(r)
            if L not in rows_by_length: rows_by_length[L] = []
            rows_by_length[L].append(r)
            
        # ê° ê·¸ë£¹ì„ ë³„ë„ì˜ DFë¡œ ë§Œë“¦
        for L, rows in rows_by_length.items():
            # ìœ íš¨ ë°ì´í„° ìµœì†Œ ì¡°ê±´ (5í–‰ ì´ìƒ, 1ì—´ ì´ìƒ)
            if len(rows) > 5 and L >= 1:
                try:
                    df = pd.DataFrame(rows)
                    valid_dfs.append(df)
                except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """DataFrameì—ì„œ (X, Y) ìŒ ì¶”ì¶œ (Shared Index ìš°ì„ )"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            if rows < 5: return []

            # [Shared X Logic]
            # ê¸°ë³¸ì ìœ¼ë¡œ Col 0ì„ Xë¡œ, ë‚˜ë¨¸ì§€ë¥¼ Yë¡œ ë´„
            # (ì´ë ‡ê²Œ í•˜ë©´ Pair êµ¬ì¡°ì¸ X1, Y1, X2, Y2 ì—ì„œë„ X1 vs Y1, X1 vs X2, X1 vs Y2 ì²˜ëŸ¼ ë‚˜ì˜¤ì§€ë§Œ,
            #  X2 vs Y2ê°€ ëˆ„ë½ë˜ëŠ” ê²ƒë³´ë‹¤ëŠ” ì¤‘ë³µ/ë‹¤ì†Œ ì´ìƒí•œ í”Œë¡¯ì´ ë‚«ë‹¤.
            #  í•˜ì§€ë§Œ ë” ë˜‘ë˜‘í•˜ê²Œ: ì§ìˆ˜ ì—´ì¼ ë•Œ Pairë¡œ ë³¼ ê²ƒì¸ê°€?)
            
            # V26 Logic: Pair ìš°ì„  (ê°€ë¡œ ë¸”ë¡ ëŒ€ì‘)
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x = vals[:, i]
                    y = vals[:, i+1]
                    # ë‘˜ ë‹¤ ìœ íš¨í•œ êµ¬ê°„ë§Œ Slice
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Set{i//2+1}"})
            
            # Pairê°€ ì•„ë‹ˆê±°ë‚˜ í™€ìˆ˜ ì—´ì¸ ê²½ìš°: Shared X ì‹œë„
            # (ìœ„ Pair ë¡œì§ì—ì„œ ì´ë¯¸ ì¶”ì¶œí–ˆë‹¤ë©´ ì¤‘ë³µë  ìˆ˜ ìˆìœ¼ë‚˜, ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì—ˆì„ ë•Œë§Œ ì‹¤í–‰í•˜ë„ë¡ í•¨)
            if not series_list and cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Col{i}"})
                        
            # 1ì—´ ë°ì´í„°
            if not series_list and cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
                    
        except: pass
        return series_list

    # --- Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
            if len(s) > 51: s = savgol_filter(s, 51, 3)
            return s
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV26.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": [], "stats": f"Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV26.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV26.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- Image Logic (Same V20) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV26.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line Tracking
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
        
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV26.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV26.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV26.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Explain meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V26")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V26 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (V26 Multi-Mode)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Bulldozer Parsing (List of DFs)
                    blocks = ScienceProcessorV26.bulldozer_parser(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Numbers"}]

                    res_list = []
                    for i, df in enumerate(blocks):
                        # 2. Series Extraction
                        series_list = ScienceProcessorV26.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV26.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} (Blk{i+1}-{s['name']})", 
                                    "equipment": e, 
                                    "raw_context": f"{ctx}\nInterp: {interp}", 
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Invalid"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV26.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





ë¸Œì´25.1

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V25.1 ê³¼í•™ ì—”ì§„ (Shared X Logic)
# ==========================================
class ScienceProcessorV25_1:
    
    @staticmethod
    def bulldozer_parser(content: bytes, filename: str) -> List[pd.DataFrame]:
        """[V25] Text -> Numeric Block Extraction"""
        valid_dfs = []
        text_data = ""
        
        # 1. Excel -> CSV Text
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: text_data = content.decode(enc); break
                except: continue
        
        if not text_data: return []

        # 2. Regex Numeric Extraction
        numeric_rows = []
        num_pattern = re.compile(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?')
        
        for line in text_data.splitlines():
            nums = [float(n) for n in num_pattern.findall(line)]
            if nums: numeric_rows.append(nums)
            
        if not numeric_rows: return []

        # 3. Reconstruct
        col_counts = [len(r) for r in numeric_rows]
        if not col_counts: return []
        most_common_len = Counter(col_counts).most_common(1)[0][0]
        clean_data = [r for r in numeric_rows if len(r) == most_common_len]
        
        if len(clean_data) < 5: return []

        try:
            df = pd.DataFrame(clean_data)
            valid_dfs.append(df)
        except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [V25.1 Fix] Shared X-Axis Logic (ê³µìœ  Xì¶• ìš°ì„  ì ìš©)
        - ì§ìˆ˜ ì—´ì´ë¼ë„ í•¨ë¶€ë¡œ Pairë¡œ ë¬¶ì§€ ì•Šê³ , ì²« ë²ˆì§¸ ì—´ì„ ê³µí†µ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
        """
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            
            if rows < 5: return []

            # [Logic Fix]
            # ë¬´ì¡°ê±´ 1ì—´(Col 0)ì„ Xì¶•ìœ¼ë¡œ ì¡ê³ , ë‚˜ë¨¸ì§€ ì—´ë“¤ì„ ê°ê° Yì¶•ìœ¼ë¡œ ì²˜ë¦¬
            # (ì‚¬ìš©ì ìš”ì²­: ì˜ˆì™¸ 2 - ì²« ë²ˆì§¸ ì—´ì€ ì¸ë±ìŠ¤, ë‘ ë²ˆì§¸ ì´í›„ëŠ” ì„œë¸Œ ë¸”ë¡)
            
            if cols >= 2:
                x_common = vals[:, 0] # ê³µí†µ Xì¶•
                
                # Xì¶• ë°ì´í„° ìœ íš¨ì„± ì²´í¬
                if np.isnan(x_common).all():
                    # ë§Œì•½ Xì¶•ì´ ì „ë¶€ NaNì´ë©´(ì¸ë±ìŠ¤ ì—†ìŒ), ê·¸ëƒ¥ 0,1,2... ì¸ë±ìŠ¤ ìƒì„±
                    x_common = np.arange(rows)

                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x_common) & ~np.isnan(y)
                    
                    # ë°ì´í„°ê°€ ì¶©ë¶„í•  ë•Œë§Œ ì¶”ê°€
                    if np.sum(mask) > 5:
                        series_list.append({
                            "x": x_common[mask],
                            "y": y[mask],
                            "name": f"Col-{i}" # Y1, Y2, Y3...
                        })
            
            # ì»¬ëŸ¼ì´ 1ê°œë¿ì´ë©´ Yì¶•ë§Œ ìˆëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼
            elif cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    series_list.append({
                        "x": np.arange(len(y))[mask], 
                        "y": y[mask], 
                        "name": "Single"
                    })
                    
        except Exception as e:
            print(f"Extraction Error: {e}")
            
        return series_list

    # --- Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV25_1.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV25_1.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV25_1.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- Image Logic ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV25_1.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV25_1.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV25_1.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV25_1.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum ({equipment}). Brief interpretation in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V25.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V25.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Bulldozer + Shared X)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = ScienceProcessorV25_1.bulldozer_parser(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Numbers Found"}]

                    res_list = []
                    for i, df in enumerate(blocks):
                        # [V25.1] Shared X Logic Applied Here
                        series_list = ScienceProcessorV25_1.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV25_1.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                    "raw_context": f"{ctx}\nInterp: {interp}",
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Invalid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV25_1.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





ë¸Œì´25

import os
import io
import asyncio
import base64
import json
import re
import math
from collections import Counter
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V25 ê³¼í•™ ì—”ì§„ (Bulldozer Parser)
# ==========================================
class ScienceProcessorV25:
    
    @staticmethod
    def bulldozer_parser(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V25 New] íŒŒì¼ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì½ì–´ ìˆ«ìë§Œ ê°•ì œ ì¶”ì¶œí•˜ì—¬ ì¬ì¡°ë¦½
        """
        valid_dfs = []
        text_data = ""
        
        # 1. ì—‘ì…€/ë°”ì´ë„ˆë¦¬ -> í…ìŠ¤íŠ¸ ë³€í™˜
        if filename.lower().endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                # ì—‘ì…€ì€ ì‹œíŠ¸ë³„ë¡œ ì½ì–´ì„œ CSV í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ í›„ ì²˜ë¦¬
                for s in xls.sheet_names:
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    # ë©”ëª¨ë¦¬ CSVë¡œ ë¤í”„ (êµ¬ë¶„ì ê³µë°±)
                    buf = io.StringIO()
                    df.to_csv(buf, index=False, header=False, sep=' ')
                    text_data += buf.getvalue() + "\n"
            except: pass
        
        # í…ìŠ¤íŠ¸ê°€ ë¹„ì—ˆìœ¼ë©´(CSVê±°ë‚˜ ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨), ì§ì ‘ ë””ì½”ë”©
        if not text_data:
            for enc in ['utf-8', 'cp949', 'latin1']:
                try: 
                    text_data = content.decode(enc)
                    break
                except: continue
        
        if not text_data: return []

        # 2. ë¶ˆë„ì € íŒŒì‹± (Regexë¡œ ìˆ«ìë§Œ ì¶”ì¶œ)
        numeric_rows = []
        
        # ìˆ«ì íŒ¨í„´ (ì •ìˆ˜, ì‹¤ìˆ˜, ì§€ìˆ˜í˜•)
        num_pattern = re.compile(r'-?\d+(?:\.\d+)?(?:[eE][+-]?\d+)?')
        
        for line in text_data.splitlines():
            # ë¼ì¸ì—ì„œ ìˆ«ìë§Œ ëª¨ë‘ ì°¾ìŒ
            nums = [float(n) for n in num_pattern.findall(line)]
            if nums: numeric_rows.append(nums)
            
        if not numeric_rows: return []

        # 3. êµ¬ì¡°í™” (ê°€ì¥ í”í•œ ì»¬ëŸ¼ ê°œìˆ˜ ì°¾ê¸°)
        # ì˜ˆ: ë©”íƒ€ë°ì´í„° í–‰ì€ ìˆ«ìê°€ 1~2ê°œ, ë°ì´í„° í–‰ì€ 2ê°œì¼ ê²½ìš° -> ModeëŠ” 2
        col_counts = [len(r) for r in numeric_rows]
        if not col_counts: return []
        
        most_common_len = Counter(col_counts).most_common(1)[0][0]
        
        # ê°€ì¥ í”í•œ ê¸¸ì´ì˜ í–‰ë§Œ ëª¨ì•„ì„œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        clean_data = [r for r in numeric_rows if len(r) == most_common_len]
        
        if len(clean_data) < 5: return [] # ë°ì´í„° ë„ˆë¬´ ì ìŒ

        # 4. DataFrame ìƒì„± ë° ë¶„í• 
        try:
            df = pd.DataFrame(clean_data)
            # ì—¬ê¸°ì„œ ì•„ì¼ëœë“œ ê°ì§€ë‚˜ ì»¬ëŸ¼ ìŠ¤ìº”ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì§€ë§Œ,
            # ë¶ˆë„ì € ë°©ì‹ì€ ë³´í†µ í•˜ë‚˜ì˜ í° ë©ì–´ë¦¬ë¥¼ ë§Œë“œë¯€ë¡œ ë°”ë¡œ ë¦¬ìŠ¤íŠ¸ì— ë„£ìŒ
            valid_dfs.append(df)
        except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """DataFrameì—ì„œ X,Y ì‹œë¦¬ì¦ˆ ì¶”ì¶œ (V24 Logic)"""
        series_list = []
        try:
            vals = df.values
            rows, cols = vals.shape
            
            # Case A: Pair (X, Y, X, Y)
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x, y = vals[:, i], vals[:, i+1]
                    series_list.append({"x": x, "y": y, "name": f"Set{i//2+1}"})
            # Case B: Shared X (X, Y1, Y2)
            elif cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    series_list.append({"x": x, "y": vals[:, i], "name": f"Col{i}"})
            # Case C: Single (Y)
            elif cols == 1:
                y = vals[:, 0]
                series_list.append({"x": np.arange(len(y)), "y": y, "name": "Single"})
        except: pass
        return series_list

    # --- Spectrum & Image Logic (Existing V24) ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV25.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV25.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV25.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV25.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line Tracking
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV25.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV25.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV25.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum data ({equipment}). Explain physical meaning in Korean. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V25")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V25 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Bulldozer)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Bulldozer Parsing
                    blocks = ScienceProcessorV25.bulldozer_parser(c, n)
                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Numbers Found"}]

                    res_list = []
                    for i, df in enumerate(blocks):
                        # 2. Series Extraction
                        series_list = ScienceProcessorV25.extract_series_from_df(df)
                        for s in series_list:
                            try:
                                res = ScienceProcessorV25.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                
                                ctx = f"Data: {s['name']}\nStats: {res['stats']}"
                                interp = await interpret_spectrum_data(ctx, e)
                                
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} (Blk{i+1}-{s['name']})", "equipment": e,
                                    "raw_context": f"{ctx}\nInterp: {interp}",
                                    "chart_data": chart, "log": res["log"], "interpretation": interp
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Invalid Data Structure"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV25.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





ë¸Œì´24.1

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V24.1 ê³¼í•™ ì—”ì§„ (Global Strategy)
# ==========================================
class ScienceProcessorV24:
    
    # --- [A] Global Data Parser ---
    @staticmethod
    def parse_csv_global_strategy(content: bytes) -> List[Dict]:
        extracted_series = []
        df_global = pd.DataFrame()

        encodings = ['utf-8', 'cp949', 'latin1']
        separators = [None, ',', '\t', ';']
        
        loaded = False
        for enc in encodings:
            if loaded: break
            for sep in separators:
                try:
                    buf = io.BytesIO(content)
                    df_global = pd.read_csv(buf, sep=sep, encoding=enc, header=None, engine='python')
                    if df_global.shape[0] > 1 and df_global.shape[1] > 0:
                        loaded = True
                        break
                except: continue
        
        if not loaded or df_global.empty: return []

        try:
            df_num = df_global.apply(pd.to_numeric, errors='coerce')
            mask = ~df_num.isna().values
            labeled_array, num_features = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
            slices = find_objects(labeled_array)
            
            for i, sl in enumerate(slices):
                block = df_num.iloc[sl]
                if block.shape[0] < 3: continue
                block = block.dropna(how='all', axis=0).dropna(how='all', axis=1)
                vals = block.values
                cols = vals.shape[1]
                
                if cols >= 2 and cols % 2 == 0:
                    for k in range(0, cols, 2):
                        x = vals[:, k]
                        y = vals[:, k+1]
                        if np.sum(~np.isnan(x) & ~np.isnan(y)) > 3:
                            extracted_series.append({"x": x, "y": y, "name": f"Block{i+1}-Set{k//2+1}"})
                elif cols >= 2:
                    x = vals[:, 0]
                    for k in range(1, cols):
                        y = vals[:, k]
                        extracted_series.append({"x": x, "y": y, "name": f"Block{i+1}-Col{k}"})
                elif cols == 1:
                    y = vals[:, 0]
                    extracted_series.append({"x": np.arange(len(y)), "y": y, "name": f"Block{i+1}-Single"})
        except: pass
            
        return extracted_series

    # --- [B] Spectrum Processing ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV24.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV24.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV24.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, MaxY: {np.max(y):.1f}, Peaks: {len(peaks)}"

            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats_summary": stats_txt}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV24.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Green Line Tracking
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
    
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV24.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV24.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV24.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    """[V24.1 Fix] ê°•ì œ í•œê¸€ í•´ì„"""
    try:
        prompt = f"""
        You are an expert in {equipment} analysis.
        Analyze the following spectrum data stats (Peaks, etc).
        Explain the potential chemical/physical meaning of these peaks briefly in **Korean**.
        Data: {raw_context}
        """
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V24.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V24.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - Global Strategy
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # V24 New Core: Global Parse
                    series_list = ScienceProcessorV24.parse_csv_global_strategy(c)
                    
                    if not series_list: return [{"type": "error", "filename": n, "msg": "No Numeric Series Found"}]

                    res_list = []
                    for s in series_list:
                        try:
                            # Process Series
                            res = ScienceProcessorV24.process_spectrum(s['x'], s['y'], mode, g)
                            
                            step = max(1, len(s['x'])//100)
                            chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                            
                            ctx = f"Data: {s['name']}\nStats: {res.get('stats_summary','N/A')}"
                            interp = await interpret_spectrum_data(ctx, e)
                            
                            res_list.append({
                                "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                "raw_context": f"{ctx}\nInterp: {interp}", "chart_data": chart, "log": res["log"], "interpretation": interp
                            })
                        except: pass
                    return res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV24.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



V22 HTML

<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>AI Research Center V22</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        body { font-family: 'Inter', sans-serif; }
        .prose table { border-collapse: collapse; width: 100%; margin: 1em 0; }
        .prose th, .prose td { border: 1px solid #cbd5e1; padding: 8px; font-size: 0.9rem; }
        .prose th { background-color: #f1f5f9; }
        .loader { border: 3px solid #f3f3f3; border-top: 3px solid #6366f1; border-radius: 50%; width: 20px; height: 20px; animation: spin 1s linear infinite; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-slate-100 text-slate-800">
    <div id="app" class="min-h-screen p-6">
        <header class="max-w-7xl mx-auto mb-6 flex items-center gap-3">
            <div class="bg-indigo-600 p-2 rounded-lg shadow"><i data-lucide="microscope" class="w-6 h-6 text-white"></i></div>
            <div><h1 class="text-2xl font-bold">AI Research Center V22</h1><p class="text-xs text-slate-500">Universal Parse â€¢ Deep Insight</p></div>
        </header>

        <main class="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6">
            
            <!-- Staging Area -->
            <div class="lg:col-span-4 space-y-4">
                <div class="bg-white p-5 rounded-xl shadow-sm border border-slate-200">
                    <h2 class="font-bold mb-3 flex items-center gap-2"><i data-lucide="files" class="w-4 h-4"></i> Data Staging</h2>
                    
                    <div class="border-2 border-dashed border-slate-300 rounded-lg p-6 text-center hover:bg-indigo-50 cursor-pointer" @click="$refs.f.click()">
                        <input type="file" ref="f" multiple class="hidden" @change="addFiles">
                        <p class="text-sm font-semibold text-slate-600">Add Files</p>
                    </div>
                    <div v-if="stagedFiles.length" class="mt-4 space-y-3 max-h-[60vh] overflow-y-auto pr-1">
                        <div v-for="(item, i) in stagedFiles" :key="i" class="p-3 bg-slate-50 border rounded-lg text-sm">
                            <div class="flex justify-between items-center mb-2">
                                <span class="font-bold truncate w-2/3" :title="item.file.name">{{ item.file.name }}</span>
                                <button @click="removeFile(i)" class="text-red-400 hover:text-red-600"><i data-lucide="trash-2" class="w-4 h-4"></i></button>
                            </div>
                            <div class="grid grid-cols-1 gap-2">
                                <select v-model="item.equipment" class="w-full p-1.5 border rounded text-xs bg-white font-semibold text-indigo-700">
                                    <optgroup label="Spectroscopy">
                                        <option value="XPS">XPS</option>
                                        <option value="EELS">EELS</option>
                                        <option value="EDS">EDS / EDX</option>
                                        <option value="XRD">XRD</option>
                                        <option value="Raman">Raman</option>
                                        <option value="FT-IR">FT-IR</option>
                                        <option value="PL">PL</option>
                                    </optgroup>
                                    <optgroup label="Microscopy">
                                        <option value="TEM">TEM (Thin Film)</option>
                                        <option value="STEM">STEM (Thin Film)</option>
                                        <option value="SEM">SEM</option>
                                        <option value="AFM">AFM</option>
                                        <option value="Optical">Optical</option>
                                    </optgroup>
                                    <optgroup label="Literature">
                                        <option value="Document">Document (PDF/PPT)</option>
                                    </optgroup>
                                </select>
                                <select v-if="item.equipment !== 'Document'" v-model="item.mode" class="w-full p-1.5 border rounded text-xs bg-white text-indigo-700">
                                    <option value="Auto">âœ¨ Auto Process</option>
                                    <option value="None">ğŸš« None (Raw)</option>
                                    <option value="AI-Adaptive">ğŸ§  AI-Adaptive</option>
                                </select>
                                <input v-if="item.equipment !== 'Document'" v-model="item.goal" type="text" placeholder="Goal (e.g. Fit peaks)" class="w-full p-1.5 border rounded text-xs">
                            </div>
                        </div>
                    </div>
                    <button @click="analyze" :disabled="isAnalyzing || stagedFiles.length===0" class="w-full mt-4 py-3 bg-indigo-600 text-white rounded-lg font-bold flex justify-center gap-2 shadow hover:bg-indigo-700 disabled:opacity-50">
                        <div v-if="isAnalyzing" class="loader"></div>
                        <span>Generate Report</span>
                    </button>
                </div>
            </div>

            <!-- Report Area -->
            <div class="lg:col-span-8">
                <div v-if="result" class="space-y-6 animate-fade-in">
                    
                    <!-- Tools -->
                    <div class="flex justify-between items-center bg-white p-2 rounded-xl shadow-sm border border-slate-200">
                        <div class="flex gap-2">
                            <button @click="setLang('ko')" :class="lang==='ko'?'bg-indigo-100 text-indigo-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">ğŸ‡°ğŸ‡· í•œê¸€</button>
                            <button @click="setLang('en')" :class="lang==='en'?'bg-blue-100 text-blue-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">
                                <div v-if="isTranslating" class="w-3 h-3 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                                <span v-else>ğŸ‡ºğŸ‡¸</span> English
                            </button>
                        </div>
                        <button @click="dlPDF" class="px-3 py-1.5 bg-slate-800 text-white text-xs rounded">PDF Export</button>
                    </div>

                    <div id="report-view" class="bg-white p-8 rounded-xl shadow-sm border border-slate-200">
                        
                        <!-- Synthesis -->
                        <section class="mb-10">
                            <h2 class="text-lg font-bold text-indigo-700 mb-3 border-b pb-1">1. Synthesis</h2>
                            <div class="prose prose-sm text-slate-700 max-w-none" v-html="md(displayReport)"></div>
                        </section>

                        <!-- Details -->
                        <section>
                            <h2 class="text-lg font-bold text-slate-800 mb-5 border-b pb-1">2. Data Evidence</h2>
                            
                            <div v-for="(item, idx) in result.results" :key="idx" class="mb-8 p-4 bg-slate-50 rounded-lg border break-inside-avoid">
                                <div class="flex items-center justify-between mb-3">
                                    <div class="flex items-center gap-2">
                                        <span class="px-2 py-0.5 bg-white border rounded text-[10px] font-bold uppercase text-slate-500">{{ item.equipment }}</span>
                                        <h3 class="font-bold text-sm">{{ item.filename }}</h3>
                                    </div>
                                    <!-- Toggle Button -->
                                    <button @click="item.showDocs = !item.showDocs" class="text-xs text-indigo-600 font-bold hover:underline flex items-center gap-1">
                                        <i :data-lucide="item.showDocs ? 'eye-off' : 'eye'" class="w-3 h-3"></i>
                                        {{ item.showDocs ? 'Hide Details' : 'Show Details' }}
                                    </button>
                                </div>

                                <!-- Spectrum Chart + Interpretation -->
                                <div v-if="item.chart_data" class="bg-white p-2 rounded border mb-3">
                                    <div :id="'chart-'+idx" class="w-full h-60"></div>
                                    
                                    <!-- [V22 New] Interpretation Box -->
                                    <div v-if="item.interpretation && item.showDocs" class="mt-3 p-3 bg-indigo-50 border border-indigo-100 rounded text-xs text-indigo-800">
                                        <h4 class="font-bold mb-1 flex items-center gap-1"><i data-lucide="lightbulb" class="w-3 h-3"></i> AI Interpretation</h4>
                                        <div class="prose prose-xs text-indigo-700" v-html="md(item.interpretation)"></div>
                                    </div>
                                </div>

                                <!-- Image Viewer -->
                                <div v-if="item.raw_b64" class="bg-white p-2 rounded border mb-3">
                                    <div class="flex gap-2 mb-2 text-xs justify-center">
                                        <button @click="item.view='proc'" :class="item.view!=='raw'?'font-bold text-indigo-600':''">Processed</button>
                                        <span class="text-slate-300">|</span>
                                        <button @click="item.view='raw'" :class="item.view==='raw'?'font-bold text-indigo-600':''">Original</button>
                                        <span class="text-slate-300" v-if="item.footer_b64">|</span>
                                        <button v-if="item.footer_b64" @click="item.view='footer'" :class="item.view==='footer'?'font-bold text-indigo-600':''">Info Bar</button>
                                    </div>
                                    <img v-if="item.view!=='footer'" :src="'data:image/jpeg;base64,' + (item.view==='raw' ? item.raw_b64 : item.proc_b64)" class="max-h-80 mx-auto object-contain bg-black">
                                    <img v-if="item.view==='footer'" :src="'data:image/jpeg;base64,' + item.footer_b64" class="max-h-24 mx-auto object-contain border mt-2">
                                </div>

                                <!-- Docs -->
                                <div v-if="item.showDocs">
                                    <div v-if="item.pages" class="grid grid-cols-1 gap-4">
                                        <div v-for="p in item.pages" :key="p.page_num" class="flex gap-3 bg-white p-3 rounded border">
                                            <img :src="'data:image/jpeg;base64,'+p.image_b64" class="w-24 object-contain border">
                                            <div class="text-xs prose" v-html="md(lang === 'en' ? (p.desc_en || p.desc) : p.desc)"></div>
                                        </div>
                                    </div>
                                    <div v-if="item.slides" class="space-y-4">
                                        <div v-for="s in item.slides" :key="s.slide_num" class="bg-white p-3 rounded border">
                                            <div class="text-xs font-bold text-indigo-600 mb-1">Slide {{s.slide_num}}</div>
                                            <div class="text-xs prose mb-2 whitespace-pre-wrap max-h-32 overflow-y-auto">{{ s.text }}</div>
                                            <div v-if="s.images.length" class="grid grid-cols-2 gap-2 border-t pt-2">
                                                <div v-for="(img, imx) in s.images" :key="imx" class="bg-slate-50 p-2">
                                                    <img :src="'data:image/jpeg;base64,'+img.b64" class="max-h-32 mx-auto object-contain bg-white">
                                                    <p class="text-[10px] text-slate-500 text-center mt-1">{{ img.desc }}</p>
                                                </div>
                                            </div>
                                        </div>
                                    </div>
                                    
                                    <!-- Summary & Log -->
                                    <div v-if="item.summary" class="text-xs text-slate-600 mt-2 prose bg-slate-50 p-3 rounded" v-html="md(lang === 'en' ? (item.summary_en || item.summary) : item.summary)"></div>
                                    <div v-if="item.log && item.log.length > 0" class="mt-2 p-2 bg-gray-100 rounded border text-[10px] font-mono text-gray-600">
                                        <strong>âš™ï¸ Log:</strong> {{ item.log.join(' â†’ ') }}
                                    </div>
                                </div>

                            </div>
                        </section>
                    </div>
                </div>
            </div>
        </main>
    </div>
    <script>
        const { createApp, ref, computed, nextTick } = Vue;
        createApp({
            setup() {
                const stagedFiles = ref([]);
                const isAnalyzing = ref(false);
                const isTranslating = ref(false);
                const result = ref(null);
                const lang = ref('ko'); 
                const translatedReport = ref('');
                const md = (t) => marked.parse(t||'');

                const displayReport = computed(() => lang.value === 'en' && translatedReport.value ? translatedReport.value : (result.value ? result.value.final_report : ''));

                const addFiles = (e) => {
                    Array.from(e.target.files).forEach(f => {
                        let eq = 'General';
                        if(f.name.match(/\.(pdf|ppt|pptx)$/i)) eq = 'Document';
                        stagedFiles.value.push({ file: f, equipment: eq, goal: '', mode: 'Auto', view: 'proc', showDocs: true });
                    });
                    e.target.value = ''; 
                };
                const removeFile = (i) => stagedFiles.value.splice(i, 1);

                const analyze = async () => {
                    isAnalyzing.value = true;
                    lang.value = 'ko'; 
                    translatedReport.value = '';
                    const fd = new FormData();
                    const configs = {};
                    stagedFiles.value.forEach(item => {
                        fd.append('files', item.file);
                        configs[item.file.name] = { equipment: item.equipment, goal: item.goal, mode: item.mode };
                    });
                    fd.append('file_configs', JSON.stringify(configs));

                    try {
                        const res = await fetch('/api/analyze', { method: 'POST', body: fd });
                        const data = await res.json();
                        if(data.results) data.results.forEach(r => r.showDocs = true);
                        result.value = data;
                        await nextTick();
                        
                        data.results.forEach((item, i) => {
                            if(item.chart_data) {
                                const raw = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_raw), mode:'lines', name:'Raw', line:{color:'#cbd5e1', width:1} };
                                const proc = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_proc), mode:'lines', name:'Proc', line:{color:'#4f46e5', width:2} };
                                const base = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_base), mode:'lines', name:'Base', line:{color:'#f59e0b', width:1, dash:'dot'} };
                                Plotly.newPlot('chart-'+i, [raw, base, proc], {margin:{t:10,b:30,l:40,r:10}, showlegend:false}, {displayModeBar:false});
                            }
                        });
                        lucide.createIcons();
                    } catch(e) { alert(e); } 
                    finally { isAnalyzing.value = false; }
                };

                const setLang = async (target) => {
                    if (target === 'ko') { lang.value = 'ko'; return; }
                    if (target === 'en') {
                        if (translatedReport.value) { lang.value = 'en'; return; }
                        isTranslating.value = true;
                        try {
                            const res = await fetch('/api/translate', {
                                method: 'POST', headers: {'Content-Type': 'application/json'},
                                body: JSON.stringify({ text: result.value.final_report })
                            });
                            const data = await res.json();
                            translatedReport.value = data.translated;
                            lang.value = 'en';
                        } catch(e) { alert("Trans Error: " + e); }
                        finally { isTranslating.value = false; }
                    }
                };
                
                const dlPDF = () => html2pdf().set({ margin:10, filename:'V22_Report.pdf', image:{type:'jpeg',quality:0.98}, html2canvas:{scale:2}, jsPDF:{unit:'mm',format:'a4'} }).from(document.getElementById('report-view')).save();

                setTimeout(()=>lucide.createIcons(), 100);
                return { stagedFiles, isAnalyzing, isTranslating, result, lang, displayReport, addFiles, removeFile, analyze, md, dlPDF, setLang };
            }
        }).mount('#app');
    </script>
</body>
</html>







V21.1
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V22.1 ê³¼í•™ ì—”ì§„ (Anti-Merge Added)
# ==========================================
class ScienceProcessorV22_1:
    
    # --- [A] Universal Data Parser ---
    @staticmethod
    def read_any_format(content: bytes, filename: str) -> List[pd.DataFrame]:
        """
        [V22.1 Update] ì—‘ì…€ ë³‘í•© ì…€(Merge Cell) ëŒ€ì‘ ë¡œì§ ì¶”ê°€
        ì—‘ì…€ êµ¬ì¡°ê°€ ë³µì¡í•˜ë©´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ 'Data Hunter'ì—ê²Œ ë„˜ê¹€
        """
        dfs = []
        fname = filename.lower()
        
        # 1. Excel ì—”ì§„ ì‹œë„
        if fname.endswith(('.xlsx', '.xls')):
            try:
                xls = pd.ExcelFile(io.BytesIO(content))
                for s in xls.sheet_names:
                    # í—¤ë” ì—†ì´ ì›ë³¸ ê·¸ëŒ€ë¡œ ë¡œë“œ
                    df = pd.read_excel(xls, sheet_name=s, header=None)
                    
                    # [Check] ë°ì´í„°ê°€ ìœ íš¨í•œê°€? (ìˆ«ìê°€ ì¶©ë¶„í•œê°€?)
                    num_check = df.apply(pd.to_numeric, errors='coerce').notna().sum().sum()
                    
                    # ìˆ«ìê°€ ë„ˆë¬´ ì ê±°ë‚˜(êµ¬ì¡° ê¼¬ì„), ë³‘í•© ì…€ë¡œ ì¸í•´ NaNì´ ë„ˆë¬´ ë§ìœ¼ë©´
                    # í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ì „í™˜ (CSVë¡œ ë³€í™˜í•´ë²„ë¦¼)
                    if num_check < 10 or (df.isna().sum().sum() > df.size * 0.5):
                        print(f"Merge Cells Detected in {s}. Switching to Text Parser.")
                        # ì—‘ì…€ ë‚´ìš©ì„ CSV í…ìŠ¤íŠ¸ë¡œ ë¤í”„ (ë©”ëª¨ë¦¬ ìƒì—ì„œ)
                        csv_buffer = io.StringIO()
                        df.to_csv(csv_buffer, index=False, header=False)
                        csv_content = csv_buffer.getvalue()
                        
                        # í…ìŠ¤íŠ¸ íŒŒì„œ í˜¸ì¶œ (Robust CSV Reader ì¬ì‚¬ìš©)
                        text_dfs = ScienceProcessorV22_1.read_robust_text(csv_content)
                        dfs.extend(text_dfs)
                    else:
                        # ì •ìƒì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        if not df.empty: dfs.append(df)
                
                if dfs: return dfs
            except Exception as e:
                print(f"Excel Parse Error: {e}. Fallback to Text.")

        # 2. Text/CSV ì—”ì§„ ì‹œë„ (Fallback & Non-Excel)
        return ScienceProcessorV22_1.read_robust_csv_bytes(content)

    @staticmethod
    def read_robust_text(text_content: str) -> List[pd.DataFrame]:
        """ë¬¸ìì—´(String)ì—ì„œ ë°ì´í„° ë¸”ë¡ ì¶”ì¶œ"""
        valid_dfs = []
        lines = text_content.splitlines()
        separators = [',', '\t', ';', '\s+']
        
        # Line Scan
        data_start = -1
        delimiter = None
        
        for i, line in enumerate(lines[:100]):
            for sep in separators:
                parts = line.split() if sep=='\s+' else line.split(sep)
                nums = sum(1 for p in parts if re.match(r'^-?\d+(\.\d+)?$', p.strip()))
                if nums >= 2:
                    data_start = i; delimiter = sep; break
            if data_start != -1: break
            
        if data_start != -1:
            try:
                data_str = "\n".join(lines[data_start:])
                sep_arg = '\s+' if delimiter=='\s+' else delimiter
                df = pd.read_csv(io.StringIO(data_str), sep=sep_arg, header=None, engine='python')
                df_clean = df.apply(pd.to_numeric, errors='coerce').dropna(how='all', axis=0).dropna(how='all', axis=1)
                if df_clean.shape[0] > 2: valid_dfs.append(df_clean.reset_index(drop=True))
            except: pass
        return valid_dfs

    @staticmethod
    def read_robust_csv_bytes(content: bytes) -> List[pd.DataFrame]:
        """ë°”ì´íŠ¸(Bytes)ì—ì„œ ë°ì´í„° ë¸”ë¡ ì¶”ì¶œ"""
        # ì¸ì½”ë”© ìˆœíšŒí•˜ë©° í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ í›„ read_robust_text í˜¸ì¶œ
        for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
            try:
                text = content.decode(enc)
                dfs = ScienceProcessorV22_1.read_robust_text(text)
                if dfs: return dfs
            except: continue
        return []

    # --- [B] Hybrid Parser (V21) ---
    @staticmethod
    def parse_hybrid_block(df_block: pd.DataFrame) -> List[Dict]:
        extracted_series = []
        try:
            df_num = df_block.apply(pd.to_numeric, errors='coerce')
            is_meta_row = (df_block.notna() & df_num.isna()).any(axis=1)
            
            meta_text = " | ".join([x.strip() for x in df_block[is_meta_row].fillna('').values.flatten().astype(str) if x.strip()])
            data_rows = df_num[~is_meta_row].dropna(how='all')
            
            if data_rows.shape[0] < 5: return []
            vals = data_rows.values
            cols = vals.shape[1]
            
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x, y = vals[:, i], vals[:, i+1]
                    if np.sum(~np.isnan(x) & ~np.isnan(y)) > 5:
                        extracted_series.append({"x": x, "y": y, "name": f"Set-{i//2+1}", "meta": meta_text})
            elif cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    if np.sum(~np.isnan(x) & ~np.isnan(y)) > 5:
                        extracted_series.append({"x": x, "y": y, "name": f"Col-{i}", "meta": meta_text})
            elif cols == 1:
                y = vals[:, 0]
                extracted_series.append({"x": np.arange(len(y)), "y": y, "name": "Single", "meta": meta_text})
        except: pass
        return extracted_series

    # --- [C] Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
            if len(s) > 51: s = savgol_filter(s, 51, 3)
            return s
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            # ê²°ì¸¡ì¹˜ ì œê±°
            mask = np.isfinite(x) & np.isfinite(y)
            x, y, y_raw = x[mask], y[mask], y_raw[mask]
            
            if len(x) < 5: raise ValueError("Not enough data")

            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15
            if mode == "AI-Adaptive" and "noise" in goal.lower(): win = 31
            
            base = ScienceProcessorV22_1.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": [], "y_raw": [], "y_proc": [], "y_base": [], "peaks": [], "log": ["Error"], "stats": "Error"}

    # --- [D] Image Logic (V20) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV22_1.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        interfaces, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            sh = int(h * 0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            idx = np.argmax(row_sums)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
        
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV22_1.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV22_1.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV22_1.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

async def interpret_spectrum_data(raw_context: str, equipment: str) -> str:
    try:
        prompt = f"Analyze spectrum data ({equipment}). Explain physical meaning. Data: {raw_context}"
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'user','content':prompt}])
        return res['message']['content']
    except: return ""

# [5] App
app = FastAPI(title="Analyst V22.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V22.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Universal Parser)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. Universal Read (Excel or Text)
                    dfs = ScienceProcessorV22_1.read_any_format(c, n)
                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    res_list = []
                    for i, df in enumerate(dfs):
                        # 2. Block Detection (Pandas Native)
                        blocks = detect_excel_blocks(df)
                        if not blocks: blocks = [df]

                        for block in blocks:
                            # 3. Hybrid Parsing
                            series_list = ScienceProcessorV22_1.parse_hybrid_block(block)
                            for s in series_list:
                                try:
                                    res = ScienceProcessorV22_1.process_spectrum(s['x'], s['y'], m, g)
                                    # Chart data
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    
                                    ctx = f"Data: {s['name']}\nMeta: {s.get('meta','')}\nStats: {res['stats']}"
                                    interp = await interpret_spectrum_data(ctx, e)
                                    
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                        "raw_context": f"{ctx}\nInterpretation: {interp}",
                                        "chart_data": chart, "log": res["log"], "interpretation": interp
                                    })
                                except: pass
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Series"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV22_1.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)






ë¸Œì´21.1
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V21.1 ê³¼í•™ ì—”ì§„
# ==========================================
class ScienceProcessorV21:
    
    # --- [A] Hybrid Data Parser (Strict Numeric) ---
    @staticmethod
    def parse_hybrid_block(df_block: pd.DataFrame) -> List[Dict]:
        """
        [V21.1 Fix] ì—„ê²©í•œ ë°ì´í„° í–‰ íŒë³„
        - ë¬¸ìê°€ í•˜ë‚˜ë¼ë„ ì„ì—¬ ìˆìœ¼ë©´ ë©”íƒ€ë°ì´í„°ë¡œ ë¶„ë¥˜
        - ì˜¤ì§ ìˆ«ì(ë˜ëŠ” ë¹ˆì¹¸)ë§Œ ìˆëŠ” í–‰ë§Œ ë°ì´í„°ë¡œ ì‚¬ìš©
        """
        extracted_series = []
        try:
            # 1. ìˆ«ì ë³€í™˜ ì‹œë„ (ë¬¸ìëŠ” NaNì´ ë¨)
            df_num = df_block.apply(pd.to_numeric, errors='coerce')
            
            # 2. ì›ë³¸ ë°ì´í„°ê°€ ìˆëŠ”ë° ìˆ«ìë¡œ ë³€í™˜ ì•ˆ ëœ ê²ƒ ì°¾ê¸°
            # notna() : ì›ë³¸ì— ê°’ì´ ìˆìŒ
            # df_num.isna() : ìˆ«ìë¡œ ë³€í™˜ ì‹¤íŒ¨í•¨
            # ì´ ë‘ ì¡°ê±´ì´ ë™ì‹œì— ë§Œì¡±ë˜ë©´ "ë¬¸ìì—´ì´ í¬í•¨ëœ ì…€"ì„
            has_text = df_block.notna() & df_num.isna()
            
            # í–‰ ë‹¨ìœ„ë¡œ "ë¬¸ìì—´ì´ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€" í™•ì¸
            is_metadata_row = has_text.any(axis=1)
            is_data_row = ~is_metadata_row # ë¬¸ìê°€ í•˜ë‚˜ë„ ì—†ì–´ì•¼ ë°ì´í„° í–‰
            
            # 3. Extract Metadata
            meta_rows = df_block[is_metadata_row].fillna('')
            meta_text = ""
            if not meta_rows.empty:
                flat_text = meta_rows.astype(str).values.flatten()
                clean_text = [t.strip() for t in flat_text if t.strip() and t.lower() != 'nan']
                meta_text = " | ".join(clean_text)
                
            # 4. Extract Numeric Data
            data_rows = df_num[is_data_row].dropna(how='all')
            
            # ìœ íš¨ì„± ê²€ì‚¬
            if data_rows.shape[0] < 5: return []
            
            vals = data_rows.values
            cols = vals.shape[1]
            
            # [Logic] Column Splitting
            if cols >= 2 and cols % 2 == 0: # ì§ìˆ˜ ì—´ (Pairs)
                for i in range(0, cols, 2):
                    x = vals[:, i]
                    y = vals[:, i+1]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        extracted_series.append({
                            "x": x[mask], "y": y[mask], 
                            "name": f"Set-{i//2+1}", "meta": meta_text
                        })
            elif cols >= 3: # ê³µìœ  Xì¶•
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        extracted_series.append({
                            "x": x[mask], "y": y[mask], 
                            "name": f"Col-{i}", "meta": meta_text
                        })
            elif cols == 1: # Y Only
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    extracted_series.append({
                        "x": np.arange(len(y))[mask], "y": y[mask], 
                        "name": "Single", "meta": meta_text
                    })
                
        except Exception as e:
            print(f"Hybrid Parse Error: {e}")
            
        return extracted_series

    # --- [B] Spectrum ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
            if len(s) > 51: s = savgol_filter(s, 51, 3)
            return s
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV21.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": [], "stats": f"Raw Peaks: {len(peaks)}"}

            win = 15; do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessorV21.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV21.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats": f"Peaks: {len(peaks)}"}
        except: return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": [], "stats": "Error"}

    # --- [C] Image Logic (V20) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV21.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        # Interface Tracking (Green Line)
        grad_img = np.abs(np.gradient(img_blur, axis=0))
        for y_approx in interfaces:
            path = []
            for x in range(img_crop.shape[1]):
                ys, ye = max(0, y_approx-15), min(img_crop.shape[0], y_approx+15)
                local = grad_img[ys:ye, x]
                if len(local)>0: path.append(ys + np.argmax(local))
                else: path.append(y_approx)
            pts = np.array([np.transpose(np.vstack([np.arange(len(path)), path]))], np.int32)
            cv2.polylines(overlay, pts, False, (0, 255, 0), 2)

        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None
        
    @staticmethod
    def detect_embedded_metadata(img_array):
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h*0.15); roi = img_array[h-roi_h:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            e = cv2.Canny(g, 50, 150)
            d = cv2.dilate(e, cv2.getStructuringElement(cv2.MORPH_RECT,(15,3)), iterations=2)
            c, _ = cv2.findContours(d, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            min_y = roi_h; found = False
            for cnt in c:
                x,y,cw,ch = cv2.boundingRect(cnt)
                if cw>w*0.05 and ch>5 and (y+ch)>(roi_h*0.7): min_y=min(min_y,y); found=True
            return (h-roi_h)+min_y-10 if found else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV21.detect_footer_boundary(img_raw)
        if not sy: sy = ScienceProcessorV21.detect_embedded_metadata(img_raw)
        
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, _, l = ScienceProcessorV21.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V21.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V21.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V21 Hybrid
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    dfs = []
                    if n.endswith(('.csv', '.txt')):
                        # Robust Read CSV
                        for enc in ['utf-8', 'cp949', 'latin1']:
                            if dfs: break
                            for sep in [None, ',', '\t', ';']:
                                try:
                                    # í—¤ë” í¬í•¨ ì „ì²´ ì½ê¸°
                                    temp = pd.read_csv(io.BytesIO(c), sep=sep, encoding=enc, engine='python', header=None)
                                    if temp.shape[1] > 0: dfs = [temp]; break
                                except: pass
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        dfs = [pd.read_excel(xls, sheet_name=s, header=None) for s in xls.sheet_names]

                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    res_list = []
                    for i, df in enumerate(dfs):
                        # [V21] Island Detection -> Hybrid Parsing
                        blocks = detect_excel_blocks(df)
                        for b_idx, block in enumerate(blocks):
                            # Hybrid Parsing Call
                            series_list = ScienceProcessorV21.parse_hybrid_block(block)
                            
                            for s in series_list:
                                try:
                                    res = ScienceProcessorV21.process_spectrum(s['x'], s['y'], mode, g)
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    
                                    # Augment Context
                                    ctx = f"Data: {s['name']}\nMetadata: {s.get('meta','')}\nStats: {res['stats']}"
                                    
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                        "raw_context": ctx, "chart_data": chart, "log": res["log"]
                                    })
                                except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image (V20 Hybrid Crop)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV21.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean. Use Context Metadata.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



ë¸Œì´20.1
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V20.1 ê³¼í•™ ì—”ì§„ (Logic Restored)
# ==========================================
class ScienceProcessor:
    
    # --- [A] Thin Film Engine (Fixed) ---
    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        h, w = img_rotated.shape[:2]
        if abs(angle_deg) < 1.0: return img_rotated
        cy, cx = h // 2, w // 2
        crop_h, crop_w = int(h * 0.7), int(w * 0.7)
        y1, x1 = max(0, cy - crop_h // 2), max(0, cx - crop_w // 2)
        return img_rotated[y1:min(h, y1+crop_h), x1:min(w, x1+crop_w)]

    @staticmethod
    def analyze_thin_film(img_gray):
        """
        [V20.1 Fix] ê³„ë©´ ì •ë°€ ì¶”ì  (Green Line) ë° ê±°ì¹ ê¸° ë¶„ì„ ë³µêµ¬
        """
        h_orig, w_orig = img_gray.shape
        log = []
        
        # 1. Auto-Rotation
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
            
        log.append(f"Auto-Rotation: {best_angle}Â°")
        
        # 2. Process Image
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        h, w = img_crop.shape
        
        # 3. Global Interface Search (Red Line Candidates)
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces_approx, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        log.append(f"Global Layers: {len(interfaces_approx)}")
        
        # 4. Local Interface Tracking (Green Line Calculation)
        # ê° ì»¬ëŸ¼ë³„ë¡œ ìµœëŒ€ Gradient ìœ„ì¹˜ë¥¼ ì¶”ì í•˜ì—¬ êµ¬ë¶ˆêµ¬ë¶ˆí•œ ì„ ì„ ì°¾ìŒ
        interface_paths = [] 
        grad_img = np.abs(np.gradient(img_blur, axis=0)) # Yì¶• ë¯¸ë¶„
        
        for y_approx in interfaces_approx:
            path = []
            search_range = 15 # ìƒí•˜ 15í”½ì…€ íƒìƒ‰
            
            for x in range(w):
                y_start = max(0, y_approx - search_range)
                y_end = min(h, y_approx + search_range)
                
                local_col = grad_img[y_start:y_end, x]
                if len(local_col) == 0: 
                    path.append(y_approx)
                    continue
                    
                local_max_idx = np.argmax(local_col)
                path.append(y_start + local_max_idx)
            
            # ë…¸ì´ì¦ˆ ì œê±° (Smoothing Path)
            if len(path) > 31:
                path_smooth = savgol_filter(path, window_length=31, polyorder=2)
            else:
                path_smooth = path
            interface_paths.append(path_smooth)

        # 5. Metrology & Visualization
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        roughness_stats = []
        thickness_stats = []
        
        # Draw Interfaces
        for idx, path in enumerate(interface_paths):
            x_axis = np.arange(len(path))
            
            # A. Roughness Calculation (Actual - Average)
            avg_y = np.mean(path)
            residuals = path - avg_y
            rms = np.sqrt(np.mean(residuals**2)) # Rq
            ra = np.mean(np.abs(residuals))      # Ra
            roughness_stats.append(f"Layer {idx+1}: Ra={ra:.2f}px, Rq={rms:.2f}px")
            
            # B. Draw Green Line (Actual Profile)
            pts = np.array([np.transpose(np.vstack([x_axis, path]))], np.int32)
            cv2.polylines(overlay, pts, isClosed=False, color=(0, 255, 0), thickness=2)
            
            # C. Draw Red Line (Average Level)
            cv2.line(overlay, (0, int(avg_y)), (w, int(avg_y)), (0, 0, 255), 1)

        # Calculate Thickness
        if len(interface_paths) >= 2:
            for i in range(len(interface_paths) - 1):
                diff = np.array(interface_paths[i+1]) - np.array(interface_paths[i])
                mean_t = np.mean(diff)
                std_t = np.std(diff)
                thickness_stats.append(f"L{i+1}-L{i+2}: {mean_t:.1f}Â±{std_t:.1f}px")
                
                # Draw Text on Image
                mid_y = int((np.mean(interface_paths[i]) + np.mean(interface_paths[i+1])) / 2)
                cv2.putText(overlay, f"{mean_t:.1f}px", (w//2, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        stats = {
            "type": "Thin Film Metrology",
            "angle": best_angle,
            "roughness": roughness_stats,
            "thickness": thickness_stats
        }
        
        return overlay, stats, log

    # --- [B] Image Detectors (Hawk Eye) ---
    @staticmethod
    def detect_embedded_metadata(img_array):
        """ì„ë² ë”© í…ìŠ¤íŠ¸ ê°ì§€ (ê²½ê³„ì„  ì—†ì„ ë•Œ)"""
        try:
            h, w = img_array.shape[:2]
            roi_h = int(h * 0.15)
            roi = img_array[h-roi_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            
            edges = cv2.Canny(gray, 50, 150)
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))
            dilated = cv2.dilate(edges, kernel, iterations=2)
            contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            min_y = roi_h
            found = False
            for c in contours:
                x, y, cw, ch = cv2.boundingRect(c)
                if cw > w * 0.05 and ch > 5 and (y + ch) > (roi_h * 0.7):
                    min_y = min(min_y, y)
                    found = True
            
            return (h - roi_h) + min_y - 10 if found else None
        except: return None

    @staticmethod
    def detect_footer_boundary(img_array):
        """ê²½ê³„ì„ (ë°•ìŠ¤) ê°ì§€"""
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    # --- [C] Spectrum & Data Processors ---
    @staticmethod
    def read_robust_csv(content: bytes) -> List[pd.DataFrame]:
        valid_dfs = []
        encodings = ['utf-8', 'cp949', 'latin1']
        separators = [None, ',', '\t', ';', ' ']
        
        for enc in encodings:
            if valid_dfs: break
            for sep in separators:
                try:
                    buf = io.BytesIO(content)
                    if sep is None: df = pd.read_csv(buf, sep=None, engine='python', encoding=enc, header=None)
                    else: df = pd.read_csv(buf, sep=sep, encoding=enc, header=None)
                    
                    df_num = df.apply(pd.to_numeric, errors='coerce')
                    df_clean = df_num.dropna(how='all', axis=0).dropna(how='all', axis=1)
                    if df_clean.shape[0] > 5 and df_clean.shape[1] >= 1:
                        valid_dfs.append(df_clean.reset_index(drop=True))
                        break
                except: continue
        return valid_dfs

    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            # Fitting logic (Simplified for length)
            fits = [] 
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits}
        except: return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": []}

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        
        # 1. Hybrid Smart Crop
        split_y = ScienceProcessor.detect_footer_boundary(img_raw)
        method = "Line Detect"
        if split_y is None:
            split_y = ScienceProcessor.detect_embedded_metadata(img_raw)
            method = "Embedded Detect"
            
        body_img, footer_img = img_raw, None
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append(f"Crop: {method}")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body_img)
        foot_b64 = to_b64(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": process_log}

        # 2. Analysis
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body_img.copy(); stats = {}
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, l = ScienceProcessor.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs); stats["type"] = "Atoms"
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts); stats["type"] = "Particles"

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": process_log}

# [4] Helper & Extract
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V20.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V20.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Literature", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Literature", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                        sheet_name = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=0, header=None)
                        blocks = detect_excel_blocks(df)
                        sheet_name = "Sheet1"

                    if not blocks: return [{"type": "error", "filename": n, "msg": "No Valid Data"}]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            if not num_block.empty and num_block.shape[0] > 5:
                                if num_block.shape[1] == 1: x = np.arange(len(num_block)); y = num_block.iloc[:, 0].values
                                else: x = num_block.iloc[:, 0].values; y = num_block.iloc[:, 1].values
                                
                                res = ScienceProcessor.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                
                                stats_summary = f"Peaks: {len(res['peaks'])}"
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1})", "equipment": e,
                                    "raw_context": f"Spectrum {e}. {stats_summary}", 
                                    "chart_data": chart, "log": res["log"]
                                })
                        except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Fail"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)




ë¸Œì´20
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V20 ê³¼í•™ ì—”ì§„ (Hawk Eye)
# ==========================================
class ScienceProcessor:
    
    # --- [New] Embedded Metadata Detector ---
    @staticmethod
    def detect_embedded_metadata(img_array):
        """
        [V20 New] ê²½ê³„ì„ ì´ ì—†ëŠ” ì„ë² ë”© í…ìŠ¤íŠ¸/ìŠ¤ì¼€ì¼ë°” ê°ì§€
        """
        try:
            h, w = img_array.shape[:2]
            # í•˜ë‹¨ 15%ë§Œ ì§‘ì¤‘ ë¶„ì„
            roi_h = int(h * 0.15)
            roi = img_array[h-roi_h:, :]
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            
            # 1. ì—£ì§€ ê²€ì¶œ (ê¸€ìëŠ” ì—£ì§€ê°€ ë§ìŒ)
            edges = cv2.Canny(gray, 50, 150)
            
            # 2. íŒ½ì°½ (Dilation) - ê¸€ìë“¤ì„ í•˜ë‚˜ì˜ ë©ì–´ë¦¬ë¡œ ë­‰ì¹¨
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3)) # ê°€ë¡œë¡œ ê¸´ ì»¤ë„
            dilated = cv2.dilate(edges, kernel, iterations=2)
            
            # 3. ì»¨íˆ¬ì–´(ë©ì–´ë¦¬) ì°¾ê¸°
            contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            min_y_local = roi_h # ì´ˆê¸°ê°’: ë°”ë‹¥
            found_candidate = False
            
            for c in contours:
                x, y, cw, ch = cv2.boundingRect(c)
                # ë„ˆë¬´ ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°, ë„ˆë¬´ ìœ„ì— ìˆëŠ” ê²ƒ ì œê±°
                if cw > w * 0.05 and ch > 5: # ë„ˆë¹„ê°€ 5% ì´ìƒì¸ ë©ì–´ë¦¬ë§Œ
                    # ë©ì–´ë¦¬ê°€ ë°”ë‹¥ ë¶€ê·¼ì— ìˆì–´ì•¼ í•¨
                    if (y + ch) > (roi_h * 0.7):
                        min_y_local = min(min_y_local, y)
                        found_candidate = True
            
            if found_candidate:
                # ì°¾ì€ ë©ì–´ë¦¬ì˜ ìœ—ë¶€ë¶„ + ì—¬ìœ  ê³µê°„(Padding 10px)
                cut_y = (h - roi_h) + min_y_local - 10
                return cut_y
                
            return None
        except: return None

    @staticmethod
    def detect_footer_boundary(img_array):
        """ê¸°ì¡´ ë°©ì‹: ëª…í™•í•œ ê²½ê³„ì„ (ë°•ìŠ¤) ê°ì§€"""
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    # --- Spectrum Logic ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw Data"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            # Fitting Logic Omitted for brevity but assumed present
            fits = []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, Peaks: {len(peaks)}"
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits, "stats_summary": stats_txt}
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": [], "stats_summary": "Error"}

    # --- Image Logic ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        # Auto-Rotation
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Angle: {best_angle}")
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, "", log

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        
        # [V20 Hybrid Smart Crop]
        # 1. Try Line Detection first (Strong Box)
        split_y = ScienceProcessor.detect_footer_boundary(img_raw)
        crop_method = "Line Detect"
        
        # 2. If no line, try Embedded Text Detection
        if split_y is None:
            split_y = ScienceProcessor.detect_embedded_metadata(img_raw)
            crop_method = "Embedded Text Detect"
            
        body_img, footer_img = img_raw, None
        
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append(f"Smart Crop ({crop_method}): Footer Removed")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body_img); foot_b64 = to_b64(footer_img) if footer_img is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": process_log, "summary": "Raw"}
        
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body_img.copy(); stats = {}; summary = ""; l = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, summary, l = ScienceProcessor.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "summary": summary, "log": process_log}

    # --- [E] Robust Data Parser ---
    @staticmethod
    def read_robust_csv(content: bytes) -> List[pd.DataFrame]:
        valid_dfs = []
        encodings = ['utf-8', 'cp949', 'latin1']
        separators = [None, ',', '\t', ';', ' ']
        
        # Text decoding first
        text_content = ""
        for enc in encodings:
            try: text_content = content.decode(enc); break
            except: continue
        
        if not text_content: return []

        # Line scan for numeric blocks
        lines = text_content.splitlines()
        data_start = -1; delimiter = None
        
        for i, line in enumerate(lines[:100]):
            for sep in separators:
                parts = line.split() if sep==' ' else line.split(sep)
                # Count numbers
                nums = sum(1 for p in parts if re.match(r'^-?\d+(\.\d+)?$', p.strip()))
                if nums >= 2:
                    if i+1 < len(lines): # check next line
                        nxt = lines[i+1].split() if sep==' ' else lines[i+1].split(sep)
                        if len(nxt) == len(parts):
                            data_start = i; delimiter = sep; break
            if data_start != -1: break
            
        if data_start != -1:
            try:
                data_str = "\n".join(lines[data_start:])
                df = pd.read_csv(io.StringIO(data_str), sep=delimiter, header=None, engine='python')
                df = df.apply(pd.to_numeric, errors='coerce').dropna(how='all')
                if df.shape[0] > 2: valid_dfs.append(df)
            except: pass
            
        if not valid_dfs: # Fallback
            try:
                df = pd.read_csv(io.BytesIO(content), sep=None, engine='python', header=None)
                df = df.apply(pd.to_numeric, errors='coerce').dropna(how='all')
                if df.shape[0]>5: valid_dfs.append(df)
            except: pass
            
        return valid_dfs

    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        series_list = []
        try:
            df_num = df.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
            vals = df_num.values
            rows, cols = vals.shape
            if rows < 5: return []

            # Even Pairs
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x, y = vals[:, i], vals[:, i+1]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5: series_list.append({"x": x[mask], "y": y[mask], "name": f"Set{i//2+1}"})
            # Shared X
            elif cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]; mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5: series_list.append({"x": x[mask], "y": y[mask], "name": f"Col{i}"})
            # Single Y
            elif cols == 1:
                y = vals[:, 0]; mask = ~np.isnan(y)
                if np.sum(mask) > 5: series_list.append({"x": np.arange(len(y))[mask], "y": y[mask], "name": "Single"})
        except: pass
        return series_list

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V20")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V20 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    # ... (PPT Logic V17ê³¼ ë™ì¼) ...
                    return {"type": "doc", "filename": n, "equipment": "Lit", "raw_context": "Doc", "summary": "Processed"}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V19.5 Logic
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        for s in xls.sheet_names:
                            df = pd.read_excel(xls, sheet_name=s, header=None)
                            blocks.append(df)

                    res_list = []
                    for df in blocks:
                        series = ScienceProcessor.extract_series_from_df(df)
                        for s in series:
                            try:
                                res = ScienceProcessor.process_spectrum(s['x'], s['y'], m, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": n, "equipment": e,
                                    "raw_context": f"Peaks: {len(res['peaks'])}",
                                    "chart_data": chart, "log": res["log"]
                                })
                            except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image - V20 Logic
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





ë¸Œì´19
import os
import io
import asyncio
import base64
import json
import re
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V19 ê³¼í•™ ì—”ì§„ (Robust & Simple)
# ==========================================
class ScienceProcessorV19:
    
    # --- [A] New Data Parser (Pandas Native) ---
    @staticmethod
    def parse_data_robust(df: pd.DataFrame) -> List[Dict]:
        """
        [V19] ë³µì¡í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì—†ì´ Pandasë¡œë§Œ ë°ì´í„° ë¸”ë¡ê³¼ ìŒì„ ì¶”ì¶œ
        """
        extracted_series = []
        
        try:
            # 1. ìˆ«ìë§Œ ë‚¨ê¸°ê¸° (ë¬¸ìì—´ -> NaN)
            df_num = df.apply(pd.to_numeric, errors='coerce')
            
            # 2. ë°ì´í„°ê°€ ìˆëŠ” í–‰ë§Œ ë‚¨ê¸°ê¸° (ë¹ˆ ì¤„ ì œê±°)
            # ëŒ€ìš©ëŸ‰ íŒŒì¼(6000í–‰)ë„ ì—¬ê¸°ì„œ ê¹”ë”í•˜ê²Œ ì •ë¦¬ë¨
            df_clean = df_num.dropna(how='all') 
            
            if df_clean.empty: return []
            
            # 3. ë¹ˆ í–‰ì„ ê¸°ì¤€ìœ¼ë¡œ ë¸”ë¡ ë‚˜ëˆ„ê¸° (Pandas Groupby ì´ìš©)
            # ì¸ë±ìŠ¤ê°€ ì—°ì†ì ì´ì§€ ì•Šì€ êµ¬ê°„ì„ ì°¾ì•„ì„œ ê·¸ë£¹í•‘
            # (ì›ë˜ ì—‘ì…€ì—ì„œ ë–¨ì–´ì ¸ ìˆë˜ í‘œë“¤ì´ ì—¬ê¸°ì„œ ë¶„ë¦¬ë¨)
            df_clean['group'] = (df_clean.index.to_series().diff() > 1).cumsum()
            
            for _, group in df_clean.groupby('group'):
                # group ë‚´ì—ì„œ ë°ì´í„°ê°€ ì—†ëŠ” ì—´(Column) ì œê±°
                block = group.drop(columns=['group']).dropna(how='all', axis=1)
                
                if block.shape[0] < 5: continue # ë„ˆë¬´ ì§§ìœ¼ë©´ íŒ¨ìŠ¤
                
                vals = block.values
                cols = vals.shape[1]
                
                # [Logic] ì»¬ëŸ¼ ìŒ ì¶”ì¶œ
                # Case A: ì§ìˆ˜ ì»¬ëŸ¼ (X1, Y1, X2, Y2 ...) -> "ì¶•|ë°ì´í„°|ì¶•|ë°ì´í„°" ëŒ€ì‘
                if cols >= 2 and cols % 2 == 0:
                    for i in range(0, cols, 2):
                        x = vals[:, i]
                        y = vals[:, i+1]
                        # ìœ íš¨ ë°ì´í„° í•„í„°ë§
                        mask = ~np.isnan(x) & ~np.isnan(y)
                        if np.sum(mask) > 5:
                            extracted_series.append({
                                "x": x[mask], "y": y[mask], 
                                "name": f"Block{_}-Set{i//2+1}"
                            })
                            
                # Case B: í™€ìˆ˜ ì»¬ëŸ¼ or 1ì—´ (Index, Y1, Y2... or Y only)
                else:
                    x = vals[:, 0]
                    # ì²« ì—´ì´ Xë¼ê³  ê°€ì •í•˜ê³  ë‚˜ë¨¸ì§€ Yë“¤ ë§¤ì¹­
                    if cols > 1:
                        for i in range(1, cols):
                            y = vals[:, i]
                            mask = ~np.isnan(x) & ~np.isnan(y)
                            if np.sum(mask) > 5:
                                extracted_series.append({
                                    "x": x[mask], "y": y[mask], 
                                    "name": f"Block{_}-Col{i}"
                                })
                    # 1ì—´ë§Œ ìˆìœ¼ë©´ Indexë¥¼ Xë¡œ
                    elif cols == 1:
                        y = vals[:, 0]
                        mask = ~np.isnan(y)
                        if np.sum(mask) > 5:
                            extracted_series.append({
                                "x": np.arange(len(y))[mask], "y": y[mask], 
                                "name": f"Block{_}-Single"
                            })
                            
        except Exception as e:
            print(f"Parser Error: {e}")
            
        return extracted_series

    # --- [B] Spectrum Processing ---
    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def gaussian(x, amp, cen, wid): 
        return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV19.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            
            # Mode: None
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {
                    "x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y),
                    "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks],
                    "log": ["Raw Data"], "fits": [], 
                    "stats_summary": f"Raw Data. Peaks: {len(peaks)}"
                }

            # Mode: Auto / AI-Adaptive
            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            # Baseline & Smoothing
            base = ScienceProcessorV19.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win:
                y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessorV19.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, MaxY: {np.max(y):.1f}, Peaks: {len(peaks)}"

            return {
                "x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base,
                "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks],
                "log": ["Processed"], "fits": fits, "stats_summary": stats_txt
            }
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": [], "stats_summary": "Error"}

    # --- [C] Image Logic (V15 Same) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        # Auto-Rotation
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV19.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        thk = np.diff(interfaces).tolist() if len(interfaces)>=2 else []
        summary = f"Thin Film: {len(interfaces)} layers. Angle: {best_angle}. Avg Thickness: {np.mean(thk) if thk else 0:.1f}px"
        return overlay, {"type":"Thin Film", "layers":len(interfaces), "angle":best_angle}, summary, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel)), axis=1)
            if np.max(row_sums) < (w*30): return None
            idx = np.argmax(row_sums)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV19.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": [], "summary": "Raw Image"}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; summary = ""; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, summary, log = ScienceProcessorV19.analyze_thin_film(gray)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            cnt = 0
            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                cnt = len(blobs); stats["type"] = "Atoms"
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                cnt = len(cnts); stats["type"] = "Particles"
            
            stats["count"] = cnt
            summary = f"Detected {cnt} {stats.get('type','features')}."

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "summary": summary, "log": log}

# [4] Helper
async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V19")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V19 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V19 Robust Parser
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    dfs = []
                    # 1. Load Data
                    if n.endswith(('.csv', '.txt')):
                        for enc in ['utf-8', 'cp949', 'latin1']:
                            if dfs: break
                            for sep in [None, ',', '\t']:
                                try:
                                    temp = pd.read_csv(io.BytesIO(c), sep=sep, encoding=enc, engine='python', header=None)
                                    if temp.shape[1] > 0: dfs = [temp]; break
                                except: pass
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        dfs = [pd.read_excel(xls, sheet_name=s, header=None) for s in xls.sheet_names]

                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    # 2. Extract & Process
                    res_list = []
                    for i, df in enumerate(dfs):
                        series = ScienceProcessorV19.parse_data_robust(df)
                        for s in series:
                            res = ScienceProcessorV19.process_spectrum(s['x'], s['y'], mode, g)
                            # Downsample for Chart
                            step = max(1, len(s['x'])//100)
                            chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                            
                            res_list.append({
                                "type": "spectrum", "filename": f"{n} ({s['name']})", 
                                "equipment": e, 
                                "raw_context": f"Spectrum {s['name']}: {res['stats_summary']}",
                                "chart_data": chart, "log": res["log"], "fits": res["fits"]
                            })
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Numeric Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV19.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('summary','')}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)




ë¸Œì´18.1
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- JSON Sanitizer ---
def sanitize_json(obj):
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V18.1 ê³¼í•™ ì—”ì§„
# ==========================================
class ScienceProcessor:
    
    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [Optimization] ì „ì²´ ì‹œíŠ¸ì—ì„œ (X,Y) ìŒ ê³ ì† ì¶”ì¶œ
        """
        series_list = []
        try:
            # 1. ì „ì²´ ìˆ«ì ë³€í™˜ (Coerce errors)
            # ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ì‹œ ì—¬ê¸°ì„œ ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆì§€ë§Œ, label() ë³´ë‹¨ ë¹ ë¦„
            df_num = df.apply(pd.to_numeric, errors='coerce')
            
            # 2. ë°ì´í„°ê°€ ìˆëŠ” í–‰/ì—´ë§Œ ë‚¨ê¸°ê¸° (Trim)
            df_clean = df_num.dropna(how='all', axis=0).dropna(how='all', axis=1)
            
            if df_clean.empty: return []
            
            vals = df_clean.values
            rows, cols = vals.shape
            
            if rows < 5: return [] 

            # A. ì§ìˆ˜ ì»¬ëŸ¼ êµ¬ì¡° (X, Y, X, Y ...)
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x = vals[:, i]
                    y = vals[:, i+1]
                    # ìœ íš¨ ë°ì´í„°(NaN ì•„ë‹˜) í•„í„°ë§
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Set {i//2+1}"})
            
            # B. ê³µìœ  Xì¶• êµ¬ì¡° (X, Y1, Y2 ...) - Aì—ì„œ ëª» ì°¾ì•˜ì„ ë•Œ ì‹œë„
            if not series_list and cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Col {i}"})
            
            # C. 1ì—´ ë°ì´í„° (Y only)
            if not series_list and cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    x = np.arange(len(y))[mask] # Index as X
                    series_list.append({"x": x, "y": y[mask], "name": "Single"})
                    
        except Exception as e:
            print(f"Extraction Error: {e}")
            
        return series_list

    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            # Downsampling for Chart (ì¤‘ìš”: 6000ê°œ ë‹¤ ê·¸ë¦¬ë©´ ëŠë¦¼)
            # ì›ë³¸ ë¶„ì„ì€ ì „ì²´ë¡œ í•˜ë˜, ì°¨íŠ¸ìš©ì€ ì¤„ì„ (ì—¬ê¸°ì„  ë¶„ì„ìš© ë¦¬í„´)
            
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            # Stats Summary for LLM
            stats_txt = f"Range: {np.min(x):.1f}~{np.max(x):.1f}, MaxY: {np.max(y):.1f}, Peaks: {len(peaks)}"
            
            return {
                "x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, 
                "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], 
                "log": ["Processed"], "fits": [], "stats_summary": stats_txt
            }
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": [], "stats_summary": "Error"}

    # ... Image Logic (Same as V15.5) ...
    @staticmethod
    def detect_footer_boundary(img):
        try:
            h, w = img.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img[h-sh:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        img_blur = gaussian_filter(img_crop, sigma=3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        layers, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        ov = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y in layers: cv2.line(ov, (0, y), (ov.shape[1], y), (0, 0, 255), 2)
        thk = np.diff(layers).tolist() if len(layers)>=2 else []
        summary = f"Thin Film: {len(layers)} layers. Angle: {best_angle}. Avg Thickness: {np.mean(thk) if thk else 0:.1f}px"
        return ov, {"type":"Thin Film", "layers":len(layers), "angle":best_angle}, summary, log

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessor.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "summary": "Raw Image", "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; summary = ""; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, summary, log = ScienceProcessor.analyze_thin_film(gray)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            cnt = 0
            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                cnt = len(blobs); stats["type"] = "Atoms"
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                cnt = len(cnts); stats["type"] = "Particles"
            
            stats["count"] = cnt
            summary = f"Detected {cnt} {stats.get('type','features')}."

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "summary": summary, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ boolean maskë§Œ ì‚¬ìš©
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V18.1")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V18.1 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                # (V15.5 Logic Same)
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - â˜… Optimized Strategy
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    res_list = []
                    sheet_name = "Data"
                    
                    # 1. CSV Handler
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                        for i, df in enumerate(blocks):
                            # CSVëŠ” ë³´í†µ Series êµ¬ì¡°ê°€ ëª…í™•í•¨
                            series = ScienceProcessor.extract_series_from_df(df)
                            for s in series:
                                res = ScienceProcessor.process_spectrum(s['x'], s['y'], mode, g)
                                step = max(1, len(s['x'])//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                    "raw_context": f"Stats: {res.get('stats_summary', 'N/A')}",
                                    "chart_data": chart, "log": res["log"]
                                })
                    
                    # 2. Excel Handler (Optimized)
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        for sname in xls.sheet_names:
                            df = pd.read_excel(xls, sheet_name=sname, header=None)
                            
                            # Strategy A: Fast Column Scan (for 6000+ rows)
                            series = ScienceProcessor.extract_series_from_df(df)
                            if series:
                                for s in series:
                                    res = ScienceProcessor.process_spectrum(s['x'], s['y'], mode, g)
                                    step = max(1, len(s['x'])//100)
                                    chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                                    res_list.append({
                                        "type": "spectrum", "filename": f"{n} ({sname}-{s['name']})", "equipment": e,
                                        "raw_context": f"Stats: {res.get('stats_summary', 'N/A')}",
                                        "chart_data": chart, "log": res["log"]
                                    })
                            else:
                                # Strategy B: Island Detection (Fallback)
                                blocks = detect_excel_blocks(df)
                                for i, block in enumerate(blocks):
                                    # ... (Same Block Logic) ...
                                    # (ê°„ì†Œí™”ë¥¼ ìœ„í•´ ìƒëµ, ìœ„ extract_seriesê°€ ì‹¤íŒ¨í–ˆì„ ë•Œë§Œ ì‹¤í–‰ë¨)
                                    pass

                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Valid Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('summary','')}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{})
                    }
                except: return {"type": "error", "filename": n, "msg": "Error"}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    # Sanitize
    final_results = sanitize_json(final_results)

    # Synthesis
    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
            
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





ë¸Œì´18
import os
import io
import asyncio
import base64
import json
import re
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- [V18 Fix] JSON Sanitizer ---
def sanitize_json(obj):
    """JSON ì „ì†¡ ì „ NaN/Inf ì²­ì†Œ"""
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return 0.0 # None ëŒ€ì‹  0.0ìœ¼ë¡œ ì²˜ë¦¬í•´ í”Œë¡¯ ì—ëŸ¬ ë°©ì§€
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return 0.0
        return float(obj)
    return obj

# ==========================================
# [3] V18 ê³¼í•™ ì—”ì§„
# ==========================================
class ScienceProcessorV18:
    
    @staticmethod
    def extract_series_from_df(df: pd.DataFrame) -> List[Dict]:
        """
        [V18 New] ì—‘ì…€/CSV ë°ì´í„° êµ¬ì¡° ìë™ íŒë³„ ë° ì¶”ì¶œ
        Returns: List of {'x': array, 'y': array, 'name': str}
        """
        series_list = []
        try:
            # 1. ìˆ«ìë§Œ ë‚¨ê¸°ê¸°
            df_num = df.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
            if df_num.empty: return []
            
            vals = df_num.values
            cols = vals.shape[1]
            rows = vals.shape[0]
            
            if rows < 5: return [] # ë„ˆë¬´ ì§§ìœ¼ë©´ íŒ¨ìŠ¤

            # Case A: ì§ìˆ˜ ì»¬ëŸ¼ (X, Y), (X, Y) ...
            if cols >= 2 and cols % 2 == 0:
                for i in range(0, cols, 2):
                    x = vals[:, i]
                    y = vals[:, i+1]
                    # ìœ íš¨ ë°ì´í„° í•„í„°ë§ (NaN ì œê±°)
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Set {i//2+1}"})
            
            # Case B: í™€ìˆ˜ ì»¬ëŸ¼ or ê³µìœ  Xì¶• (X, Y1, Y2 ...)
            # (ìœ„ Case Aì—ì„œ ê±¸ëŸ¬ì§€ì§€ ì•Šì€ ê²½ìš°, í˜¹ì€ ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ê³µìœ ì¶•ì„ ì›í•  ë•Œ)
            # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ: ë§Œì•½ Case Aë¡œ í•˜ë‚˜ë„ ëª» ì°¾ì•˜ë‹¤ë©´ Case B ì‹œë„
            if not series_list and cols >= 2:
                x = vals[:, 0]
                for i in range(1, cols):
                    y = vals[:, i]
                    mask = ~np.isnan(x) & ~np.isnan(y)
                    if np.sum(mask) > 5:
                        series_list.append({"x": x[mask], "y": y[mask], "name": f"Col {i}"})
            
            # Case C: 1ì—´ ë°ì´í„° (Y only)
            if not series_list and cols == 1:
                y = vals[:, 0]
                mask = ~np.isnan(y)
                if np.sum(mask) > 5:
                    x = np.arange(len(y))[mask]
                    series_list.append({"x": x, "y": y[mask], "name": "Single Series"})
                    
        except Exception as e:
            print(f"Extraction Error: {e}")
            
        return series_list

    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            # Parameters
            win = 15
            do_fit = False
            
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            # Process
            if mode == "None":
                y_base = np.zeros_like(y)
                y_proc = y
            else:
                y_base = ScienceProcessorV18.simple_baseline(y)
                y_proc = np.maximum(y - y_base, 0)
                if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            # Peaks
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            # [V18] LLMì„ ìœ„í•œ í†µê³„ ìš”ì•½ ìƒì„± (Raw Text ëŒ€ì‹  ì‚¬ìš©)
            stats_summary = (
                f"Range X: {np.min(x):.2f}~{np.max(x):.2f}, "
                f"Max Y: {np.max(y_proc):.2f}, "
                f"Detected Peaks: {len(peaks)} points. "
                f"Top Peaks at X: {[float(f'{x[p]:.1f}') for p in peaks[:5]]}"
            )

            return {
                "x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": y_base,
                "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks],
                "log": ["Processed"], 
                "stats_summary": stats_summary # LLMìš© í…ìŠ¤íŠ¸
            }
        except Exception as e:
            return {"x": [], "stats_summary": f"Error: {e}", "log": ["Fail"]}

    # --- Image Logic (Same as V15.5) ---
    @staticmethod
    def detect_footer_boundary(img):
        try:
            h, w = img.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img[h-sh:, :]
            g = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            s = np.sum(np.uint8(np.absolute(cv2.Sobel(g, cv2.CV_64F, 0, 1, ksize=3))), axis=1)
            if np.max(s) < (w*30): return None
            idx = np.argmax(s)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def analyze_thin_film(img_gray):
        # (V15 Thin Film Logic)
        h, w = img_gray.shape
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        
        # Valid Crop
        cy, cx = img_rot.shape[0]//2, img_rot.shape[1]//2
        ch, cw = int(h*0.7), int(w*0.7)
        img_crop = img_rot[max(0, cy-ch//2):min(img_rot.shape[0], cy+ch//2), max(0, cx-cw//2):min(img_rot.shape[1], cx+cw//2)]
        
        img_blur = gaussian_filter(img_crop, 3)
        prof = np.mean(img_blur, axis=1)
        grad = np.abs(np.gradient(prof))
        layers, _ = find_peaks(grad, height=np.max(grad)*0.25, distance=30)
        
        ov = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y in layers: cv2.line(ov, (0, y), (ov.shape[1], y), (0, 0, 255), 2)
        
        # LLMìš© ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
        thk = np.diff(layers).tolist() if len(layers)>=2 else []
        summary = f"Thin Film Analysis: Rotation {best_angle}deg. Found {len(layers)} interfaces. Avg Thickness: {np.mean(thk) if thk else 0:.2f} px."
        
        return ov, {"type":"Thin Film", "angle":best_angle, "layers":len(layers)}, summary

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessorV18.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        b_raw = to_b64(body); b_foot = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": b_raw, "proc_b64": b_raw, "footer_b64": b_foot, "stats": {"info": "Raw"}, "summary": "Raw Image"}

        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; summary = ""
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, summary = ScienceProcessorV18.analyze_thin_film(gray)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            cnt = 0
            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                cnt = len(blobs); stats["type"] = "Atoms"
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                cnt = len(cnts); stats["type"] = "Particles"
            
            stats["count"] = cnt
            summary = f"Detected {cnt} {stats.get('type','features')}."

        return {"raw_b64": b_raw, "proc_b64": to_b64(overlay), "footer_b64": b_foot, "stats": stats, "summary": summary}

# [4] Helper
async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        return res['message']['content']
    except Exception as e: return f"Vision Error: {e}"

# [5] App
app = FastAPI(title="Analyst V18")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V18 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    # ... (PPT Logic omitted for brevity, assumes V17 logic is here) ...
                    return {"type": "doc", "filename": n, "equipment": "Lit", "raw_context": "Doc", "summary": "Processed"}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Robust V18)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    # 1. íŒŒì¼ ì½ê¸° (ëª¨ë“  ë°©ë²• ë™ì›)
                    dfs = []
                    if n.endswith(('.csv', '.txt')):
                        # V15.6 Logic: Header Hunter
                        text_content = ""
                        try: text_content = c.decode('utf-8')
                        except: 
                            try: text_content = c.decode('cp949')
                            except: pass
                        
                        if text_content:
                            lines = text_content.splitlines()
                            data_start = 0
                            # ë°ì´í„° ì‹œì‘ì  ì°¾ê¸° (ìˆ«ì 2ê°œ ì´ìƒ)
                            for i, line in enumerate(lines[:50]):
                                parts = re.split(r'[,\t\s]+', line.strip())
                                nums = [p for p in parts if re.match(r'^-?\d+(\.\d+)?$', p)]
                                if len(nums) >= 2: data_start = i; break
                            
                            try:
                                dfs = [pd.read_csv(io.StringIO("\n".join(lines[data_start:])), sep=None, engine='python', header=None)]
                            except: pass
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        dfs = [pd.read_excel(xls, sheet_name=s, header=None) for s in xls.sheet_names]

                    if not dfs: return [{"type": "error", "filename": n, "msg": "Read Fail"}]

                    # 2. ë°ì´í„° ì¶”ì¶œ ë° ì²˜ë¦¬
                    res_list = []
                    for i, df in enumerate(dfs):
                        series = ScienceProcessorV18.extract_series_from_df(df)
                        for s in series:
                            res = ScienceProcessorV18.process_spectrum(s['x'], s['y'], mode, g)
                            # Chart Data
                            step = max(1, len(s['x'])//100)
                            chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(s['x']), step)]
                            
                            res_list.append({
                                "type": "spectrum", "filename": f"{n} ({s['name']})", "equipment": e,
                                "raw_context": f"Spectrum ({e}): {res['stats_summary']}", # â˜… LLMìš© ìš”ì•½ í…ìŠ¤íŠ¸ ì‚¬ìš©
                                "chart_data": chart, "log": res["log"]
                            })
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "No Numeric Data"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image (V18)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV18.process_image(c, e, m, g)
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read text.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. {g}. {vis_res.get('summary','')}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nCV Analysis: {vis_res.get('summary','')}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{})
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    # [V18 Fix] Sanitize ALL results (NaN -> 0.0)
    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    for r in final_results:
        if r.get("type") != "error":
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
            
    final_report = "Fail"
    if data_ctx or lit_ctx:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ìˆ˜ì„ ì—°êµ¬ì›. í•œê¸€. í‘œ í™œìš©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



ë¸Œì´17
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- [V17 Fix] JSON Sanitizer (Top Level) ---
def sanitize_json(obj):
    """NaN, Inf -> None ë³€í™˜ (ì¬ê·€í•¨ìˆ˜)"""
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return None
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_json(v) for v in obj]
    elif isinstance(obj, (np.int64, np.int32)):
        return int(obj)
    elif isinstance(obj, (np.float64, np.float32)):
        if np.isnan(obj) or np.isinf(obj): return None
        return float(obj)
    return obj

# ==========================================
# [3] V17 ê³¼í•™ ì—”ì§„
# ==========================================
class ScienceProcessorV17:
    
    @staticmethod
    def extract_data_pairs_from_sheet(df: pd.DataFrame) -> List[pd.DataFrame]:
        """
        [V17 New] ì‹œíŠ¸ ì „ì²´ë¥¼ ì»¬ëŸ¼ ë‹¨ìœ„ë¡œ ìŠ¤ìº”í•˜ì—¬ (X, Y) ìŒì„ ì¶”ì¶œ
        'ì¶•|ë°ì´í„°|ì¶•|ë°ì´í„°' ì²˜ëŸ¼ ë¶™ì–´ìˆëŠ” ê²½ìš°ë¥¼ í•´ê²°í•¨
        """
        valid_pairs = []
        
        # 1. ì „ì²´ë¥¼ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„ (ë¬¸ìëŠ” NaN)
        df_num = df.apply(pd.to_numeric, errors='coerce')
        
        num_cols = df_num.shape[1]
        
        # 2. 2ì—´ì”© ì§ì§€ì–´ ê²€ì‚¬ (0-1, 2-3, ...)
        # í™€ìˆ˜ ì—´ì´ ë‚¨ìœ¼ë©´ ë§ˆì§€ë§‰ì€ ë¬´ì‹œí•˜ê±°ë‚˜ Index-Valueë¡œ ì²˜ë¦¬ ê°€ëŠ¥
        # ì—¬ê¸°ì„œëŠ” ëª…ì‹œì ì¸ ìŒ(Pair) êµ¬ì¡°ë¥¼ ìš°ì„ í•¨
        
        processed_cols = set()
        
        # Strategy A: ì§ìˆ˜ ë‹¨ìœ„ ìŠ¤ìº” (Col 0&1, Col 2&3...)
        for i in range(0, num_cols - 1, 2):
            try:
                # ë‘ ì»¬ëŸ¼ì„ ë½‘ìŒ
                sub_df = df_num.iloc[:, i:i+2].copy()
                # ë‘˜ ë‹¤ NaNì¸ í–‰ ì œê±°
                sub_df = sub_df.dropna(how='any') # Xë‚˜ Y ì¤‘ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ë¬´íš¨
                
                # ìœ íš¨ ë°ì´í„°ê°€ ì¶©ë¶„íˆ(5ê°œ ì´ìƒ) ìˆìœ¼ë©´ ë°ì´í„°ë¡œ ì¸ì •
                if sub_df.shape[0] > 5:
                    # ì›ë³¸ í—¤ë”ë‚˜ ì •ë³´ë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´, ë°ì´í„°ê°€ ì‹œì‘ë˜ëŠ” ìœ„ì¹˜ ì°¾ê¸°
                    # (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”í•˜ì—¬ ìˆ«ì ë°ì´í„°ë§Œ ì¶”ì¶œ)
                    sub_df.columns = [0, 1] # ì»¬ëŸ¼ëª… ì´ˆê¸°í™”
                    valid_pairs.append({
                        "x": sub_df[0].values,
                        "y": sub_df[1].values,
                        "col_idx": i
                    })
                    processed_cols.add(i)
                    processed_cols.add(i+1)
            except: pass
            
        return valid_pairs

    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        h, w = img_rotated.shape[:2]
        if abs(angle_deg) < 1.0: return img_rotated
        cy, cx = h // 2, w // 2
        crop_h, crop_w = int(h * 0.7), int(w * 0.7)
        y1, x1 = max(0, cy - crop_h // 2), max(0, cx - crop_w // 2)
        return img_rotated[y1:min(h, y1+crop_h), x1:min(w, x1+crop_w)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h_orig, w_orig = img_gray.shape
        log = []
        
        # Rotation
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        log.append(f"Auto-Rotation: {best_angle}Â°")
        
        # Process
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV17.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        log.append(f"Layers: {len(interfaces)}")
        thicknesses = np.diff(interfaces).tolist() if len(interfaces) >= 2 else []
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces:
            cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
            
        return overlay, {
            "type": "Thin Film", "angle": best_angle, "layers": len(interfaces),
            "thickness_px": thicknesses, "avg_thickness": float(np.mean(thicknesses)) if thicknesses else 0
        }, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        body_img, footer_img = img_raw, None
        split_y = ScienceProcessorV17.detect_footer_boundary(img_raw)
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append("Footer Removed")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        b64_raw = to_b64(body_img)
        b64_footer = to_b64(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": b64_raw, "proc_b64": b64_raw, "footer_b64": b64_footer, "stats": {"info": "Raw"}, "log": process_log}

        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, l = ScienceProcessorV17.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": b64_raw, "proc_b64": to_b64(overlay), "footer_b64": b64_footer, "stats": stats, "log": process_log}

    # --- Spectrum ---
    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV17.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        log = []
        y_raw = y.copy()
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}
        
        win = 15
        do_fit = False
        if mode == "AI-Adaptive":
            if "noise" in goal.lower(): win = 31
            if "fit" in goal.lower(): do_fit = True
        
        base = ScienceProcessorV17.simple_baseline(y)
        y_proc = np.maximum(y - base, 0)
        if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
        fits = ScienceProcessorV17.fit_peaks(x, y_proc, peaks) if do_fit else []
        
        return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits}

# [4] Helper
async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V17")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V17 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Literature", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Literature", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V17 Column Scanner
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    res_list = []
                    # 1. Load DataFrame (Robust)
                    dfs = []
                    if n.endswith(('.csv', '.txt')):
                        try: dfs = [pd.read_csv(io.BytesIO(c), sep=None, engine='python', header=None)]
                        except: dfs = [pd.read_csv(io.BytesIO(c), header=None)]
                        sheet_prefix = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        for s in xls.sheet_names:
                            dfs.append(pd.read_excel(xls, sheet_name=s, header=None))
                        sheet_prefix = "Sheet"

                    # 2. Column-wise Pair Extraction
                    for i, df in enumerate(dfs):
                        pairs = ScienceProcessorV17.extract_data_pairs_from_sheet(df)
                        for p_idx, pair in enumerate(pairs):
                            try:
                                x, y = pair['x'], pair['y']
                                res = ScienceProcessorV17.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                
                                res_list.append({
                                    "type": "spectrum", 
                                    "filename": f"{n} ({sheet_prefix}{i}-Pair{p_idx})", 
                                    "equipment": e, 
                                    "raw_context": f"Peaks: {len(res['peaks'])}", 
                                    "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                })
                            except: pass
                            
                    if not res_list: return [{"type": "error", "filename": n, "msg": "No Valid Pairs Found"}]
                    return res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV17.process_image(c, e, m, g)
                    if not vis_res: return {"type": "error", "filename": n, "msg": "Fail"}
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. ëª©í‘œ:{g}. í†µê³„:{vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    # [Sanitize] Final check for NaN/Inf
    final_results = sanitize_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r and r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ìˆ˜ì„ ì—°êµ¬ì›. í•œê¸€. í‘œ í™œìš©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



ë¸Œì´16
import os
import io
import asyncio
import base64
import json
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# --- [V16 Fix] JSON Sanitizer ---
def sanitize_for_json(obj):
    """NaN, Infinityë¥¼ JSON í‘œì¤€ì¸ Noneìœ¼ë¡œ ë³€í™˜"""
    if isinstance(obj, float):
        if np.isnan(obj) or np.isinf(obj): return None
        return obj
    elif isinstance(obj, dict):
        return {k: sanitize_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [sanitize_for_json(v) for v in obj]
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        if np.isnan(obj) or np.isinf(obj): return None
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return sanitize_for_json(obj.tolist())
    return obj

# ==========================================
# [3] V16 ê³¼í•™ ì—”ì§„
# ==========================================
class ScienceProcessor:
    
    @staticmethod
    def read_robust_csv(content: bytes) -> List[pd.DataFrame]:
        valid_dfs = []
        encodings = ['utf-8', 'cp949', 'latin1']
        separators = [None, ',', '\t', ';', ' '] 
        
        for enc in encodings:
            if valid_dfs: break
            for sep in separators:
                try:
                    buf = io.BytesIO(content)
                    if sep is None:
                        df = pd.read_csv(buf, sep=None, engine='python', encoding=enc, header=None)
                    else:
                        df = pd.read_csv(buf, sep=sep, encoding=enc, header=None)
                    
                    df_num = df.apply(pd.to_numeric, errors='coerce')
                    df_clean = df_num.dropna(how='all', axis=0).dropna(how='all', axis=1)
                    
                    if df_clean.shape[0] > 5 and df_clean.shape[1] >= 1:
                        valid_dfs.append(df_clean.reset_index(drop=True))
                        break
                except: continue
        return valid_dfs

    # --- Spectrum Logic ---
    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessor.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        try:
            w = max(5, len(y)//10)
            s = pd.Series(y).rolling(window=w, center=True).min()
            b = s.bfill().ffill().values 
            if len(b) > 51: b = savgol_filter(b, 51, 3)
            return b
        except: return np.zeros_like(y)

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            fits = ScienceProcessor.fit_peaks(x, y_proc, peaks) if do_fit else []
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits}
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": []}

    # --- Image Logic (V15 Same) ---
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        return overlay, {"type": "Thin Film", "layers": len(interfaces), "angle": best_angle}, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel)), axis=1)
            if np.max(row_sums) < (w*30): return None
            idx = np.argmax(row_sums)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessor.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, l = ScienceProcessor.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V16")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V16 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV) - V16 Multi-Column Pair Support
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []
                    # Parsing
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                        sheet_name = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=0, header=None)
                        blocks = detect_excel_blocks(df)
                        sheet_name = "Sheet1"

                    if not blocks: return [{"type": "error", "filename": n, "msg": "No valid data"}]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            # ìˆ«ì ë³€í™˜
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            
                            # [V16 NEW] Multi-Column Splitter (Pair Loop)
                            num_cols = num_block.shape[1]
                            
                            # 2ì—´ ì´ìƒì´ê³  ì§ìˆ˜ ì»¬ëŸ¼ì´ë©´ (X,Y), (X,Y) êµ¬ì¡°ë¡œ ê°„ì£¼
                            # (ë‹¨, 2ì—´ì¸ ê²½ìš°ë„ ì´ ë£¨í”„ì— í¬í•¨ë¨)
                            if num_cols >= 2 and num_cols % 2 == 0:
                                for k in range(0, num_cols, 2):
                                    x = num_block.iloc[:, k].values
                                    y = num_block.iloc[:, k+1].values
                                    if len(x) < 5: continue
                                    
                                    res = ScienceProcessor.process_spectrum(x, y, mode, g)
                                    step = max(1, len(x)//100)
                                    chart = [{"x": float(res["x"][idx]), "y_proc": float(res["y_proc"][idx]), "y_raw": float(res["y_raw"][idx]), "y_base": float(res["y_base"][idx])} for idx in range(0, len(x), step)]
                                    
                                    series_name = f"Series-{k//2+1}" if num_cols > 2 else ""
                                    
                                    res_list.append({
                                        "type": "spectrum", 
                                        "filename": f"{n} ({sheet_name}-{i+1} {series_name})", 
                                        "equipment": e, 
                                        "raw_context": f"Spectrum {series_name}. Peaks: {len(res['peaks'])}", 
                                        "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                    })
                            
                            # í™€ìˆ˜ ì»¬ëŸ¼ or 1ì—´ (Index + Data or Just Data)
                            elif num_cols >= 1:
                                if num_cols == 1:
                                    x = np.arange(len(num_block))
                                    y = num_block.iloc[:, 0].values
                                else:
                                    # 3ì—´, 5ì—´ ë“± ì• ë§¤í•œ ê²½ìš°: 0ì—´ì„ X, ë‚˜ë¨¸ì§€ë¥¼ Yë¡œ
                                    x = num_block.iloc[:, 0].values
                                    for k in range(1, num_cols):
                                        y = num_block.iloc[:, k].values
                                        res = ScienceProcessor.process_spectrum(x, y, mode, g)
                                        step = max(1, len(x)//100)
                                        chart = [{"x": float(res["x"][idx]), "y_proc": float(res["y_proc"][idx]), "y_raw": float(res["y_raw"][idx]), "y_base": float(res["y_base"][idx])} for idx in range(0, len(x), step)]
                                        res_list.append({
                                            "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1} Col{k})", "equipment": e,
                                            "raw_context": f"Spectrum. Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                        })

                        except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Process Fail"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"Analyze {e}.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}", "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{})
                    }
                except: return {"type": "error", "filename": n, "msg": "Error"}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    # [V16 Fix] Sanitize JSON before sending
    final_results = sanitize_for_json(final_results)

    data_ctx, lit_ctx = "", ""
    has_valid = False
    for r in final_results:
        if r.get("type") != "error":
            has_valid = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") == "Literature": lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_valid:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





ë¸Œì´15.6

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# ==========================================
# [3] V15.6 ê³¼í•™ ì—”ì§„ (Header Hunter)
# ==========================================
class ScienceProcessor:
    
    @staticmethod
    def read_robust_csv(content: bytes) -> List[pd.DataFrame]:
        """
        [V15.6 New] í—¤ë” ìŠ¤í‚¤í•‘ ë¡œì§ ê°•í™”
        íŒŒì¼ì„ ë¼ì¸ ë‹¨ìœ„ë¡œ ë¶„ì„í•˜ì—¬ ìˆ«ì ë°ì´í„° ë¸”ë¡ì„ ì§ì ‘ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
        """
        valid_dfs = []
        
        # 1. í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”© ì‹œë„ (ì¸ì½”ë”© ì°¾ê¸°)
        text_content = ""
        decoded = False
        for enc in ['utf-8', 'cp949', 'latin1', 'utf-16']:
            try:
                text_content = content.decode(enc)
                decoded = True
                break
            except: continue
            
        if not decoded: return [] # í…ìŠ¤íŠ¸ ì•„ë‹˜

        # 2. ë¼ì¸ ë‹¨ìœ„ ë¶„ì„ (Data Hunting)
        lines = text_content.splitlines()
        data_start_idx = -1
        delimiter = None
        
        # êµ¬ë¶„ì í›„ë³´
        separators = [',', '\t', ';', '\s+'] 
        
        # "ìˆ«ìê°€ 2ê°œ ì´ìƒ ìˆëŠ” í–‰"ì´ ì–´ë””ì„œë¶€í„° ì‹œì‘ë˜ëŠ”ì§€ íƒìƒ‰
        for i, line in enumerate(lines[:100]): # ì²˜ìŒ 100ì¤„ë§Œ ê²€ì‚¬
            line = line.strip()
            if not line: continue
            
            # êµ¬ë¶„ì ì¶”ì •
            for sep in separators:
                if sep == '\s+': parts = line.split()
                else: parts = line.split(sep)
                
                # ìˆ«ì ë³€í™˜ ê°€ëŠ¥í•œì§€ ì²´í¬
                num_count = 0
                for p in parts:
                    try: 
                        float(p.strip())
                        num_count += 1
                    except: pass
                
                # í•œ ì¤„ì— ìˆ«ìê°€ 2ê°œ ì´ìƒì´ë©´ ë°ì´í„° ì‹œì‘ìœ¼ë¡œ ì˜ì‹¬
                if num_count >= 2:
                    # ë‹¤ìŒ ì¤„ë„ í™•ì¸í•´ì„œ í™•ì‹ ì„ ê°€ì§
                    if i + 1 < len(lines):
                        next_parts = lines[i+1].split() if sep == '\s+' else lines[i+1].split(sep)
                        if len(next_parts) == len(parts): # ì»¬ëŸ¼ ìˆ˜ ë¹„ìŠ·í•˜ë©´ í™•ì •
                            data_start_idx = i
                            delimiter = sep
                            break
            if data_start_idx != -1: break
            
        # 3. ë°ì´í„° ë¡œë“œ
        if data_start_idx != -1:
            try:
                # ì°¾ì€ ìœ„ì¹˜ë¶€í„° ë‹¤ì‹œ ì½ê¸° (StringIO ì‚¬ìš©)
                data_str = "\n".join(lines[data_start_idx:])
                if delimiter == '\s+':
                    df = pd.read_csv(io.StringIO(data_str), sep='\s+', header=None, engine='python')
                else:
                    df = pd.read_csv(io.StringIO(data_str), sep=delimiter, header=None, engine='python')
                
                # ìˆ«ìë§Œ ë‚¨ê¸°ê¸° (Double Check)
                df_num = df.apply(pd.to_numeric, errors='coerce')
                df_clean = df_num.dropna(how='all', axis=0).dropna(how='all', axis=1)
                
                if df_clean.shape[0] > 2:
                    valid_dfs.append(df_clean.reset_index(drop=True))
            except: pass
            
        # 4. ì‹¤íŒ¨ ì‹œ ê¸°ì¡´(í†µì§¸ë¡œ ì½ê¸°) ë°©ì‹ ì‹œë„ (Fallback)
        if not valid_dfs:
            try:
                df = pd.read_csv(io.BytesIO(content), sep=None, engine='python', header=None)
                df_num = df.apply(pd.to_numeric, errors='coerce').dropna(how='all')
                if df_num.shape[0] > 5: valid_dfs.append(df_num)
            except: pass
            
        return valid_dfs

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        try:
            y_raw = y.copy()
            if mode == "None":
                peaks, _ = find_peaks(y, height=np.max(y)*0.05)
                return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}

            win = 15
            do_fit = False
            if mode == "AI-Adaptive":
                if "noise" in goal.lower(): win = 31
                if "fit" in goal.lower(): do_fit = True
            
            base = ScienceProcessor.simple_baseline(y)
            y_proc = np.maximum(y - base, 0)
            if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
            
            peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
            
            fits = [] # (Fitting Logic Omitted for Brevity - Same as V15)
            
            return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": ["Processed"], "fits": fits}
        except:
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [], "log": ["Error"], "fits": []}

    # ... (Image / Helper Logic V15 Same) ...
    @staticmethod
    def crop_valid_rotated_region(img, angle):
        h, w = img.shape[:2]
        if abs(angle) < 1.0: return img
        cy, cx = h//2, w//2; ch, cw = int(h*0.7), int(w*0.7)
        return img[max(0, cy-ch//2):min(h, cy+ch//2), max(0, cx-cw//2):min(w, cx+cw//2)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h, w = img_gray.shape; log = []
        scale = min(1.0, 512/max(h,w)); small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0; max_var = -1
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1); prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
        
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces: cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
        
        return overlay, {"type": "Thin Film", "layers": len(interfaces), "angle": best_angle}, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h<100 or w<100: return None
            sh = int(h*0.25); roi = img_array[h-sh:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel)), axis=1)
            if np.max(row_sums) < (w*30): return None
            idx = np.argmax(row_sums)
            return (h-sh)+idx if idx < sh*0.98 else None
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        body, footer = img_raw, None
        sy = ScienceProcessor.detect_footer_boundary(img_raw)
        if sy: body = img_raw[:sy, :]; footer = img_raw[sy:, :]
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        raw_b64 = to_b64(body); foot_b64 = to_b64(footer) if footer is not None else None
        
        if mode == "None": return {"raw_b64": raw_b64, "proc_b64": raw_b64, "footer_b64": foot_b64, "stats": {"info": "Raw"}, "log": []}
        
        gray = cv2.cvtColor(body, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body.copy(); stats = {}; log = []
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰"]):
            overlay, stats, l = ScienceProcessor.analyze_thin_film(gray)
            log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": raw_b64, "proc_b64": to_b64(overlay), "footer_b64": foot_b64, "stats": stats, "log": log}

# [4] Helper
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=1: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V15.6")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V15.6 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Literature", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Literature", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Spectrum (Excel/CSV)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []
                    # Robust CSV
                    if n.endswith(('.csv', '.txt')):
                        blocks = ScienceProcessor.read_robust_csv(c)
                        sheet_name = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=0, header=None)
                        blocks = detect_excel_blocks(df)
                        sheet_name = "Sheet1"

                    if not blocks: return [{"type": "error", "filename": n, "msg": "No valid data"}]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            if block.shape[1] == 1: x = np.arange(len(block)); y = block.iloc[:, 0].values
                            else: x = block.iloc[:, 0].values; y = block.iloc[:, 1].values
                            
                            if len(x) < 5: continue
                            res = ScienceProcessor.process_spectrum(x, y, mode, g)
                            step = max(1, len(x)//100)
                            chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                            
                            res_list.append({
                                "type": "spectrum", "filename": f"{n}-{i}", "equipment": e,
                                "raw_context": f"Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"]
                            })
                        except: pass
                    
                    return res_list if res_list else [{"type": "error", "filename": n, "msg": "Parse Error"}]
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"Analyze {e}.")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}", "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{})
                    }
                except: return {"type": "error", "filename": n, "msg": "Error"}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    data_ctx, lit_ctx = "", ""
    has_content = False
    for r in final_results:
        if r.get("type") != "error":
            has_content = True
            raw = r.get("raw_context") or ""
            if r.get("equipment") == "Literature": lit_ctx += f"\nFile {r['filename']}: {raw[:3000]}"
            else: data_ctx += f"\nFile {r['filename']}: {raw[:3000]}"
    
    final_report = "Fail"
    if has_content:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Researcher. Korean Report.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)




ë¸Œì´15.3
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# ==========================================
# [3] ê³¼í•™ ì²˜ë¦¬ ì—”ì§„ (V15.3 Core)
# ==========================================
class ScienceProcessor:
    
    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        h, w = img_rotated.shape[:2]
        if abs(angle_deg) < 1.0: return img_rotated
        cy, cx = h // 2, w // 2
        crop_h, crop_w = int(h * 0.7), int(w * 0.7)
        y1, x1 = max(0, cy - crop_h // 2), max(0, cx - crop_w // 2)
        return img_rotated[y1:min(h, y1+crop_h), x1:min(w, x1+crop_w)]

    @staticmethod
    def analyze_thin_film(img_gray):
        h_orig, w_orig = img_gray.shape
        log = []
        
        # 1. Auto-Rotation
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle, max_var = 0, -1
        
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
            
        log.append(f"Auto-Rotation: {best_angle}Â°")
        
        # 2. Process
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessor.crop_valid_rotated_region(img_rot, best_angle)
        
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        log.append(f"Layers: {len(interfaces)}")
        thicknesses = np.diff(interfaces).tolist() if len(interfaces) >= 2 else []
        
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces:
            cv2.line(overlay, (0, y_pos), (img_crop.shape[1], y_pos), (0, 0, 255), 2)
            
        return overlay, {
            "type": "Thin Film", "angle": best_angle, "layers": len(interfaces),
            "thickness_px": thicknesses, "avg_thickness": float(np.mean(thicknesses)) if thicknesses else 0
        }, log

    @staticmethod
    def detect_footer_boundary(img_array):
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        body_img, footer_img = img_raw, None
        split_y = ScienceProcessor.detect_footer_boundary(img_raw)
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append("Footer Removed")
        
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        b64_raw = to_b64(body_img)
        b64_footer = to_b64(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": b64_raw, "proc_b64": b64_raw, "footer_b64": b64_footer, "stats": {"info": "Raw"}, "log": process_log}

        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        overlay = body_img.copy()
        stats = {}
        
        if any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰", "ë‘ê»˜"]):
            overlay, stats, l = ScienceProcessor.analyze_thin_film(gray)
            process_log.extend(l)
        else:
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = mode=="AI-Adaptive" and any(x in kwd for x in ["atom", "ì›ì"])
            detect_parts = mode=="AI-Adaptive" and any(x in kwd for x in ["particle", "ì…ì"])
            if mode == "Auto":
                if equipment in ["STEM","TEM"]: detect_atoms = True
                if equipment in ["SEM","Optical"]: detect_parts = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
            elif detect_parts:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)

        return {"raw_b64": b64_raw, "proc_b64": to_b64(overlay), "footer_b64": b64_footer, "stats": stats, "log": process_log}

    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessor.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        log = []
        y_raw = y.copy()
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}
        
        win = 15
        do_fit = False
        if mode == "AI-Adaptive":
            if "noise" in goal.lower(): win = 31
            if "fit" in goal.lower(): do_fit = True
        
        base = ScienceProcessor.simple_baseline(y)
        y_proc = np.maximum(y - base, 0)
        if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
        
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
        fits = ScienceProcessor.fit_peaks(x, y_proc, peaks) if do_fit else []
        
        return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits}

# [4] í—¬í¼
def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# [5] App
app = FastAPI(title="Analyst V15.3")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V15.3 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document Path (Literature)
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))

        # [B] Spectrum Path (Excel/CSV) - Fix: elif ì‚¬ìš©
        elif fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    blocks = []; sheet_name = "Data"
                    if n.endswith(('.csv', '.txt')):
                        success = False
                        for enc in ['utf-8', 'cp949', 'latin1']:
                            if success: break
                            for sep in [None, ',', '\t', ';']:
                                try:
                                    df = pd.read_csv(io.BytesIO(c), sep=sep, encoding=enc, engine='python', header=None)
                                    # ìˆ«ìë§Œ ìˆëŠ”ì§€ ì²´í¬
                                    num = df.apply(pd.to_numeric, errors='coerce').dropna(how='all')
                                    if num.shape[0] > 2:
                                        blocks = [df]; success = True; break
                                except: pass
                        if not blocks: return {"type": "error", "filename": n, "msg": "CSV Read Failed"}
                        sheet_name = "CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=xls.sheet_names[0], header=None)
                        blocks = detect_excel_blocks(df)
                        sheet_name = xls.sheet_names[0]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            if not num_block.empty and num_block.shape[0] > 5:
                                x = num_block.iloc[:, 0].fillna(0).values; y = num_block.iloc[:, 1].fillna(0).values
                                res = ScienceProcessor.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1})", "equipment": e,
                                    "raw_context": f"Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                })
                        except: pass
                    
                    if not res_list: return {"type": "error", "filename": n, "msg": "No valid data"}
                    return res_list[0] if len(res_list)==1 else res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            tasks.append(proc_spec(content, filename, eq, goal, mode))

        # [C] Image Path - Fix: elif ì‚¬ìš©
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessor.process_image(c, e, m, g)
                    if not vis_res: return {"type": "error", "filename": n, "msg": "Fail"}
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. ëª©í‘œ:{g}. í†µê³„:{vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    data_ctx, lit_ctx = "", ""
    has_data = False
    for r in final_results:
        if r.get("type") != "error":
            has_data = True
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if has_data and (data_ctx or lit_ctx):
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ìˆ˜ì„ ì—°êµ¬ì›. í•œê¸€. í‘œ í™œìš©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)





ë¸Œì´15
import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# ==========================================
# [3] V15 ê³¼í•™ ì—”ì§„ (Interface Metrology)
# ==========================================
class ScienceProcessorV15:
    
    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        h, w = img_rotated.shape[:2]
        if abs(angle_deg) < 1.0: return img_rotated # ì‘ì€ ê°ë„ëŠ” ë¬´ì‹œ
        
        # ê°„ë‹¨í•œ ì¤‘ì•™ë¶€ Crop (ë§ˆë¦„ëª¨ ë¬¸ì œ íšŒí”¼)
        # ì•ˆì „í•˜ê²Œ ì¤‘ì•™ 70% ì˜ì—­ë§Œ ì‚¬ìš© (ë³µì¡í•œ ê¸°í•˜í•™ ê³„ì‚° ëŒ€ì‹  ì•ˆì •ì„± íƒí•¨)
        cy, cx = h // 2, w // 2
        crop_h, crop_w = int(h * 0.7), int(w * 0.7)
        y1 = max(0, cy - crop_h // 2)
        x1 = max(0, cx - crop_w // 2)
        y2 = min(h, y1 + crop_h)
        x2 = min(w, x1 + crop_w)
        return img_rotated[y1:y2, x1:x2]

    @staticmethod
    def analyze_thin_film(img_gray):
        """
        [V15] ê³„ë©´ ì¶”ì  ë° ê±°ì¹ ê¸°/ë‘ê»˜ ì •ë°€ ë¶„ì„
        """
        h_orig, w_orig = img_gray.shape
        log = []
        
        # 1. Auto-Rotation
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0
        max_var = -1
        
        for ang in range(-90, 91, 2):
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var: max_var = var; best_angle = ang
            
        log.append(f"Auto-Rotation: {best_angle}Â°")
        
        # 2. Rotate & Valid Crop
        img_rot = rotate(img_gray, best_angle, reshape=True, order=3, mode='constant', cval=np.mean(img_gray))
        img_crop = ScienceProcessorV15.crop_valid_rotated_region(img_rot, best_angle)
        h, w = img_crop.shape
        
        # 3. Global Peak Search (Approximate Locations)
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        # ì£¼ìš” ê³„ë©´ ì°¾ê¸°
        interfaces_approx, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        log.append(f"Global Layers Found: {len(interfaces_approx)}")
        
        # 4. Local Interface Tracking (Pixel-wise)
        # ê° xì¢Œí‘œë§ˆë‹¤ gradientê°€ ìµœëŒ€ì¸ yë¥¼ ì°¾ìŒ (Window Search)
        interface_paths = [] # List of [y_0, y_1, ..., y_w]
        
        grad_img = np.abs(np.gradient(img_blur, axis=0)) # Yì¶• ë°©í–¥ ë¯¸ë¶„ ì´ë¯¸ì§€
        
        for y_approx in interfaces_approx:
            path = []
            search_range = 15 # ìƒí•˜ 15í”½ì…€ íƒìƒ‰
            
            for x in range(w):
                # ê²€ìƒ‰ ë²”ìœ„ ì„¤ì •
                y_start = max(0, y_approx - search_range)
                y_end = min(h, y_approx + search_range)
                
                # í•´ë‹¹ ì»¬ëŸ¼(x)ì˜ ë¡œì»¬ ì˜ì—­ì—ì„œ ìµœëŒ€ Gradient ìœ„ì¹˜ ì°¾ê¸°
                local_col = grad_img[y_start:y_end, x]
                if len(local_col) == 0: 
                    path.append(y_approx)
                    continue
                    
                local_max_idx = np.argmax(local_col)
                real_y = y_start + local_max_idx
                path.append(real_y)
            
            # ë…¸ì´ì¦ˆ ì œê±° (Median Filter on Path)
            path_smooth = savgol_filter(path, window_length=31, polyorder=2)
            interface_paths.append(path_smooth)

        # 5. Analysis: Roughness & Thickness
        roughness_stats = []
        thickness_stats = {}
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        
        # Draw Paths
        for idx, path in enumerate(interface_paths):
            # A. Polynomial Fit (Trend) - 3ì°¨ í•¨ìˆ˜
            x_axis = np.arange(len(path))
            coeffs = np.polyfit(x_axis, path, 3)
            poly_func = np.poly1d(coeffs)
            trend_line = poly_func(x_axis)
            
            # B. Roughness (Actual - Trend)
            residuals = path - trend_line
            rms = np.sqrt(np.mean(residuals**2)) # Rq
            ra = np.mean(np.abs(residuals))      # Ra
            roughness_stats.append(f"Layer {idx+1}: Rq={rms:.2f}px, Ra={ra:.2f}px")
            
            # C. Draw
            # Actual Path (Green)
            pts = np.array([np.transpose(np.vstack([x_axis, path]))], np.int32)
            cv2.polylines(overlay, pts, isClosed=False, color=(0, 255, 0), thickness=2)
            # Trend Line (Red Dashed - Simulated by drawing line)
            pts_trend = np.array([np.transpose(np.vstack([x_axis, trend_line]))], np.int32)
            cv2.polylines(overlay, pts_trend, isClosed=False, color=(0, 0, 255), thickness=1)

        # Thickness Distribution
        if len(interface_paths) >= 2:
            # ë‘ ê³„ë©´ ì‚¬ì´ì˜ ê±°ë¦¬ (Point-to-Point)
            t_dist = []
            for i in range(len(interface_paths) - 1):
                diff = np.array(interface_paths[i+1]) - np.array(interface_paths[i])
                mean_t = np.mean(diff)
                std_t = np.std(diff)
                t_dist.append(f"L{i+1}-L{i+2}: Avg={mean_t:.1f}px (Â±{std_t:.2f})")
                
                # ì‹œê°í™” (ì¤‘ê°„ ì§€ì ì— í…ìŠ¤íŠ¸)
                mid_y = int((np.mean(interface_paths[i]) + np.mean(interface_paths[i+1])) / 2)
                cv2.putText(overlay, f"{mean_t:.1f}px", (w//2, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            
            thickness_stats["distribution"] = t_dist
            
        stats = {
            "type": "Thin Film Metrology",
            "angle": best_angle,
            "roughness": roughness_stats,
            "thickness": thickness_stats
        }
        
        return overlay, stats, log

    @staticmethod
    def detect_footer_boundary(img_array):
        # (ê¸°ì¡´ V14 ë™ì¼)
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        
        # 1. Smart Crop
        body_img, footer_img, split_y = img_raw, None, ScienceProcessorV15.detect_footer_boundary(img_raw)
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append("Smart Crop: Footer removed")
        
        # Helper Encoders
        def to_b64(im): return base64.b64encode(cv2.imencode('.jpg', im)[1]).decode('utf-8')
        b64_raw = to_b64(body_img)
        b64_footer = to_b64(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": b64_raw, "proc_b64": b64_raw, "footer_b64": b64_footer, "stats": {"info": "Raw"}, "log": process_log}

        # 2. Logic Branch
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        
        processed_overlay = body_img.copy()
        stats = {}
        
        # [V15] Thin Film Metrology
        is_film = any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰", "ë‘ê»˜", "ê³„ë©´", "roughness", "ê±°ì¹ ê¸°"])
        
        if is_film:
            processed_overlay, f_stats, f_log = ScienceProcessorV15.analyze_thin_film(gray)
            stats.update(f_stats)
            process_log.extend(f_log)
        else:
            # Particle / Atom
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = False
            detect_particles = False
            
            if mode == "AI-Adaptive":
                if any(x in kwd for x in ["atom", "ì›ì"]): detect_atoms = True
                if any(x in kwd for x in ["particle", "ì…ì"]): detect_particles = True
            elif mode == "Auto":
                if equipment in ["STEM", "TEM"]: detect_atoms = True
                if equipment in ["SEM", "Optical"]: detect_particles = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(processed_overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                process_log.append(f"Atoms: {len(blobs)}")
            elif detect_particles:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(processed_overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                process_log.append(f"Particles: {len(cnts)}")

        return {
            "raw_b64": b64_raw,
            "proc_b64": to_b64(processed_overlay),
            "footer_b64": b64_footer,
            "stats": stats,
            "log": process_log
        }

    # --- Spectrum & Helper ---
    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV15.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        log = []
        y_raw = y.copy()
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}
        
        win = 15
        do_fit = False
        if mode == "AI-Adaptive":
            if "noise" in goal.lower(): win = 31
            if "fit" in goal.lower(): do_fit = True
        
        base = ScienceProcessorV15.simple_baseline(y)
        y_proc = np.maximum(y - base, 0)
        if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
        fits = ScienceProcessorV15.fit_peaks(x, y_proc, peaks) if do_fit else []
        
        return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits}

def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# --- App ---
app = FastAPI(title="Analyst V15")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V15 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Data (Spectrum)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    if n.endswith(('.csv', '.txt')):
                        try: df = pd.read_csv(io.BytesIO(c))
                        except: df = pd.read_csv(io.BytesIO(c), delimiter='\t')
                        blocks = [df]; sheet_name="CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=xls.sheet_names[0], header=None)
                        blocks = detect_excel_blocks(df); sheet_name=xls.sheet_names[0]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            if not num_block.empty and num_block.shape[0] > 5:
                                x = num_block.iloc[:, 0].fillna(0).values; y = num_block.iloc[:, 1].fillna(0).values
                                res = ScienceProcessorV15.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1})", "equipment": e,
                                    "raw_context": f"Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                })
                        except: pass
                    return res_list[0] if len(res_list)==1 else res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            pass

        # [C] Data (Image)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV15.process_image(c, e, m, g)
                    if not vis_res: return {"type": "error", "filename": n, "msg": "Fail"}
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. ëª©í‘œ:{g}. í†µê³„:{vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    data_ctx, lit_ctx = "", ""
    for r in final_results:
        if r.get("type") != "error":
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if data_ctx or lit_ctx:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ìˆ˜ì„ ì—°êµ¬ì›. í•œê¸€. í‘œ í™œìš©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



ë¸Œì´14

import os
import io
import asyncio
import base64
import json
import re
import math
from typing import List, Dict, Any, Optional
from pydantic import BaseModel

# [1] ë³´ì•ˆ ì„¤ì •
os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0,::1'
if 'HTTP_PROXY' in os.environ: del os.environ['HTTP_PROXY']
if 'HTTPS_PROXY' in os.environ: del os.environ['HTTPS_PROXY']

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, FileResponse
import pandas as pd
import numpy as np

# ê³¼í•™ ì—°ì‚°
from scipy.signal import find_peaks, savgol_filter
from scipy.optimize import curve_fit
from scipy.ndimage import label, find_objects, gaussian_filter, rotate
from skimage.feature import blob_log
import cv2

from ollama import Client 
from PIL import Image
from pdf2image import convert_from_bytes
from pptx import Presentation
from pptx.enum.shapes import MSO_SHAPE_TYPE

# [2] ì„¤ì •
OLLAMA_HOST = "http://127.0.0.1:11434"
ollama_client = Client(host=OLLAMA_HOST)
VISION_MODEL = "qwen3-vl:30b-a3b-instruct" 
TEXT_MODEL = "llama3:70b"

# [3] V14 ê³¼í•™ ì—”ì§„ (Lossless Projection)
class ScienceProcessorV14:
    
    # --- [A] Geometry Helpers ---
    @staticmethod
    def crop_valid_rotated_region(img_rotated, angle_deg):
        """
        [V14 New] íšŒì „ëœ ì´ë¯¸ì§€ì—ì„œ ê²€ì€ìƒ‰(ë¹ˆ ê³µê°„)ì„ ì œì™¸í•œ
        'ê°€ì¥ í° ë‚´ë¶€ ì§ì‚¬ê°í˜•(Largest Inscribed Rectangle)'ì„ ì°¾ì•„ ì˜ë¼ëƒ…ë‹ˆë‹¤.
        """
        h, w = img_rotated.shape[:2]
        angle_rad = math.radians(abs(angle_deg))
        
        # ê¸°í•˜í•™ì  ê³„ì‚° (ì›ë³¸ ë¹„ìœ¨ ìœ ì§€ ê°€ì •)
        # sin/cos ê°’ì— ë”°ë¼ ìœ íš¨ ì˜ì—­ì˜ ë„ˆë¹„/ë†’ì´ ê³„ì‚°
        sin_a = math.sin(angle_rad)
        cos_a = math.cos(angle_rad)
        
        # íšŒì „ í›„ ì¤‘ì‹¬ ê¸°ì¤€ ìœ íš¨ ë°•ìŠ¤ í¬ê¸° ì¶”ì • (ê°„ì†Œí™”ëœ ë¡œì§)
        # ì‹¤ì œë¡œëŠ” ì›ë³¸ h0, w0ë¥¼ ì•Œì•„ì•¼ ì •í™•í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” íšŒì „ëœ ì´ë¯¸ì§€ ë‚´ì—ì„œ
        # ê²€ì€ìƒ‰ì´ ì•„ë‹Œ ì˜ì—­ì„ ì°¾ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ (ë” ë²”ìš©ì )
        
        # 1. Grayscale & Threshold to find content
        if len(img_rotated.shape) == 3:
            gray = cv2.cvtColor(img_rotated, cv2.COLOR_BGR2GRAY)
        else:
            gray = img_rotated
            
        # íšŒì „ ì‹œ ë¹ˆ ê³µê°„ì€ ë³´í†µ 0(ê²€ì€ìƒ‰) ë˜ëŠ” ë³´ê°„ëœ ê°’
        # ì•ˆì „í•˜ê²Œ 0ì´ ì•„ë‹Œ í”½ì…€ì˜ Bounding Boxë¥¼ êµ¬í•¨ (í•˜ì§€ë§Œ ì´ê±´ ë§ˆë¦„ëª¨ì„)
        # ë§ˆë¦„ëª¨ ì•ˆì˜ ì§ì‚¬ê°í˜•ì„ êµ¬í•´ì•¼ í•¨.
        
        # ê°„ë‹¨í•˜ê³  ê°•ë ¥í•œ ë°©ë²•: ì¤‘ì‹¬ì—ì„œ ì¡°ê¸ˆì”© ë°–ìœ¼ë¡œ ë‚˜ê°€ë©° ê²€ì€ìƒ‰ì„ ë§Œë‚  ë•Œê¹Œì§€ í™•ì¥
        cy, cx = h // 2, w // 2
        
        # Xì¶• íƒìƒ‰
        valid_w = 0
        for x in range(cx, w):
            if gray[cy, x] == 0: break
            valid_w += 1
        
        # Yì¶• íƒìƒ‰
        valid_h = 0
        for y in range(cy, h):
            if gray[y, cx] == 0: break
            valid_h += 1
            
        # ì•ˆì „ ë§ˆì§„ (90%)
        crop_w = int(valid_w * 2 * 0.9)
        crop_h = int(valid_h * 2 * 0.9)
        
        # Crop
        x1 = cx - crop_w // 2
        y1 = cy - crop_h // 2
        
        # ë²”ìœ„ ì²´í¬
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x1 + crop_w), min(h, y1 + crop_h)
        
        return img_rotated[y1:y2, x1:x2]

    # --- [B] Analysis Engines ---
    @staticmethod
    def analyze_thin_film(img_gray):
        """
        ë°•ë§‰ ë¶„ì„ (íšŒì „ -> ìœ íš¨ í¬ë¡­ -> í”„ë¡œíŒŒì¼ë§)
        """
        h_orig, w_orig = img_gray.shape
        log = []
        
        # 1. Angle Detection (Low Res for Speed)
        scale = min(1.0, 512 / max(h_orig, w_orig))
        small = cv2.resize(img_gray, None, fx=scale, fy=scale)
        best_angle = 0
        max_var = -1
        
        # ê°ë„ ì •ë°€ íƒìƒ‰
        for ang in range(-90, 91, 2):
            # íšŒì „ ì‹œ bicubic ì‚¬ìš© (íƒìƒ‰ìš©)
            rot = rotate(small, ang, reshape=False, order=1)
            prof = np.mean(rot, axis=1)
            var = np.var(np.abs(np.gradient(prof)))
            if var > max_var:
                max_var = var
                best_angle = ang
        
        log.append(f"Detected Angle: {best_angle}Â°")
        
        # 2. High-Quality Rotation (Lanczos4)
        # LanczosëŠ” Sinc í•¨ìˆ˜ ê¸°ë°˜ì´ë¼ Edge ë³´ì¡´ë ¥ì´ ê°€ì¥ ì¢‹ìŒ
        img_rot = rotate(img_gray, best_angle, reshape=True, order=4, mode='constant', cval=0)
        
        # 3. [V14] Valid Area Crop (Remove Black Borders)
        img_crop = ScienceProcessorV14.crop_valid_rotated_region(img_rot, best_angle)
        h_c, w_c = img_crop.shape
        log.append(f"Valid Region Cropped: {w_c}x{h_c}")
        
        # 4. Profile & Interface
        # ì´ì œ ë§ˆë¦„ëª¨ê°€ ì•„ë‹Œ ì§ì‚¬ê°í˜• ë°ì´í„°ì´ë¯€ë¡œ ìˆ˜ì§ í‰ê· ì´ ì •í™•í•¨
        img_blur = gaussian_filter(img_crop, sigma=3)
        profile = np.mean(img_blur, axis=1)
        gradient = np.abs(np.gradient(profile))
        
        interfaces, _ = find_peaks(gradient, height=np.max(gradient)*0.25, distance=30)
        
        # 5. Visualization (Overlay on the Cropped Image)
        overlay = cv2.cvtColor(img_crop, cv2.COLOR_GRAY2BGR)
        for y_pos in interfaces:
            cv2.line(overlay, (0, y_pos), (w_c, y_pos), (0, 0, 255), 2)
            
        # Thickness Calculation
        thicknesses = []
        if len(interfaces) >= 2:
            thicknesses = np.diff(interfaces).tolist()
            
        stats = {
            "type": "Thin Film",
            "angle": best_angle,
            "layers": len(interfaces),
            "thickness_px": thicknesses,
            "avg_thickness": float(np.mean(thicknesses)) if thicknesses else 0
        }
        
        # Encode cropped image for display
        return overlay, stats, log

    @staticmethod
    def detect_footer_boundary(img_array):
        # (ê¸°ì¡´ê³¼ ë™ì¼)
        try:
            h, w = img_array.shape[:2]
            if h < 100 or w < 100: return None
            search_h = int(h * 0.25)
            roi = img_array[h-search_h:, :]
            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if len(roi.shape)==3 else roi
            sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            row_sums = np.sum(np.uint8(np.absolute(sobel_y)), axis=1)
            if np.max(row_sums) < (w * 30): return None
            split_idx = np.argmax(row_sums)
            if split_idx > search_h * 0.98: return None
            return (h - search_h) + split_idx
        except: return None

    @staticmethod
    def process_image(img_bytes, equipment, mode, goal):
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_raw = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_raw is None: return None, {}
        
        process_log = []
        
        # 1. Smart Crop (Footer Removal)
        body_img = img_raw
        footer_img = None
        split_y = ScienceProcessorV14.detect_footer_boundary(img_raw)
        
        if split_y:
            body_img = img_raw[:split_y, :]
            footer_img = img_raw[split_y:, :]
            process_log.append("Smart Crop: Footer removed")
        
        # Encoding Helpers
        def encode_img(img):
            _, buf = cv2.imencode('.jpg', img)
            return base64.b64encode(buf).decode('utf-8')

        b64_raw = encode_img(body_img)
        b64_footer = encode_img(footer_img) if footer_img is not None else None

        if mode == "None":
            return {"raw_b64": b64_raw, "proc_b64": b64_raw, "footer_b64": b64_footer, "stats": {"info": "Raw"}, "log": process_log}

        # 2. Analysis Branch
        gray = cv2.cvtColor(body_img, cv2.COLOR_BGR2GRAY)
        kwd = (equipment + " " + goal).lower()
        
        processed_overlay = body_img.copy()
        stats = {}
        
        # [V14] Thin Film Check
        is_film = any(x in kwd for x in ["film", "layer", "thick", "ë°•ë§‰", "ë‘ê»˜", "ê³„ë©´"])
        
        if is_film:
            # V14 Engine Call (Returns Cropped & Rotated Image)
            processed_overlay, f_stats, f_log = ScienceProcessorV14.analyze_thin_film(gray)
            stats.update(f_stats)
            process_log.extend(f_log)
            # Thin Film ëª¨ë“œì—ì„œëŠ” ì›ë³¸(Raw) ëŒ€ì‹  ì²˜ë¦¬ëœ(Rotated) ì´ë¯¸ì§€ë¥¼ ë©”ì¸ìœ¼ë¡œ ë³´ì—¬ì£¼ëŠ”ê²Œ ë‚˜ìŒ
            # í•˜ì§€ë§Œ ë¹„êµë¥¼ ìœ„í•´ RawëŠ” ê·¸ëŒ€ë¡œ ë‘ 
        else:
            # Particle / Atom Check
            is_bright = np.mean(gray) > 127
            gray_proc = cv2.bitwise_not(gray) if is_bright else gray
            gray_blur = cv2.GaussianBlur(gray_proc, (5, 5), 0)
            
            detect_atoms = False
            detect_particles = False
            
            if mode == "AI-Adaptive":
                if any(x in kwd for x in ["atom", "ì›ì"]): detect_atoms = True
                if any(x in kwd for x in ["particle", "ì…ì"]): detect_particles = True
            elif mode == "Auto":
                if equipment in ["STEM", "TEM"]: detect_atoms = True
                if equipment in ["SEM", "Optical"]: detect_particles = True

            if detect_atoms:
                blobs = blob_log(gray_blur, min_sigma=3, max_sigma=15, threshold=0.1)
                for y, x, r in blobs: cv2.circle(processed_overlay, (int(x), int(y)), int(r*1.414), (0, 0, 255), 2)
                stats["count"] = len(blobs)
                process_log.append(f"Atoms: {len(blobs)}")
            elif detect_particles:
                _, th = cv2.threshold(gray_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                cnts, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(processed_overlay, cnts, -1, (0, 255, 0), 2)
                stats["count"] = len(cnts)
                process_log.append(f"Particles: {len(cnts)}")

        b64_proc = encode_img(processed_overlay)
        
        return {
            "raw_b64": b64_raw,
            "proc_b64": b64_proc,
            "footer_b64": b64_footer,
            "stats": stats,
            "log": process_log
        }

    # --- Spectrum & Helper ---
    @staticmethod
    def gaussian(x, amp, cen, wid): return amp * np.exp(-(x-cen)**2 / (2*wid**2))

    @staticmethod
    def fit_peaks(x, y, peaks):
        fits = []
        for p in peaks:
            try:
                p0 = [y[p], x[p], 1.0]
                win = 20
                s, e = max(0, p-win), min(len(x), p+win)
                if len(x[s:e]) > 3:
                    popt, _ = curve_fit(ScienceProcessorV14.gaussian, x[s:e], y[s:e], p0=p0, maxfev=1000)
                    fits.append({"amp": popt[0], "center": popt[1], "sigma": popt[2]})
            except: pass
        return fits

    @staticmethod
    def simple_baseline(y):
        w = max(5, len(y)//10)
        s = pd.Series(y).rolling(window=w, center=True).min().bfill().ffill().values
        if len(s) > 51: s = savgol_filter(s, 51, 3)
        return s

    @staticmethod
    def process_spectrum(x, y, mode, goal):
        log = []
        y_raw = y.copy()
        if mode == "None":
            peaks, _ = find_peaks(y, height=np.max(y)*0.05)
            return {"x": x, "y_raw": y, "y_proc": y, "y_base": np.zeros_like(y), "peaks": [{"x": float(x[p]), "y": float(y[p])} for p in peaks], "log": ["Raw"], "fits": []}
        
        win = 15
        do_fit = False
        if mode == "AI-Adaptive":
            if "noise" in goal.lower(): win = 31
            if "fit" in goal.lower(): do_fit = True
        
        base = ScienceProcessorV14.simple_baseline(y)
        y_proc = np.maximum(y - base, 0)
        if len(y_proc) > win: y_proc = savgol_filter(y_proc, win, 3)
        
        peaks, _ = find_peaks(y_proc, height=np.max(y_proc)*0.05, distance=10)
        fits = ScienceProcessorV14.fit_peaks(x, y_proc, peaks) if do_fit else []
        
        return {"x": x, "y_raw": y_raw, "y_proc": y_proc, "y_base": base, "peaks": [{"x": float(x[p]), "y": float(y_proc[p])} for p in peaks], "log": log, "fits": fits}

def detect_excel_blocks(df):
    blocks = []; mask = ~df.isnull().to_numpy()
    if df.empty: return blocks
    labeled, n = label(mask, structure=[[0,1,0],[1,1,1],[0,1,0]])
    for sl in find_objects(labeled):
        b = df.iloc[sl]
        if b.shape[0]>=3 and b.shape[1]>=2: blocks.append(b.reset_index(drop=True))
    return blocks

async def analyze_vision_ollama(image_bytes: bytes, prompt: str) -> str:
    try:
        b64 = base64.b64encode(image_bytes).decode('utf-8')
        res = await asyncio.to_thread(ollama_client.chat, model=VISION_MODEL, messages=[{'role':'user','content':prompt,'images':[b64]}])
        c = res['message']['content']
        if "<script" in c: return "Blocked"
        return c
    except Exception as e: return str(e)

# --- App ---
app = FastAPI(title="Analyst V14")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

class TranslateReq(BaseModel): text: str

@app.post("/api/translate")
async def translate_text(req: TranslateReq):
    try:
        res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'Translate to English.'}, {'role':'user','content':req.text}])
        return {"translated": res['message']['content']}
    except Exception as e: return {"translated": str(e)}

@app.post("/api/analyze")
async def analyze_orchestrator(files: List[UploadFile] = File(...), file_configs: str = Form(...)):
    configs = json.loads(file_configs)
    print(f"ğŸš€ V14 Start. Files: {len(files)}")
    
    tasks = []
    final_results = []
    file_map = {f.filename: await f.read() for f in files}
    
    for filename, config in configs.items():
        if filename not in file_map: continue
        content = file_map[filename]
        eq, goal, mode = config.get("equipment", "General"), config.get("goal", ""), config.get("mode", "Auto")
        fname_lower = filename.lower()
        
        # [A] Document
        if eq == "Document" or fname_lower.endswith(('.pdf', '.ppt', '.pptx')):
            async def proc_doc(c, n, e):
                try:
                    if n.lower().endswith('.pdf'):
                        images = convert_from_bytes(c, dpi=150, fmt='jpeg')[:10]
                        full_txt = ""; pages = []
                        for idx, img in enumerate(images):
                            buf = io.BytesIO(); img.save(buf, format="JPEG")
                            b64 = base64.b64encode(buf.getvalue()).decode()
                            desc = await analyze_vision_ollama(buf.getvalue(), "í•œê¸€ ìš”ì•½.")
                            full_txt += f"\nPage {idx+1}: {desc}"
                            pages.append({"page_num": idx+1, "image_b64": b64, "desc": desc})
                        return {"type": "pdf", "filename": n, "equipment": "Lit", "raw_context": full_txt, "pages": pages}
                    elif n.lower().endswith(('.ppt', '.pptx')):
                        prs = Presentation(io.BytesIO(c))
                        slides = []; full_txt = ""
                        for i, slide in enumerate(prs.slides):
                            txt = ""; imgs = []
                            for s in slide.shapes:
                                if hasattr(s, "text"): txt += s.text + "\n"
                                if s.shape_type == MSO_SHAPE_TYPE.PICTURE:
                                    try:
                                        ib64 = base64.b64encode(s.image.blob).decode('utf-8')
                                        desc = await analyze_vision_ollama(s.image.blob, "í•œê¸€ ì„¤ëª….")
                                        imgs.append({"b64": ib64, "desc": desc})
                                    except: pass
                            full_txt += f"Slide {i+1}: {txt}\n"
                            slides.append({"slide_num": i+1, "text": txt, "images": imgs})
                        return {"type": "ppt", "filename": n, "equipment": "Lit", "raw_context": full_txt, "slides": slides}
                except Exception as e: return {"type": "error", "filename": n, "msg": str(e)}
            tasks.append(proc_doc(content, filename, eq))
            continue

        # [B] Data (Spectrum)
        if fname_lower.endswith(('.xlsx', '.xls', '.csv', '.txt')):
            async def proc_spec(c, n, e, g, m):
                try:
                    if n.endswith(('.csv', '.txt')):
                        try: df = pd.read_csv(io.BytesIO(c))
                        except: df = pd.read_csv(io.BytesIO(c), delimiter='\t')
                        blocks = [df]; sheet_name="CSV"
                    else:
                        xls = pd.ExcelFile(io.BytesIO(c))
                        df = pd.read_excel(xls, sheet_name=xls.sheet_names[0], header=None)
                        blocks = detect_excel_blocks(df); sheet_name=xls.sheet_names[0]

                    res_list = []
                    for i, block in enumerate(blocks):
                        try:
                            num_block = block.apply(pd.to_numeric, errors='coerce').dropna(how='all').dropna(how='all', axis=1)
                            if not num_block.empty and num_block.shape[0] > 5:
                                x = num_block.iloc[:, 0].fillna(0).values; y = num_block.iloc[:, 1].fillna(0).values
                                res = ScienceProcessorV14.process_spectrum(x, y, mode, g)
                                step = max(1, len(x)//100)
                                chart = [{"x": float(res["x"][k]), "y_proc": float(res["y_proc"][k]), "y_raw": float(res["y_raw"][k]), "y_base": float(res["y_base"][k])} for k in range(0, len(x), step)]
                                res_list.append({
                                    "type": "spectrum", "filename": f"{n} ({sheet_name}-{i+1})", "equipment": e,
                                    "raw_context": f"Peaks: {len(res['peaks'])}", "chart_data": chart, "log": res["log"], "fits": res["fits"]
                                })
                        except: pass
                    return res_list[0] if len(res_list)==1 else res_list
                except Exception as ex: return [{"type": "error", "filename": n, "msg": str(ex)}]
            pass # (ìŠ¤í™íŠ¸ëŸ¼ ë¡œì§ì€ gather ì²˜ë¦¬ë¥¼ ìœ„í•´ ë˜í•‘ í•„ìš” - V13ê³¼ ë™ì¼)

        # [C] Data (Image)
        elif fname_lower.endswith(('.png', '.jpg', '.jpeg', '.tif', '.bmp')):
            async def proc_img(c, n, e, g, m):
                try:
                    vis_res = ScienceProcessorV14.process_image(c, e, m, g)
                    if not vis_res: return {"type": "error", "filename": n, "msg": "Fail"}
                    meta = ""
                    if vis_res.get("footer_b64"):
                        fb = base64.b64decode(vis_res["footer_b64"])
                        meta = await analyze_vision_ollama(fb, "Read scale/HV.")
                    body = base64.b64decode(vis_res["proc_b64"])
                    desc = await analyze_vision_ollama(body, f"í•œê¸€ ë¶„ì„. {e}. ëª©í‘œ:{g}. í†µê³„:{vis_res.get('stats',{})}")
                    return {
                        "type": "image", "filename": n, "equipment": e, "summary": desc,
                        "raw_context": f"Img {e}: {desc}\nMeta: {meta}",
                        "raw_b64": vis_res["raw_b64"], "proc_b64": vis_res["proc_b64"], "footer_b64": vis_res.get("footer_b64"),
                        "stats": vis_res.get("stats",{}), "log": vis_res.get("log", [])
                    }
                except Exception as ex: return {"type": "error", "filename": n, "msg": str(ex)}
            tasks.append(proc_img(content, filename, eq, goal, mode))

    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for r in results:
            if isinstance(r, list): final_results.extend(r)
            elif isinstance(r, dict): final_results.append(r)

    data_ctx, lit_ctx = "", ""
    for r in final_results:
        if r.get("type") != "error":
            raw = r.get("raw_context") or ""
            blk = f"\n=== File: {r['filename']} ===\n{raw[:3000]}\n"
            if r.get("equipment") in ["Literature","Lit"]: lit_ctx += blk
            else: data_ctx += blk
    
    final_report = "Fail"
    if data_ctx or lit_ctx:
        try:
            res = await asyncio.to_thread(ollama_client.chat, model=TEXT_MODEL, messages=[{'role':'system','content':'ìˆ˜ì„ ì—°êµ¬ì›. í•œê¸€. í‘œ í™œìš©.'}, {'role':'user','content':f"Data:\n{data_ctx}\n\nLit:\n{lit_ctx}"}])
            final_report = res['message']['content']
        except Exception as e: final_report = str(e)

    return {"results": final_results, "final_report": final_report}

@app.get("/", response_class=HTMLResponse)
async def serve_index():
    if os.path.exists("index.html"): return FileResponse("index.html")
    return "<h1>Upload index.html</h1>"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)



ë¸Œì´14
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>AI Research Center V14.1</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/vue@3/dist/vue.global.js"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        body { font-family: 'Inter', sans-serif; }
        .prose table { border-collapse: collapse; width: 100%; margin: 1em 0; }
        .prose th, .prose td { border: 1px solid #cbd5e1; padding: 8px; font-size: 0.9rem; }
        .prose th { background-color: #f1f5f9; }
        .loader { border: 3px solid #f3f3f3; border-top: 3px solid #0ea5e9; border-radius: 50%; width: 20px; height: 20px; animation: spin 1s linear infinite; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
</head>
<body class="bg-slate-100 text-slate-800">
    <div id="app" class="min-h-screen p-6">
        <header class="max-w-7xl mx-auto mb-6 flex items-center gap-3">
            <div class="bg-indigo-600 p-2 rounded-lg shadow"><i data-lucide="microscope" class="w-6 h-6 text-white"></i></div>
            <div><h1 class="text-2xl font-bold">AI Research Center V14.1</h1><p class="text-xs text-slate-500">Lossless Projection â€¢ Smart UX</p></div>
        </header>

        <main class="max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6">
            
            <!-- Staging Area -->
            <div class="lg:col-span-4 space-y-4">
                <div class="bg-white p-5 rounded-xl shadow-sm border border-slate-200">
                    <h2 class="font-bold mb-3 flex items-center gap-2"><i data-lucide="files" class="w-4 h-4"></i> Data Staging</h2>
                    <div class="border-2 border-dashed border-slate-300 rounded-lg p-6 text-center hover:bg-indigo-50 cursor-pointer" @click="$refs.f.click()">
                        <input type="file" ref="f" multiple class="hidden" @change="addFiles">
                        <p class="text-sm font-semibold text-slate-600">Add Files</p>
                    </div>
                    <div v-if="stagedFiles.length" class="mt-4 space-y-3 max-h-[60vh] overflow-y-auto pr-1">
                        <div v-for="(item, i) in stagedFiles" :key="i" class="p-3 bg-slate-50 border rounded-lg text-sm">
                            <div class="flex justify-between items-center mb-2">
                                <span class="font-bold truncate w-2/3" :title="item.file.name">{{ item.file.name }}</span>
                                <button @click="removeFile(i)" class="text-red-400 hover:text-red-600"><i data-lucide="trash-2" class="w-4 h-4"></i></button>
                            </div>
                            <div class="grid grid-cols-1 gap-2">
                                <select v-model="item.equipment" class="w-full p-1.5 border rounded text-xs bg-white font-semibold text-indigo-700">
                                    <optgroup label="Literature">
                                        <option value="Document">Document (PDF/PPT)</option>
                                    </optgroup>
                                    <optgroup label="Spectroscopy">
                                        <option value="XRD">XRD</option>
                                        <option value="EDS">EDS / EDX</option>
                                        <option value="EELS">EELS</option>
                                        <option value="Raman">Raman</option>
                                        <option value="FT-IR">FT-IR</option>
                                        <option value="PL">PL</option>
                                    </optgroup>
                                    <optgroup label="Microscopy">
                                        <option value="SEM">SEM</option>
                                        <option value="TEM">TEM (Thin Film)</option>
                                        <option value="STEM">STEM (Thin Film)</option>
                                        <option value="AFM">AFM</option>
                                        <option value="Optical BF">Optical (BF)</option>
                                    </optgroup>
                                </select>
                                <select v-if="item.equipment !== 'Document'" v-model="item.mode" class="w-full p-1.5 border rounded text-xs bg-white text-indigo-700">
                                    <option value="Auto">âœ¨ Auto Process</option>
                                    <option value="None">ğŸš« None (Raw)</option>
                                    <option value="AI-Adaptive">ğŸ§  AI-Adaptive</option>
                                </select>
                                <input v-if="item.equipment !== 'Document'" v-model="item.goal" type="text" placeholder="Goal (e.g. Measure thickness)" class="w-full p-1.5 border rounded text-xs">
                            </div>
                        </div>
                    </div>
                    <button @click="analyze" :disabled="isAnalyzing || stagedFiles.length===0" class="w-full mt-4 py-3 bg-indigo-600 text-white rounded-lg font-bold flex justify-center gap-2 shadow hover:bg-indigo-700 disabled:opacity-50">
                        <div v-if="isAnalyzing" class="loader"></div>
                        <span>Generate Synthesis Report</span>
                    </button>
                </div>
            </div>

            <!-- Report Area -->
            <div class="lg:col-span-8">
                <div v-if="result" class="space-y-6 animate-fade-in">
                    
                    <!-- Tools -->
                    <div class="flex justify-between items-center bg-white p-2 rounded-xl shadow-sm border border-slate-200">
                        <div class="flex gap-2">
                            <button @click="setLang('ko')" :class="lang==='ko'?'bg-indigo-100 text-indigo-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">ğŸ‡°ğŸ‡· í•œê¸€</button>
                            <button @click="setLang('en')" :class="lang==='en'?'bg-blue-100 text-blue-700 font-bold':'text-slate-500 hover:bg-slate-50'" class="px-4 py-2 rounded-lg text-sm transition-all flex items-center gap-2">
                                <div v-if="isTranslating" class="w-3 h-3 border-2 border-blue-600 border-t-transparent rounded-full animate-spin"></div>
                                <span v-else>ğŸ‡ºğŸ‡¸</span> English
                            </button>
                        </div>
                        <button @click="dlPDF" class="px-3 py-1.5 bg-slate-800 text-white text-xs rounded">PDF Export</button>
                    </div>

                    <div id="report-view" class="bg-white p-8 rounded-xl shadow-sm border border-slate-200">
                        
                        <!-- Synthesis -->
                        <section class="mb-10">
                            <h2 class="text-lg font-bold text-indigo-700 mb-3 border-b pb-1">1. Synthesis</h2>
                            <div class="prose prose-sm text-slate-700 max-w-none" v-html="md(displayReport)"></div>
                        </section>

                        <!-- Details -->
                        <section>
                            <h2 class="text-lg font-bold text-slate-800 mb-5 border-b pb-1">2. Data Evidence</h2>
                            
                            <div v-for="(item, idx) in result.results" :key="idx" class="mb-8 p-4 bg-slate-50 rounded-lg border break-inside-avoid">
                                <div class="flex items-center justify-between mb-3">
                                    <div class="flex items-center gap-2">
                                        <span class="px-2 py-0.5 bg-white border rounded text-[10px] font-bold uppercase text-slate-500">{{ item.equipment }}</span>
                                        <h3 class="font-bold text-sm">{{ item.filename }}</h3>
                                    </div>
                                    <!-- Toggle Button -->
                                    <button @click="item.showDocs = !item.showDocs" class="text-xs text-indigo-600 font-bold hover:underline flex items-center gap-1">
                                        <i :data-lucide="item.showDocs ? 'eye-off' : 'eye'" class="w-3 h-3"></i>
                                        {{ item.showDocs ? 'Hide Text' : 'Show Text' }}
                                    </button>
                                </div>

                                <!-- Spectrum Chart -->
                                <div v-if="item.chart_data" class="bg-white p-2 rounded border mb-3">
                                    <div :id="'chart-'+idx" class="w-full h-60"></div>
                                </div>

                                <!-- Image Viewer -->
                                <div v-if="item.raw_b64" class="bg-white p-2 rounded border mb-3">
                                    <div class="flex gap-2 mb-2 text-xs justify-center">
                                        <button @click="item.view='proc'" :class="item.view!=='raw'?'font-bold text-indigo-600':''">Processed</button>
                                        <span class="text-slate-300">|</span>
                                        <button @click="item.view='raw'" :class="item.view==='raw'?'font-bold text-indigo-600':''">Original</button>
                                        <span class="text-slate-300" v-if="item.footer_b64">|</span>
                                        <button v-if="item.footer_b64" @click="item.view='footer'" :class="item.view==='footer'?'font-bold text-indigo-600':''">Info Bar</button>
                                    </div>
                                    <img v-if="item.view!=='footer'" :src="'data:image/jpeg;base64,' + (item.view==='raw' ? item.raw_b64 : item.proc_b64)" class="max-h-80 mx-auto object-contain bg-black">
                                    <img v-if="item.view==='footer'" :src="'data:image/jpeg;base64,' + item.footer_b64" class="max-h-24 mx-auto object-contain border mt-2">
                                </div>

                                <!-- [Fix] PDF Pages -->
                                <div v-if="item.pages" class="space-y-4">
                                    <div v-for="p in item.pages" :key="p.page_num" class="flex gap-4 bg-white p-3 rounded border">
                                        <!-- Image always visible -->
                                        <div :class="item.showDocs ? 'w-1/3' : 'w-full text-center'">
                                            <img :src="'data:image/jpeg;base64,'+p.image_b64" class="max-h-60 object-contain border shadow-sm mx-auto">
                                            <p class="text-center text-[10px] text-slate-400 mt-1">Page {{p.page_num}}</p>
                                        </div>
                                        <!-- Text toggled -->
                                        <div v-if="item.showDocs" class="w-2/3 text-xs prose" v-html="md(lang === 'en' ? (p.desc_en || p.desc) : p.desc)"></div>
                                    </div>
                                </div>

                                <!-- [Fix] PPT Slides -->
                                <div v-if="item.slides" class="space-y-4">
                                    <div v-for="s in item.slides" :key="s.slide_num" class="bg-white p-3 rounded border">
                                        <div class="flex justify-between mb-2">
                                            <div class="text-xs font-bold text-indigo-600">Slide {{s.slide_num}}</div>
                                        </div>
                                        
                                        <!-- Extracted Images (Always Visible) -->
                                        <div v-if="s.images && s.images.length" class="grid grid-cols-2 gap-2 mb-2">
                                            <div v-for="(img, imx) in s.images" :key="imx" class="bg-slate-50 p-2 text-center">
                                                <img :src="'data:image/jpeg;base64,'+img.b64" class="max-h-40 mx-auto object-contain bg-white border">
                                                <!-- Image Description Toggle -->
                                                <p v-if="item.showDocs" class="text-[10px] text-slate-500 mt-1 bg-white p-1 rounded">{{ img.desc }}</p>
                                            </div>
                                        </div>

                                        <!-- Slide Text (Toggled) -->
                                        <div v-if="item.showDocs" class="text-xs prose border-t pt-2 mt-2 whitespace-pre-wrap max-h-32 overflow-y-auto bg-slate-50 p-2 rounded">
                                            {{ s.text }}
                                        </div>
                                    </div>
                                </div>

                                <!-- Summary Text (Toggled) -->
                                <div v-if="item.showDocs" class="text-xs text-slate-600 mt-2 prose bg-slate-50 p-3 rounded" v-html="md(lang === 'en' ? (item.summary_en || item.summary) : item.summary)"></div>
                                
                                <!-- Log (Toggled) -->
                                <div v-if="item.log && item.log.length > 0 && item.showDocs" class="mt-2 p-2 bg-gray-100 rounded border text-[10px] font-mono text-gray-600">
                                    <strong>âš™ï¸ Log:</strong> {{ item.log.join(' â†’ ') }}
                                </div>

                            </div>
                        </section>
                    </div>
                </div>
            </div>
        </main>
    </div>
    <script>
        const { createApp, ref, computed, nextTick } = Vue;
        createApp({
            setup() {
                const stagedFiles = ref([]);
                const isAnalyzing = ref(false);
                const isTranslating = ref(false);
                const result = ref(null);
                const lang = ref('ko'); 
                const translatedReport = ref('');
                const md = (t) => marked.parse(t||'');

                const displayReport = computed(() => lang.value === 'en' && translatedReport.value ? translatedReport.value : (result.value ? result.value.final_report : ''));

                const addFiles = (e) => {
                    Array.from(e.target.files).forEach(f => {
                        let eq = 'General';
                        if(f.name.match(/\.(pdf|ppt|pptx)$/i)) eq = 'Document';
                        stagedFiles.value.push({ file: f, equipment: eq, goal: '', mode: 'Auto', view: 'proc', showDocs: true });
                    });
                    e.target.value = ''; 
                };
                const removeFile = (i) => stagedFiles.value.splice(i, 1);

                const analyze = async () => {
                    isAnalyzing.value = true;
                    lang.value = 'ko'; 
                    translatedReport.value = '';
                    const fd = new FormData();
                    const configs = {};
                    stagedFiles.value.forEach(item => {
                        fd.append('files', item.file);
                        configs[item.file.name] = { equipment: item.equipment, goal: item.goal, mode: item.mode };
                    });
                    fd.append('file_configs', JSON.stringify(configs));

                    try {
                        const res = await fetch('/api/analyze', { method: 'POST', body: fd });
                        const data = await res.json();
                        // Initialize showDocs to true
                        if(data.results) data.results.forEach(r => r.showDocs = true);
                        result.value = data;
                        await nextTick();
                        
                        data.results.forEach((item, i) => {
                            if(item.chart_data) {
                                const raw = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_raw), mode:'lines', name:'Raw', line:{color:'#cbd5e1', width:1} };
                                const proc = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_proc), mode:'lines', name:'Proc', line:{color:'#4f46e5', width:2} };
                                const base = { x: item.chart_data.map(d=>d.x), y: item.chart_data.map(d=>d.y_base), mode:'lines', name:'Base', line:{color:'#f59e0b', width:1, dash:'dot'} };
                                Plotly.newPlot('chart-'+i, [raw, base, proc], {margin:{t:10,b:30,l:40,r:10}, showlegend:false}, {displayModeBar:false});
                            }
                        });
                        lucide.createIcons();
                    } catch(e) { alert(e); } 
                    finally { isAnalyzing.value = false; }
                };

                const setLang = async (target) => {
                    if (target === 'ko') { lang.value = 'ko'; return; }
                    if (target === 'en') {
                        if (translatedReport.value) { lang.value = 'en'; return; }
                        isTranslating.value = true;
                        try {
                            const res = await fetch('/api/translate', {
                                method: 'POST', headers: {'Content-Type': 'application/json'},
                                body: JSON.stringify({ text: result.value.final_report })
                            });
                            const data = await res.json();
                            translatedReport.value = data.translated;
                            lang.value = 'en';
                        } catch(e) { alert("Trans Error: " + e); }
                        finally { isTranslating.value = false; }
                    }
                };
                
                const dlPDF = () => html2pdf().set({ margin:10, filename:'V14_1_Report.pdf', image:{type:'jpeg',quality:0.98}, html2canvas:{scale:2}, jsPDF:{unit:'mm',format:'a4'} }).from(document.getElementById('report-view')).save();

                setTimeout(()=>lucide.createIcons(), 100);
                return { stagedFiles, isAnalyzing, isTranslating, result, lang, displayReport, addFiles, removeFile, analyze, md, dlPDF, setLang };
            }
        }).mount('#app');
    </script>
</body>
</html>


