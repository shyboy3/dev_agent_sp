import cv2
import numpy as np
import os
from tqdm import tqdm

def generate_valid_patches(base_dir):
    """
    VALID SET용 패치 생성: 증강 없이 원본 이미지와 라벨 1:1 매칭
    """
    H_VALID, W_VALID = 896, 1280
    PATCH_SIZE = 384
    STRIDE = 192 # 검증용이므로 조금 더 넓게 잡아도 됩니다 (속도 향상)
    
    save_dir = os.path.join(base_dir, "VALID_PATCHES")
    os.makedirs(save_dir, exist_ok=True)
    
    sem_files = sorted([f for f in os.listdir(base_dir) if f.lower().endswith('.jpg')])
    
    patch_idx = 0
    for s_file in sem_files:
        basename = os.path.splitext(s_file)[0]
        l_file = basename + ".png"
        
        # 이미지 로드 및 전처리 (CLAHE 적용 권장)
        sem_img = cv2.imread(os.path.join(base_dir, s_file), cv2.IMREAD_GRAYSCALE)[:H_VALID, :]
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        sem_norm = clahe.apply(sem_img) / 255.0
        
        label_bgr = cv2.imread(os.path.join(base_dir, l_file))[:H_VALID, :, :]
        _, grain_mask = process_expert_label(label_bgr) # 기존에 만든 함수 사용
        target_mask = (grain_mask > 0).astype(np.float32)
        
        # 패치 생성
        for y in range(0, H_VALID - PATCH_SIZE + 1, STRIDE):
            for x in range(0, W_VALID - PATCH_SIZE + 1, STRIDE):
                img_p = sem_norm[y:y+PATCH_SIZE, x:x+PATCH_SIZE]
                mask_p = target_mask[y:y+PATCH_SIZE, x:x+PATCH_SIZE]
                
                np.save(os.path.join(save_dir, f"val_{patch_idx:04d}_img.npy"), img_p.astype(np.float32))
                np.save(os.path.join(save_dir, f"val_{patch_idx:04d}_mask.npy"), mask_p.astype(np.float32))
                patch_idx += 1
    print(f"Validation patches created: {patch_idx}")

def process_expert_label(label_img):
    """
    흰 바탕(255,255,255)에 붉은 선(255,0,0)인 라벨 처리.
    OpenCV BGR 기준: (0:Blue, 1:Green, 2:Red)
    """
    # 붉은 선(Boundary) 추출: Red는 높고 나머지는 낮은 영역
    red_line = (label_img[:,:,2] > 200) & (label_img[:,:,1] < 100) & (label_img[:,:,0] < 100)
    boundary = red_line.astype(np.uint8) * 255
    
    # Grain Area: 선이 0, 내부가 255인 마스크
    grain_mask = cv2.bitwise_not(boundary)
    return boundary, grain_mask

def generate_augmented_dataset(base_dir):
    # 설정값
    H_VALID, W_VALID = 896, 1280
    PATCH_SIZE = 384
    STRIDE = 48
    
    # SEM(jpg) 파일 목록 추출 후 파일명(basename)으로 정렬
    sem_files = sorted([f for f in os.listdir(base_dir) if f.lower().endswith('.jpg')])
    
    flattened_list = []
    bg_pattern_list = []
    target_mask_list = []

    print(f"Step 1: Analyzing {len(sem_files)} base images from {base_dir}...")
    
    for s_file in sem_files:
        basename = os.path.splitext(s_file)[0]
        l_file = basename + ".png"  # 확장자만 png로 교체
        
        l_path = os.path.join(base_dir, l_file)
        if not os.path.exists(l_path):
            print(f"Warning: Label file {l_file} not found. Skipping...")
            continue
            
        # 이미지 로드 및 메타 영역 제거 (896x1280)
        sem = cv2.imread(os.path.join(base_dir, s_file), cv2.IMREAD_GRAYSCALE)[:H_VALID, :] / 255.0
        label_bgr = cv2.imread(l_path)[:H_VALID, :, :]
        
        # 라벨에서 Grain 추출
        _, grain_mask = process_expert_label(label_bgr)
        
        # 개별 Grain 분리 및 Intensity Flattening
        num_labels, labels = cv2.connectedComponents(grain_mask)
        flat_img = np.zeros_like(sem)
        
        for i in range(1, num_labels):
            m = labels == i
            if np.any(m):
                flat_img[m] = np.mean(sem[m])
        
        flattened_list.append(flat_img)
        bg_pattern_list.append(sem - flat_img)
        target_mask_list.append((labels > 0).astype(np.float32))

    print("Step 2: Generating 14x14 Synthesis and Patches...")
    # 증강 데이터가 저장될 하위 폴더 생성 (관리 용이성 위해 base_dir 내부에 생성)
    save_dir = os.path.join(base_dir, "AUGMENTED_PATCHES")
    os.makedirs(save_dir, exist_ok=True)
    
    patch_idx = 0
    # 14x14 조합 루프
    for i in tqdm(range(len(flattened_list)), desc="Synthesizing"):
        for j in range(len(bg_pattern_list)):
            synth_img = np.clip(flattened_list[i] + bg_pattern_list[j], 0, 1)
            target_mask = target_mask_list[i]
            
            # 패치 슬라이딩
            for y in range(0, H_VALID - PATCH_SIZE + 1, STRIDE):
                for x in range(0, W_VALID - PATCH_SIZE + 1, STRIDE):
                    img_p = synth_img[y:y+PATCH_SIZE, x:x+PATCH_SIZE]
                    mask_p = target_mask[y:y+PATCH_SIZE, x:x+PATCH_SIZE]
                    
                    # 90, 180, 270도 회전
                    for k in range(4):
                        aug_img = np.rot90(img_p, k)
                        aug_mask = np.rot90(mask_p, k)
                        
                        # .npy 파일로 저장
                        np.save(os.path.join(save_dir, f"patch_{patch_idx:06d}_img.npy"), aug_img.astype(np.float32))
                        np.save(os.path.join(save_dir, f"patch_{patch_idx:06d}_mask.npy"), aug_mask.astype(np.float32))
                        patch_idx += 1

    print(f"Success! {patch_idx} patches saved in {save_dir}")

# 실행: 경로만 넣어주면 됩니다.
# generate_augmented_dataset('TRAIN_SEM_IMAGE')
