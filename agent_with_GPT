# app_spectrum_agent_starter.py
# -----------------------------------------------------------------------------
# Text-only single host (Ollama) Spectrum Agent Starter â€” Preview, Multi-file,
# Denoise(Hampel/SG), Baseline(AsLS), Onset/Peaks, Manual/Agent, PDF, Chatbot
# -----------------------------------------------------------------------------

import os, io, re, json, base64, textwrap
from io import BytesIO
from typing import Optional, List, Tuple, Dict, Callable
import numpy as np
import pandas as pd
import requests

import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.font_manager import fontManager, findSystemFonts
from PIL import Image
from scipy.signal import find_peaks, savgol_filter
from scipy import sparse
from scipy.sparse.linalg import spsolve

from fastapi import FastAPI, UploadFile, File, Form, Header, HTTPException, Depends, Body
from fastapi.responses import HTMLResponse, JSONResponse

# ===================== Config (Text-only single host) =====================
OLLAMA_HOST = os.environ.get("OLLAMA_HOST_TEXT", "http://localhost:11434")
TEXT_MODEL  = os.environ.get("TEXT_MODEL", "gpt-oss")
AUTH_TOKEN  = os.environ.get("LOCAL_AGENT_TOKEN")
MAX_AGENT_ITERS = int(os.environ.get("MAX_AGENT_ITERS", "3"))

app = FastAPI(title="Spectrum Agent Starter (Text-only Single Host)")

# ===================== Auth =====================
def require_auth(x_auth_token: Optional[str] = Header(None)):
    if AUTH_TOKEN and x_auth_token != AUTH_TOKEN:
        raise HTTPException(status_code=401, detail="Unauthorized")
    return True

# ===================== Ollama helpers =====================
def list_model_names(base: str) -> List[str]:
    try:
        r = requests.get(f"{base}/api/tags", timeout=10)
        r.raise_for_status()
        models = r.json().get("models", [])
        out=[]
        for m in models:
            if isinstance(m, dict):
                name = m.get("name") or m.get("model") or m.get("tag") or m.get("id")
                if name: out.append(name)
        return out
    except Exception:
        return []

def ensure_model_installed(model: str, base: str) -> str:
    names = list_model_names(base)
    if model in names:
        return model
    want = model.split(":", 1)[0]
    for n in names:
        if n.split(":",1)[0] == want:
            return n
    raise HTTPException(status_code=400, detail=f"Model '{model}' not found at {base}. Found: {names}")

def ollama_generate_once(model: str, prompt: str, base: str, num_predict=512) -> str:
    req = {
        "model": model,
        "prompt": prompt,
        "stream": False,
        "options": {"temperature": 0.2, "top_p": 0.8, "num_predict": num_predict},
        "keep_alive": "20m",
    }
    r = requests.post(f"{base}/api/generate", json=req, timeout=120)
    r.raise_for_status()
    return r.json().get("response","").strip()

# ===================== Robust CSV/Excel parsing =====================
def smart_decode_csv(csv_bytes: bytes) -> str:
    if csv_bytes.startswith(b"\xff\xfe"): return csv_bytes.decode("utf-16le", errors="ignore")
    if csv_bytes.startswith(b"\xfe\xff"): return csv_bytes.decode("utf-16be", errors="ignore")
    if csv_bytes.startswith(b"\xef\xbb\xbf"): return csv_bytes.decode("utf-8-sig", errors="ignore")
    if b"\x00" in csv_bytes:
        for enc in ("utf-16le","utf-16be"):
            try: return csv_bytes.decode(enc, errors="ignore")
            except: pass
    try: return csv_bytes.decode("utf-8", errors="ignore")
    except: return csv_bytes.decode("latin-1", errors="ignore")

def parse_spectrum_csv(csv_bytes: bytes):
    """
    Robust CSV parser:
    - sep/decimal ìë™ ì¶”ì • â†’ íŒë‹¤ìŠ¤ ìš°ì„ 
    - ìˆ«ìì—´ ìë™ ì„ íƒ(ì²« ë‘ ê°œ)
    - ì‹¤íŒ¨ ì‹œ ë¼ì¸ íŒŒì„œ ë°±ì—…
    """
    text = smart_decode_csv(csv_bytes)
    import pandas as _pd
    import io as _io
    tried = []
    for sep in [None, ",", ";", "\t", r"\s+"]:
        for dec in [".", ","]:
            try:
                df = _pd.read_csv(_io.StringIO(text), sep=sep, engine="python", decimal=dec)
                if df.shape[1] >= 2:
                    num_df = df.apply(_pd.to_numeric, errors="coerce")
                    numeric_cols = [c for c in num_df.columns if num_df[c].notna().sum() >= 2]
                    if len(numeric_cols) >= 2:
                        c1, c2 = numeric_cols[:2]
                        x_series = num_df[c1].dropna()
                        y_series = num_df[c2].dropna()
                        idx = x_series.index.intersection(y_series.index)
                        if len(idx) >= 2:
                            x = x_series.loc[idx].astype(float).tolist()
                            y = y_series.loc[idx].astype(float).tolist()
                            xlabel = str(c1); ylabel = str(c2)
                            return x, y, xlabel, ylabel
                tried.append(f"sep={sep},dec={dec},cols={getattr(df,'shape',('NA','NA'))[1] if isinstance(getattr(df,'shape',None),tuple) else 'NA'}")
            except Exception as e:
                tried.append(f"sep={sep},dec={dec},err={type(e).__name__}")
                continue

    # ë°±ì—… ë¼ì¸ íŒŒì„œ
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    x_vals, y_vals = [], []
    xlabel = "X"; ylabel = "Y"

    def to_float(tok: str):
        t = tok.strip()
        t = re.sub(r"(?<=\d)[,\s](?=\d{3}(?:\D|$))", "", t)  # ì²œë‹¨ìœ„ ì œê±°
        if t.count(",") == 1 and t.count(".") == 0 and re.search(r",\d+$", t):
            t = t.replace(",", ".")
        return float(t)

    for ln in lines:
        low = ln.lower()
        if low.startswith("#") or low.startswith(("xlabel","ylabel","x_label","y_label","x:","y:")):
            continue
        for d in [",", ";", "\t", " "]:
            toks = [t for t in re.split(r"\s+" if d==" " else re.escape(d), ln) if t]
            nums = []
            for tok in toks:
                try: nums.append(to_float(tok))
                except: nums.append(None)
            nz = [v for v in nums if v is not None]
            if len(nz) >= 2:
                x_vals.append(nz[0]); y_vals.append(nz[1])
                break
        if len(x_vals) >= 10 and len(y_vals) >= 10:
            break

    if x_vals and y_vals and len(x_vals) == len(y_vals) and len(x_vals) >= 2:
        return x_vals, y_vals, xlabel, ylabel

    raise ValueError(f"No numeric X,Y pairs found in CSV. Tried combos: {', '.join(tried[:6])} ...")

def parse_excel(file_bytes: bytes):
    df = pd.read_excel(BytesIO(file_bytes), engine="openpyxl")
    if df.shape[1] < 2:
        raise ValueError("Excel íŒŒì¼ì—ì„œ ìµœì†Œ ë‘ ê°œì˜ ì—´(X,Y)ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    x_series = pd.to_numeric(df.iloc[:,0], errors="coerce").dropna()
    y_series = pd.to_numeric(df.iloc[:,1], errors="coerce").dropna()
    idx = x_series.index.intersection(y_series.index)
    x = x_series.loc[idx].astype(float).tolist()
    y = y_series.loc[idx].astype(float).tolist()
    xlabel = str(df.columns[0]); ylabel = str(df.columns[1])
    return x, y, xlabel, ylabel

# ===================== Operators & Detect =====================
OpFn = Callable[[List[float], List[float], Dict], Tuple[List[float], List[float], Dict]]
OP_REGISTRY: Dict[str, OpFn] = {}
def register(name: str):
    def deco(fn: OpFn):
        OP_REGISTRY[name] = fn; return fn
    return deco

@register("hampel")
def op_hampel(x, y, kw):
    window = int(float(kw.get("window", 7)))
    sigma  = float(kw.get("sigma", 3.0))
    arr = np.asarray(y, float)
    k = max(1, window//2)
    y_med = np.copy(arr)
    for i in range(len(arr)):
        s = max(0, i-k); e = min(len(arr), i+k+1)
        y_med[i] = np.median(arr[s:e])
    diff = np.abs(arr - y_med)
    med_abs_dev = np.median(diff) + 1e-12
    thr = sigma * 1.4826 * med_abs_dev
    out = np.where(diff > thr, y_med, arr)
    return x, out.tolist(), {"op":"hampel", "window":window, "sigma":sigma}

@register("sg")
def op_sg(x, y, kw):
    win = int(float(kw.get("window", 11)))
    poly= int(float(kw.get("poly", 3)))
    if win % 2 == 0: win += 1
    win = max(win, poly + 3 if (poly + 3) % 2 == 1 else poly + 4)
    win = min(win, len(y) - 1 - (len(y) % 2 == 0))
    arr = np.asarray(y, float)
    out = savgol_filter(arr, window_length=max(5, win), polyorder=max(2, poly))
    return x, out.tolist(), {"op":"sg", "window":win, "poly":poly}

def baseline_asls(y: np.ndarray, lam: float = 1e5, p: float = 0.01, niter: int = 10) -> np.ndarray:
    y = np.asarray(y, dtype=float)
    L = len(y)
    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(L, L-2))
    DTD = (lam * D @ D.T).tocsc()
    w = np.ones(L)
    for _ in range(niter):
        W = sparse.diags(w, 0, shape=(L, L))
        Z = W + DTD
        z = spsolve(Z, w * y)
        w = p * (y > z) + (1 - p) * (y < z)
    return z

@register("baseline")
def op_baseline(x, y, kw):
    lam  = float(kw.get("lam", 1e5))
    p    = float(kw.get("p", 0.01))
    nite = int(float(kw.get("iter", 10)))
    arr = np.asarray(y, float)
    base = baseline_asls(arr, lam=lam, p=p, niter=nite)
    return x, (arr - base).tolist(), {"op":"baseline", "lam":lam, "p":p, "iter":nite}

@register("normalize")
def op_normalize(x, y, kw):
    kind = str(kw.get("kind","minmax")).lower()
    arr = np.asarray(y, float)
    if kind == "z":
        m, s = float(np.mean(arr)), float(np.std(arr)+1e-12)
        out = (arr - m) / s
        return x, out.tolist(), {"op":"normalize","kind":"z","mean":m,"std":s}
    lo, hi = float(np.min(arr)), float(np.max(arr))
    out = (arr - lo) / (hi - lo + 1e-12)
    return x, out.tolist(), {"op":"normalize","kind":"minmax","min":lo,"max":hi}

@register("resample")
def op_resample(x, y, kw):
    n = int(float(kw.get("n", 1024)))
    xp = np.linspace(float(np.min(x)), float(np.max(x)), n)
    yp = np.interp(xp, np.asarray(x, float), np.asarray(y, float))
    return xp.tolist(), yp.tolist(), {"op":"resample", "n":n}

def detect_onset(x: List[float], y_corr: List[float], win: int = 11, poly: int = 2, z_thresh: float = 3.0) -> Optional[int]:
    x = np.asarray(x, dtype=float); y = np.asarray(y_corr, dtype=float)
    if len(y) < 7: return None
    if win % 2 == 0: win += 1
    win = max(win, poly + 3 if (poly + 3) % 2 == 1 else poly + 4)
    win = min(win, len(y) - 1 - (len(y) % 2 == 0))
    if win < 5: return None
    dy = savgol_filter(y, window_length=win, polyorder=poly, deriv=1)
    low_mask = y < np.quantile(y, 0.3)
    sigma = np.std(dy[low_mask]) if np.any(low_mask) else np.std(dy)
    if sigma <= 0: return None
    thr = z_thresh * sigma
    cand = np.where((dy > thr) & (y > 0))[0]
    return int(cand[0]) if cand.size else None

def detect_peaks_list(x: List[float], y: List[float], prominence_frac: float = 0.02, distance_pts: int = 5, width: Optional[float] = None) -> List[dict]:
    y_arr = np.asarray(y, dtype=float)
    y_min, y_max = float(np.nanmin(y_arr)), float(np.nanmax(y_arr))
    prom = max(prominence_frac * (y_max - y_min), 1e-12)
    kwargs = {"prominence": prom, "distance": max(distance_pts, 1)}
    if width is not None: kwargs["width"] = width
    idx, props = find_peaks(y_arr, **kwargs)
    peaks=[]
    for k,i in enumerate(idx):
        peaks.append({"i": int(i), "x": float(x[i]), "y": float(y[i]), "prom": float(props["prominences"][k])})
    peaks.sort(key=lambda d:d["x"])
    return peaks

# ===================== Pipeline / Planner / Evaluator =====================
ALIASES = {
    "ìŠ¤ë¬´ë”©":"sg","savitzky":"sg","savitzky-golay":"sg","sgfilter":"sg",
    "í•´ë°€":"hampel","hampel-filter":"hampel",
    "ë² ì´ìŠ¤ë¼ì¸":"baseline","bg":"baseline","asls":"baseline",
    "ì •ê·œí™”":"normalize","zscore":"normalize","minmax":"normalize",
    "ë¦¬ìƒ˜í”Œ":"resample","resampling":"resample",
    "í”¼í¬":"peaks","peak":"peaks",
    "ì˜¨ì…‹":"onset","threshold-onset":"onset",
}
def normalize_op_name(op:str) -> str:
    o = (op or "").strip().lower()
    return ALIASES.get(o, o)

def validate_and_normalize_steps(steps: List[dict]):
    warns=[]; norm=[]
    for i,s in enumerate(steps or []):
        if not isinstance(s, dict): warns.append(f"[step {i+1}] invalid"); continue
        op_raw = s.get("op","")
        op = normalize_op_name(op_raw)
        s = {**s, "op": op}
        if op not in OP_REGISTRY and not op.startswith("custom:"):
            warns.append(f"[step {i+1}] unknown op '{op_raw}'")
            s["__unknown__"]=True
        norm.append(s)
    return norm, warns

def execute_steps(x: List[float], y: List[float], steps: List[dict]):
    metas=[]
    for s in steps or []:
        if s.get("__unknown__"): continue
        op = s["op"]; kw = {k:v for k,v in s.items() if k!="op"}
        fn = OP_REGISTRY[op]
        x, y, meta = fn(x, y, kw)
        metas.append({"op":op, **(meta or {})})
    return x, y, metas

PLAN_SYS_PROMPT = """ë‹¹ì‹ ì€ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì…ë‹ˆë‹¤.
ë‹¤ìŒ DSL YAMLë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…/ì½”ë“œë¸”ë¡ ê¸ˆì§€.
pipeline:
  - op: hampel|sg|normalize|resample|baseline|peaks|onset
"""

def plan_from_goal(goal: str, model: str, host: str):
    yml = ollama_generate_once(model, PLAN_SYS_PROMPT + "\nëª©í‘œ:\n" + goal + "\nì¶œë ¥:\n", host, num_predict=400)
    try:
        import yaml
        doc = yaml.safe_load(yml) or {}
        steps = doc.get("pipeline") or []
    except Exception:
        steps = []
    steps, warns = validate_and_normalize_steps(steps)
    return steps, warns, {"raw_yaml": yml}

def revise_plan(prev_steps: List[dict], feedback: dict, model: str, host: str):
    payload = json.dumps({"prev": prev_steps, "feedback": feedback}, ensure_ascii=False)
    yml = ollama_generate_once(model, PLAN_SYS_PROMPT + "\nìˆ˜ì •:\n" + payload + "\nì¶œë ¥:\n", host, num_predict=400)
    try:
        import yaml
        doc = yaml.safe_load(yml) or {}
        steps = doc.get("pipeline") or []
    except Exception:
        steps = prev_steps
    steps, warns = validate_and_normalize_steps(steps)
    return steps, warns, {"raw_yaml": yml}

def evaluate_result(x, y_corr, onset_idx, peaks: List[dict]):
    ok=True; fb={}
    if onset_idx is None:
        ok=False; fb["onset"]="not_found"
    n=len(peaks or []); fb["peaks_count"]=n
    if n==0: ok=False; fb["peaks"]="none"
    if n>50: ok=False; fb["peaks"]="too_many"
    arr=np.asarray(y_corr,float)
    if arr.size>16:
        snr=(arr.max()-arr.min())/(arr[:max(8,arr.size//20)].std()+1e-12)
        fb["snr"]=float(snr)
        if snr<2.0:
            ok=False; fb["snr_status"]="low"
    return ok, fb

def default_agent_steps():
    return [
        {"op":"sg", "window":11, "poly":3},
        {"op":"baseline", "lam":1e5, "p":0.01, "iter":10},
        {"op":"peaks", "prominence_frac":0.02, "distance_pts":5}
    ]

# ===================== Plot / PDF =====================
def set_korean_font():
    candidates = [
        "Malgun Gothic", "Apple SD Gothic Neo",
        "Noto Sans CJK KR", "Noto Serif CJK KR",
        "NanumGothic", "NanumMyeongjo",
    ]
    fams = [f.name for f in fontManager.ttflist]
    for f in candidates:
        if f in fams:
            matplotlib.rcParams["font.family"] = [f]
            matplotlib.rcParams["axes.unicode_minus"] = False
            return
    matplotlib.rcParams["axes.unicode_minus"] = False
set_korean_font()

def plot_layers_png(x: List[float], y: List[float],
                    show_baseline: bool, baseline: Optional[np.ndarray],
                    show_onset: bool, onset_idx: Optional[int],
                    show_peaks: bool, peaks: Optional[List[dict]],
                    xlabel: str, ylabel: str,
                    show_corrected: bool = False, y_corr: Optional[np.ndarray] = None) -> bytes:
    x = np.asarray(x, dtype=float); y=np.asarray(y, dtype=float)
    fig = plt.figure()
    plt.plot(x, y, label="raw")
    if show_baseline and baseline is not None:
        plt.plot(x, baseline, linestyle="--", label="baseline")
    if show_corrected and (y_corr is not None):
        plt.plot(x, y_corr, linestyle="-.", label="corrected")
    if show_peaks and peaks:
        for p in peaks: plt.axvline(float(p["x"]), linestyle=":", linewidth=1)
    if show_onset and onset_idx is not None and 0 <= onset_idx < len(x):
        plt.axvline(float(x[onset_idx]), linestyle="-.", linewidth=1.2)
    plt.xlabel(xlabel); plt.ylabel(ylabel); plt.legend(loc="best")
    buf = BytesIO(); fig.savefig(buf, format="png", bbox_inches="tight", dpi=150); plt.close(fig)
    return buf.getvalue()

def plot_layers_dual_png(
    x: List[float], y: List[float],
    show_baseline: bool, baseline: Optional[np.ndarray],
    show_onset: bool, onset_idx: Optional[int],
    show_peaks: bool, peaks: Optional[List[dict]],
    xlabel: str, ylabel: str,
    y_corr: Optional[np.ndarray]
) -> bytes:
    x = np.asarray(x, dtype=float); y = np.asarray(y, dtype=float)
    if y_corr is None:
        y_corr = y if baseline is None else (y - baseline)
    fig, axes = plt.subplots(1, 2, figsize=(10, 4))
    ax = axes[0]
    ax.plot(x, y, label="raw")
    if show_baseline and (baseline is not None):
        ax.plot(x, baseline, linestyle="--", label="baseline")
    ax.set_xlabel(xlabel); ax.set_ylabel(ylabel); ax.legend(loc="best"); ax.set_title("Raw + Baseline")
    ax = axes[1]
    ax.plot(x, y_corr, label="corrected", linestyle="-.")
    if show_peaks and peaks:
        for p in peaks: ax.axvline(float(p["x"]), linestyle=":", linewidth=1)
    if show_onset and onset_idx is not None and 0 <= onset_idx < len(x):
        ax.axvline(float(x[onset_idx]), linestyle="-.", linewidth=1.2)
    ax.set_xlabel(xlabel); ax.set_ylabel(ylabel); ax.legend(loc="best"); ax.set_title("Corrected + Peaks/Onset")
    buf = BytesIO(); fig.tight_layout(); fig.savefig(buf, format="png", bbox_inches="tight", dpi=150); plt.close(fig)
    return buf.getvalue()

def save_pdf_report(filename_or_buf, pages: List[Dict]):
    """A4 portrait, images(â‰¤2) + wrapped text, multi-page split."""
    A4_W, A4_H = (8.27, 11.69)
    with PdfPages(filename_or_buf) as pdf:
        page_no = 0
        for page in pages:
            title = page.get("title","")
            images = page.get("images",[]) or []
            blocks = page.get("text_blocks",[]) or []

            i_idx = 0
            b_idx = 0
            while True:
                fig = plt.figure(figsize=(A4_W, A4_H))
                ax_page = plt.gca(); ax_page.axis("off")
                y_cur = 0.96
                if title and (i_idx==0 and b_idx==0):
                    plt.text(0.03, y_cur, title, fontsize=14, weight="bold", transform=ax_page.transAxes)
                    y_cur -= 0.05

                # images (max 2 per page)
                if i_idx < len(images):
                    if i_idx+1 < len(images):
                        for col in range(2):
                            if i_idx >= len(images): break
                            ax = plt.axes([0.05 + col*0.47, 0.58, 0.43, 0.32])
                            ax.axis("off")
                            ax.imshow(Image.open(BytesIO(images[i_idx])))
                            i_idx += 1
                        y_cur = 0.54
                    else:
                        ax = plt.axes([0.05, 0.58, 0.9, 0.32])
                        ax.axis("off")
                        ax.imshow(Image.open(BytesIO(images[i_idx])))
                        i_idx += 1
                        y_cur = 0.54

                # text blocks (wrapped, split)
                max_blocks_this_page = 10
                while b_idx < len(blocks) and max_blocks_this_page>0:
                    blk = str(blocks[b_idx]).replace("\r\n","\n")
                    wrapped = textwrap.wrap(blk, width=100)
                    need = 0.02 + 0.018*max(1, len(wrapped))
                    if y_cur - need < 0.06:
                        break
                    plt.text(0.04, y_cur, "\n".join(wrapped), fontsize=10,
                             transform=ax_page.transAxes, va='top')
                    y_cur -= need
                    b_idx += 1
                    max_blocks_this_page -= 1

                page_no += 1
                plt.text(0.95, 0.02, f"{page_no}", fontsize=9, transform=ax_page.transAxes, ha='right', color='#666')
                pdf.savefig(fig, bbox_inches="tight"); plt.close(fig)

                if (i_idx >= len(images)) and (b_idx >= len(blocks)):
                    break

# ===================== HTML =====================
def html_form():
    host_info = f"Ollama host: <code>{OLLAMA_HOST}</code> Â· TEXT_MODEL: <code>{TEXT_MODEL}</code>"
    token_hint = "(Auth ON)" if AUTH_TOKEN else "(Auth OFF)"
    auth_on_js = "true" if AUTH_TOKEN else "false"
    auth_val_js = (AUTH_TOKEN or "").replace("\\", "\\\\").replace('"', '\\"')
    return f"""<!doctype html>
<html><head><meta charset="utf-8"><title>Spectrum Agent Starter</title>
<style>
body{{max-width:1100px;margin:20px auto;font-family:system-ui,-apple-system,Segoe UI,Roboto}}
.flex{{display:flex;gap:12px;flex-wrap:wrap}}
.preview img{{max-height:240px;border:1px solid #ddd;padding:4px;background:#fff}}
.result{{white-space:pre-wrap;border:1px solid #ddd;padding:12px;background:#fafafa}}
.small{{color:#666;font-size:12px}}
.tablabel{{padding:6px 12px;cursor:pointer;background:#eee;margin-right:4px;border:1px solid #ddd;display:inline-block}}
.tabpanel{{display:none;padding:8px;border:1px solid #ddd;margin-top:4px}}
.tabpanel.active{{display:block}}
</style></head><body>
<h1>ğŸ“ˆ Spectrum Agent Starter (Text-only)</h1>
<div class="small">{host_info} Â· {token_hint}</div>

<form action="/analyze" method="post" enctype="multipart/form-data">
  <label>CSV/Excel (multi)</label><br>
  <input id="fileInput" type="file" name="csv" accept=".csv,.tsv,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet,application/vnd.ms-excel" multiple required />

  <fieldset style="margin-top:10px;">
    <legend>ì‹¤í–‰ ëª¨ë“œ</legend>
    <label><input type="radio" name="run_mode" value="manual" checked> ìˆ˜ë™(ì²´í¬ë°•ìŠ¤)</label>
    <label><input type="radio" name="run_mode" value="agent"> ëª©í‘œ ê¸°ë°˜(Agent)</label>
  </fieldset>

  <label>Prompt / Goal</label>
  <textarea name="prompt" rows="5" style="width:100%;">ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ. ì£¼ìš” í”¼í¬ì™€ ë¬¼ë¦¬ì  ì˜ë¯¸ë¥¼ ìš”ì•½í•˜ë¼.</textarea>

  <fieldset style="margin-top:10px;">
    <legend>ì „ì²˜ë¦¬ ì˜µì…˜ (ìˆ˜ë™ ëª¨ë“œ)</legend>
    <div class="flex">
      <label><input type="checkbox" name="do_hampel" value="1"> Hampel</label>
      <label><input type="checkbox" name="do_sg" value="1" checked> Savitzkyâ€“Golay</label>
      <label><input type="checkbox" name="do_bg" value="1" checked> Baseline (AsLS)</label>
      <label><input type="checkbox" name="do_onset" value="1"> Onset</label>
      <label><input type="checkbox" name="do_peaks" value="1" checked> Peaks</label>
      <label><input type="checkbox" name="show_corrected" value="1" checked> Show corrected</label>
    </div>
    <div class="flex">
      <div style="flex:1"><label>Hampel window</label><input name="hampel_win" value="7"></div>
      <div style="flex:1"><label>Hampel sigma</label><input name="hampel_sigma" value="3.0"></div>
      <div style="flex:1"><label>SG window</label><input name="sg_win" value="11"></div>
      <div style="flex:1"><label>SG poly</label><input name="sg_poly" value="3"></div>
    </div>
    <div class="flex">
      <div style="flex:1"><label>AsLS Î»</label><input name="bg_lam" value="100000"></div>
      <div style="flex:1"><label>AsLS p</label><input name="bg_p" value="0.01"></div>
      <div style="flex:1"><label>AsLS iter</label><input name="bg_iter" value="10"></div>
    </div>
    <div class="flex">
      <div style="flex:1"><label>Onset win</label><input name="on_win" value="11"></div>
      <div style="flex:1"><label>Onset poly</label><input name="on_poly" value="2"></div>
      <div style="flex:1"><label>Onset z</label><input name="on_z" value="3.0"></div>
    </div>
    <div class="flex">
      <div style="flex:1"><label>peaks.prominence_frac</label><input name="prom_frac" value="0.02"></div>
      <div style="flex:1"><label>peaks.distance_pts</label><input name="dist_pts" value="5"></div>
      <div style="flex:1"><label>peaks.width</label><input name="width" value=""></div>
    </div>
  </fieldset>

  <div class="flex" style="margin-top:10px;">
    <button type="button" onclick="doPreview()">Preview First File</button>
    <button type="submit">Analyze</button>
  </div>
</form>

<h3>Data Preview</h3>
<div id="preview" class="preview"></div>
<div id="previewStats" class="small"></div>

<hr>
<h2>Chatbot</h2>
<div class="flex">
  <input id="chatInput" style="flex:1" placeholder="ëª¨ë¸ì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”â€¦">
  <button onclick="sendChat()">Send</button>
</div>
<pre id="chatLog" class="result" style="margin-top:8px;min-height:140px;"></pre>

<script>
const AUTH_TOKEN = {{"on": {auth_on_js}, "val": "{auth_val_js}"}};

async function doPreview(){{
  const fi = document.getElementById('fileInput');
  const preview = document.getElementById('preview');
  const stats = document.getElementById('previewStats');
  preview.innerHTML = ''; stats.textContent='';
  if(!fi.files || !fi.files.length){{ alert('íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”'); return; }}

  const fd = new FormData();
  fd.append('csv', fi.files[0]); // í•„ë“œëª… 'csv' ê³ ì •

  try{{
    const res = await fetch('/preview', {{
      method: 'POST',
      headers: AUTH_TOKEN.on ? {{'X-Auth-Token': AUTH_TOKEN.val}} : {{}},
      body: fd
    }});
    if(!res.ok){{ throw new Error(await res.text()); }}
    const data = await res.json();
    preview.innerHTML = '<img alt="preview" src="'+data.png+'">';
    const s = data.stats || {{}};
    stats.textContent = `points=${{s.n_points}} | ${{s.xlabel}}: ${{s.x_min}}~${{s.x_max}} | ${{s.ylabel}}: ${{s.y_min}}~${{s.y_max}}`;
  }}catch(e){{
    preview.innerHTML = '<div class="small" style="color:#b00;">ë¯¸ë¦¬ë³´ê¸° ì‹¤íŒ¨</div>';
    console.error('preview error:', e);
  }}
}}

async function sendChat(){{
  const input = document.getElementById('chatInput');
  const log = document.getElementById('chatLog');
  const text = input.value.trim(); if(!text) return;
  log.textContent += "\\n[You] "+text+"\\n";
  input.value = '';
  try{{
    const res = await fetch('/chat', {{
      method:'POST',
      headers: Object.assign({{'Content-Type':'application/json'}}, AUTH_TOKEN.on ? {{'X-Auth-Token': AUTH_TOKEN.val}} : {{}}),
      body: JSON.stringify({{message: text}})
    }});
    if(!res.ok){{ throw new Error(await res.text()); }}
    const data = await res.json();
    log.textContent += "[Model] "+data.reply+"\\n";
  }}catch(e){{
    log.textContent += "[Error] "+e.message+"\\n";
  }}
}}
</script>

</body></html>
"""

# ===================== Routes =====================
@app.get("/", response_class=HTMLResponse)
def index(_: bool = Depends(require_auth)):
    return html_form()

@app.get("/debug/models")
def debug_models(_: bool = Depends(require_auth)):
    return {
        "host": OLLAMA_HOST,
        "available_models": list_model_names(OLLAMA_HOST),
        "text_model_fixed": TEXT_MODEL,
    }

@app.post("/preview")
def preview(csv: UploadFile = File(...), _ok: bool = Depends(require_auth)):
    try:
        b = csv.file.read()
        csv.file.close()
        low = (csv.filename or "").lower()
        if low.endswith((".xlsx",".xls")):
            x, y, xlabel, ylabel = parse_excel(b)
        else:
            x, y, xlabel, ylabel = parse_spectrum_csv(b)
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"preview parse error: {e}")

    fig = plt.figure()
    plt.plot(x, y); plt.xlabel(xlabel); plt.ylabel(ylabel)
    buf = BytesIO(); fig.savefig(buf, format="png", bbox_inches="tight", dpi=150); plt.close(fig)
    img64 = base64.b64encode(buf.getvalue()).decode()
    stats = {
        "n_points": len(x),
        "xlabel": xlabel, "ylabel": ylabel,
        "x_min": float(np.min(x)), "x_max": float(np.max(x)),
        "y_min": float(np.min(y)), "y_max": float(np.max(y)),
    }
    return JSONResponse({"png": "data:image/png;base64,"+img64, "stats": stats})

@app.post("/chat")
def chat(payload: dict = Body(...), _ok: bool = Depends(require_auth)):
    model_chosen = ensure_model_installed(TEXT_MODEL, OLLAMA_HOST)
    user_text = (payload.get("message") or "").strip()
    if not user_text:
        raise HTTPException(status_code=400, detail="empty message")
    reply = ollama_generate_once(model_chosen, user_text, OLLAMA_HOST, num_predict=600)
    return {"reply": reply}

@app.post("/analyze", response_class=HTMLResponse)
def analyze(
    csv: List[UploadFile] = File(...),
    prompt: str = Form(""),
    run_mode: str = Form("manual"),

    # manual options
    do_hampel: Optional[str] = Form(None),
    do_sg: Optional[str] = Form(None),
    do_bg: Optional[str] = Form(None),
    do_onset: Optional[str] = Form(None),
    do_peaks: Optional[str] = Form(None),
    show_corrected: Optional[str] = Form(None),

    hampel_win: str = Form("7"),
    hampel_sigma: str = Form("3.0"),
    sg_win: str = Form("11"),
    sg_poly: str = Form("3"),

    bg_lam: str = Form("100000"),
    bg_p: str = Form("0.01"),
    bg_iter: str = Form("10"),

    on_win: str = Form("11"),
    on_poly: str = Form("2"),
    on_z: str = Form("3.0"),

    prom_frac: str = Form("0.02"),
    dist_pts: str = Form("5"),
    width: str = Form(""),

    _ok: bool = Depends(require_auth)
):
    def f2(v,d):
        try: return float(v)
        except: return d
    def i2(v,d):
        try: return int(float(v))
        except: return d

    use_hampel = (do_hampel=="1")
    use_sg     = (do_sg=="1")
    use_bg     = (do_bg=="1")
    use_onset  = (do_onset=="1")
    use_peaks  = (do_peaks=="1")
    show_corr  = (show_corrected=="1")

    hampel_win_v   = max(i2(hampel_win,7),3)
    hampel_sigma_v = max(f2(hampel_sigma,3.0),0.1)
    sg_win_v       = max(i2(sg_win,11),5)
    sg_poly_v      = max(i2(sg_poly,3),2)

    bg_lam_v  = max(f2(bg_lam,1e5),1.0)
    bg_p_v    = min(max(f2(bg_p,0.01),1e-5),0.5)
    bg_iter_v = max(i2(bg_iter,10),1)

    on_win_v  = max(i2(on_win,11),5)
    on_poly_v = max(i2(on_poly,2),1)
    on_z_v    = max(f2(on_z,3.0),0.1)

    prom_frac_v = f2(prom_frac,0.02)
    dist_pts_v  = max(i2(dist_pts,5),1)
    width_v     = f2(width,None) if (width or "").strip() else None

    model_chosen = ensure_model_installed(TEXT_MODEL, OLLAMA_HOST)

    # read all uploaded files (sync)
    file_payloads=[]
    for k, uf in enumerate(csv,1):
        name = uf.filename or f"file_{k}"
        b = uf.file.read()
        uf.file.close()
        file_payloads.append({"name":name,"bytes":b})

    tabs_labels=[]; tabs_panes=[]
    pdf_pages=[]

    for fp in file_payloads:
        name = fp["name"]; b = fp["bytes"]
        try:
            low = name.lower()
            if low.endswith((".xlsx",".xls")):
                x, y, xlabel, ylabel = parse_excel(b)
            else:
                x, y, xlabel, ylabel = parse_spectrum_csv(b)
        except Exception as e:
            tabs_labels.append(f"<span class='tablabel'>{name}</span>")
            tabs_panes.append(f"<div class='tabpanel'><h3>{name}</h3><div class='result' style='color:#b00;'>íŒŒì‹± ì‹¤íŒ¨: {e}</div></div>")
            pdf_pages.append({"title": f"{name} â€” ì˜¤ë¥˜ ë³´ê³ ", "images": [], "text_blocks": [f"ì˜¤ë¥˜: {repr(e)}"]})
            continue

        # ---------- AGENT MODE ----------
        if run_mode == "agent":
            steps, warns, _ = plan_from_goal(prompt, model_chosen, OLLAMA_HOST)
            steps, _ = validate_and_normalize_steps(steps)
            if not steps or all(s.get("__unknown__") for s in steps):
                steps = default_agent_steps()

            history=[]
            for it in range(1, MAX_AGENT_ITERS+1):
                # ë§¤íšŒ ì›ë³¸ì—ì„œ ì‹¤í–‰ (ê³„íšì´ ë°”ë€” ìˆ˜ ìˆìœ¼ë‹ˆ)
                x2, y2, metas = execute_steps(x, y, steps)
                y_work = np.asarray(y2, float)
                onset_idx = detect_onset(x2, y_work.tolist(), win=on_win_v, poly=on_poly_v, z_thresh=on_z_v)
                peaks = detect_peaks_list(x2, y_work.tolist(), prominence_frac=prom_frac_v, distance_pts=dist_pts_v, width=width_v)
                ok, fb = evaluate_result(x2, y_work, onset_idx, peaks)
                history.append({"iter":it, "steps":steps, "feedback":fb})
                if ok:
                    break
                steps, _, _ = revise_plan(steps, fb, model_chosen, OLLAMA_HOST)
                steps, _ = validate_and_normalize_steps(steps)
                if not steps or all(s.get("__unknown__") for s in steps):
                    steps = default_agent_steps()

            overlay_png = plot_layers_dual_png(
                x2, y,
                show_baseline=False, baseline=None,
                show_onset=True, onset_idx=onset_idx,
                show_peaks=True, peaks=peaks,
                xlabel=xlabel, ylabel=ylabel,
                y_corr=np.asarray(y2,float)
            )
            img64 = base64.b64encode(overlay_png).decode()

            base_prompt = (
                (prompt or "ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ. ìŠ¤í™íŠ¸ëŸ¼ë§Œ í•´ì„í•˜ë¼.").strip()
                + "\n\n[Agent ìµœì¢… ë‹¨ê³„]\n"
                + json.dumps(steps, ensure_ascii=False)
                + "\n[ê²€ì¶œ]\n"
                + (f"onset @ {x2[onset_idx]:.6g}" if onset_idx is not None else "(no onset)")
                + "\npeaks:\n"
                + ("\n".join([f"- peak @ {p['x']:.6g} (y={p['y']:.6g}, prom={p['prom']:.6g})" for p in peaks]) or "(no peaks)")
                + "\nì´ë¯¸ì§€/í˜•íƒœ ì–¸ê¸‰ ê¸ˆì§€."
            )
            out_text = ollama_generate_once(model_chosen, base_prompt, OLLAMA_HOST, num_predict=800)

            pane_inner = (
                f"<h3>{name} â€” Agent</h3>"
                f"<div class='preview'><img src='data:image/png;base64,{img64}'></div>"
                "<details class='small'><summary>Agent steps</summary><pre>"
                + json.dumps(steps, indent=2, ensure_ascii=False) + "</pre></details>"
                "<details class='small'><summary>History</summary><pre>"
                + json.dumps(history, indent=2, ensure_ascii=False) + "</pre></details>"
                "<h3>LLM í•´ì„</h3><div class='result'>"+ out_text + "</div>"
            )
            tabs_labels.append(f"<span class='tablabel'>{name}</span>")
            tabs_panes.append(f"<div class='tabpanel'>{pane_inner}</div>")

            pdf_pages.append({
                "title": f"{name} â€” Agent ê²°ê³¼",
                "images": [overlay_png],
                "text_blocks": [
                    "ìµœì¢… Steps:\n" + json.dumps(steps, ensure_ascii=False),
                    "ë§ˆì§€ë§‰ Feedback:\n" + json.dumps(history[-1]["feedback"] if history else {}, ensure_ascii=False),
                    "LLM í•´ì„:\n" + out_text
                ]
            })
            continue

        # ---------- MANUAL MODE ----------
        y_work = np.asarray(y, float)
        if use_hampel:
            _, y_work_list, _ = op_hampel(x, y_work.tolist(), {"window":hampel_win_v,"sigma":hampel_sigma_v})
            y_work = np.asarray(y_work_list, float)
        if use_sg:
            _, y_work_list, _ = op_sg(x, y_work.tolist(), {"window":sg_win_v,"poly":sg_poly_v})
            y_work = np.asarray(y_work_list, float)

        baseline = None
        y_corr = y_work.copy()
        if use_bg:
            baseline = baseline_asls(y_corr, lam=bg_lam_v, p=bg_p_v, niter=bg_iter_v)
            y_corr = y_corr - baseline

        onset_idx = detect_onset(x, y_corr.tolist(), win=on_win_v, poly=on_poly_v, z_thresh=on_z_v) if use_onset else None
        peaks = detect_peaks_list(x, y_corr.tolist(), prominence_frac=prom_frac_v, distance_pts=dist_pts_v, width=width_v) if use_peaks else []

        if show_corr:
            overlay_png = plot_layers_dual_png(
                x, y,
                show_baseline=use_bg, baseline=baseline,
                show_onset=use_onset, onset_idx=onset_idx,
                show_peaks=use_peaks, peaks=peaks,
                xlabel=xlabel, ylabel=ylabel,
                y_corr=y_corr
            )
        else:
            overlay_png = plot_layers_png(
                x, y,
                show_baseline=use_bg, baseline=baseline,
                show_onset=use_onset, onset_idx=onset_idx,
                show_peaks=use_peaks, peaks=peaks,
                xlabel=xlabel, ylabel=ylabel,
                show_corrected=False, y_corr=None
            )
        img64 = base64.b64encode(overlay_png).decode()

        top_peaks_text = "\n".join([f"- peak @ {p['x']:.6g} (y={p['y']:.6g}, prom={p['prom']:.6g})" for p in peaks]) or "(no peaks)"
        onset_line = f"onset @ {x[onset_idx]:.6g}" if (onset_idx is not None) else "(no onset)"
        base_prompt = (
            (prompt or "ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ. ìŠ¤í™íŠ¸ëŸ¼ë§Œ í•´ì„í•˜ë¼.").strip()
            + "\n\n[ì „ì²˜ë¦¬ ì˜µì…˜] DN(Hampel="+("Y" if use_hampel else "N")
            + ", SG="+("Y" if use_sg else "N")+") | BG="+("Y" if use_bg else "N")
            + " | ONSET="+("Y" if use_onset else "N")+" | PEAKS="+("Y" if use_peaks else "N")
            + f"\n[ì¶•] X={xlabel}, Y={ylabel}"
            + f"\n[onset] {onset_line}\n[peaks]\n{top_peaks_text}\nì´ë¯¸ì§€/í˜•íƒœ ì–¸ê¸‰ ê¸ˆì§€."
        )
        out_text = ollama_generate_once(model_chosen, base_prompt, OLLAMA_HOST, num_predict=800)

        params = {
            "Hampel": f"window={hampel_win_v}, sigma={hampel_sigma_v}" if use_hampel else "OFF",
            "Savitzkyâ€“Golay": f"window={sg_win_v}, poly={sg_poly_v}" if use_sg else "OFF",
            "AsLS": f"Î»={bg_lam_v}, p={bg_p_v}, iter={bg_iter_v}" if use_bg else "OFF",
            "Onset": f"win={on_win_v}, poly={on_poly_v}, z={on_z_v}" if use_onset else "OFF",
            "Peaks": f"prom_frac={prom_frac_v}, dist={dist_pts_v}, width={width_v}" if use_peaks else "OFF"
        }
        param_lines = "\n".join([f"{k}: {v}" for k, v in params.items()])
        param_html = (
            "<details class='small' style='margin:8px 0;'><summary>ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„°</summary>"
            "<pre style='white-space:pre-wrap;'>" + param_lines + "</pre></details>"
        )

        pane_inner = (
            f"<h3>{name} â€” Manual</h3>"
            f"<div class='preview'><img src='data:image/png;base64,{img64}'></div>"
            "<h3>Server Summary (text fed to LLM)</h3>"
            "<pre>"+ base_prompt + "</pre>"
            + param_html +
            "<h3>LLM í•´ì„</h3><div class='result'>"+ out_text + "</div>"
        )
        tabs_labels.append(f"<span class='tablabel'>{name}</span>")
        tabs_panes.append(f"<div class='tabpanel'>{pane_inner}</div>")

        pdf_pages.append({
            "title": f"{name} â€” Manual ê²°ê³¼",
            "images": [overlay_png],
            "text_blocks": [
                "ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„°:\n"+param_lines,
                "LLM í•´ì„:\n"+out_text
            ]
        })

    # Tabs HTML
    tabs_html = (
        "<div id='tablabels'>" + "".join(tabs_labels) + "</div>"
        + "<div id='tabpanes'>" + "".join(tabs_panes) + "</div>"
        + "<script>(function(){{const ls=[...document.querySelectorAll('.tablabel')];const ps=[...document.querySelectorAll('.tabpanel')];function act(i){{ls.forEach((el,k)=>el.style.fontWeight=k===i?'bold':'normal');ps.forEach((el,k)=>el.className='tabpanel'+(k===i?' active':''));}}ls.forEach((el,i)=>el.addEventListener('click',()=>act(i)));if(ls.length)act(0);}})();</script>"
    )

    # PDF build
    pdf_buf = BytesIO()
    save_pdf_report(pdf_buf, pdf_pages)
    pdf_bytes = pdf_buf.getvalue()
    pdf_b64 = base64.b64encode(pdf_bytes).decode()

    html = f"""<!doctype html><html><head><meta charset="utf-8"><title>Results</title>
<style>
.preview img{{max-height:240px;border:1px solid #ddd;padding:4px;background:#fff}}
.result{{white-space:pre-wrap;border:1px solid #ddd;padding:12px;background:#fafafa}}
.small{{color:#666;font-size:12px}}
.tablabel{{padding:6px 12px;cursor:pointer;background:#eee;margin-right:4px;border:1px solid #ddd;display:inline-block}}
.tabpanel{{display:none;padding:8px;border:1px solid #ddd;margin-top:4px}}
.tabpanel.active{{display:block}}
</style></head><body>
<h2>Results ({ensure_model_installed(TEXT_MODEL, OLLAMA_HOST)} @ {OLLAMA_HOST})</h2>
<p><a download="spectrum_report.pdf" href="data:application/pdf;base64,{pdf_b64}">ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ</a></p>
{tabs_html}
<p class="small">* Text-only single host Â· Manual/Agent ì§€ì›</p>
<p><a href="/">â† Back</a></p>
</body></html>"""
    return HTMLResponse(html)

# ===================== main =====================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=7862, log_level="info")